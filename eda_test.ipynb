{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90566,"databundleVersionId":10712530,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:00:44.758793Z","iopub.execute_input":"2025-02-09T04:00:44.759342Z","iopub.status.idle":"2025-02-09T04:00:44.770007Z","shell.execute_reply.started":"2025-02-09T04:00:44.759287Z","shell.execute_reply":"2025-02-09T04:00:44.768521Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/widsdatathon2025/SAMPLE_SUBMISSION.xlsx\n/kaggle/input/widsdatathon2025/Data Dictionary.xlsx\n/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\n/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\n/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\n/kaggle/input/widsdatathon2025/TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\n/kaggle/input/widsdatathon2025/TRAIN/TRAINING_SOLUTIONS.xlsx\n/kaggle/input/widsdatathon2025/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx\n/kaggle/input/widsdatathon2025/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"main_dir = \"/kaggle/input/widsdatathon2025\"\ntrain_connectome = pd.read_csv(f\"{main_dir}/TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\ntest_connectome = pd.read_csv(f\"{main_dir}/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\ntrain_quantitative = pd.read_excel(f\"{main_dir}/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx\")\ntest_quantitative = pd.read_excel(f\"{main_dir}/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\ntrain_solutions = pd.read_excel(f\"{main_dir}/TRAIN/TRAINING_SOLUTIONS.xlsx\")\nsample_submission = pd.read_excel(f'{main_dir}/SAMPLE_SUBMISSION.xlsx')\ntrain_categorical = pd.read_excel(f'{main_dir}/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx')\ntest_categorical = pd.read_excel(f'{main_dir}/TEST/TEST_CATEGORICAL.xlsx')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:00:44.771675Z","iopub.execute_input":"2025-02-09T04:00:44.772115Z","iopub.status.idle":"2025-02-09T04:01:00.717312Z","shell.execute_reply.started":"2025-02-09T04:00:44.772077Z","shell.execute_reply":"2025-02-09T04:01:00.716250Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:00.718932Z","iopub.execute_input":"2025-02-09T04:01:00.719277Z","iopub.status.idle":"2025-02-09T04:01:00.724331Z","shell.execute_reply.started":"2025-02-09T04:01:00.719218Z","shell.execute_reply":"2025-02-09T04:01:00.723166Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"print(f\"shape of functional MRI connectome matrices\", train_connectome.shape)\nprint(f\"shape of functional MRI quantitative metadata\", train_quantitative.shape)\nprint(f\"shape of functional MRI metadata\", train_categorical.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:00.726063Z","iopub.execute_input":"2025-02-09T04:01:00.726499Z","iopub.status.idle":"2025-02-09T04:01:00.747129Z","shell.execute_reply.started":"2025-02-09T04:01:00.726450Z","shell.execute_reply":"2025-02-09T04:01:00.745866Z"}},"outputs":[{"name":"stdout","text":"shape of functional MRI connectome matrices (1213, 19901)\nshape of functional MRI quantitative metadata (1213, 19)\nshape of functional MRI metadata (1213, 10)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"train_connectome.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:00.748159Z","iopub.execute_input":"2025-02-09T04:01:00.748573Z","iopub.status.idle":"2025-02-09T04:01:29.726548Z","shell.execute_reply.started":"2025-02-09T04:01:00.748510Z","shell.execute_reply":"2025-02-09T04:01:29.725208Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"       0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  0throw_4thcolumn  \\\ncount       1213.000000       1213.000000       1213.000000       1213.000000   \nmean           0.060553          0.122315          0.060268          0.041287   \nstd            0.064178          0.054026          0.057495          0.043491   \nmin           -0.183279         -0.059932         -0.145566         -0.127827   \n25%            0.018482          0.086102          0.026548          0.014457   \n50%            0.058276          0.123220          0.061339          0.043246   \n75%            0.100103          0.154518          0.099056          0.068408   \nmax            0.321522          0.390895          0.278429          0.189825   \n\n       0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  0throw_8thcolumn  \\\ncount       1213.000000       1213.000000       1213.000000       1213.000000   \nmean           0.069722          0.091007          0.066852          0.000252   \nstd            0.044222          0.049189          0.046864          0.049046   \nmin           -0.072043         -0.079184         -0.105722         -0.164297   \n25%            0.042462          0.057614          0.036934         -0.031358   \n50%            0.067066          0.086494          0.067247          0.002549   \n75%            0.096504          0.119404          0.095117          0.031053   \nmax            0.317500          0.316811          0.270018          0.168196   \n\n       0throw_9thcolumn  0throw_10thcolumn  ...  195throw_196thcolumn  \\\ncount       1213.000000        1213.000000  ...           1213.000000   \nmean           0.014128          -0.002914  ...              0.011075   \nstd            0.038205           0.042462  ...              0.049632   \nmin           -0.137728          -0.148490  ...             -0.161666   \n25%           -0.010635          -0.030538  ...             -0.021376   \n50%            0.016130          -0.002604  ...              0.010254   \n75%            0.038770           0.024507  ...              0.044165   \nmax            0.145364           0.128301  ...              0.194616   \n\n       195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\ncount           1213.000000           1213.000000           1213.000000   \nmean              -0.004938             -0.004378              0.001610   \nstd                0.046536              0.042900              0.047424   \nmin               -0.176523             -0.178688             -0.138048   \n25%               -0.033424             -0.033798             -0.030132   \n50%               -0.004683             -0.003724              0.000990   \n75%                0.024913              0.024007              0.032268   \nmax                0.183152              0.180562              0.192015   \n\n       196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\ncount           1213.000000           1213.000000           1213.000000   \nmean               0.115171              0.049984              0.058144   \nstd                0.057128              0.051664              0.057674   \nmin               -0.070094             -0.153540             -0.131455   \n25%                0.080291              0.015827              0.022316   \n50%                0.113640              0.052705              0.059151   \n75%                0.150524              0.082526              0.095192   \nmax                0.375635              0.228748              0.322084   \n\n       197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \ncount           1213.000000           1213.000000           1213.000000  \nmean               0.093527              0.089403              0.128946  \nstd                0.054594              0.058036              0.058490  \nmin               -0.085566             -0.204160             -0.083077  \n25%                0.059621              0.053224              0.090459  \n50%                0.093397              0.088612              0.127913  \n75%                0.127144              0.127613              0.166523  \nmax                0.348153              0.267162              0.414304  \n\n[8 rows x 19900 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0throw_1thcolumn</th>\n      <th>0throw_2thcolumn</th>\n      <th>0throw_3thcolumn</th>\n      <th>0throw_4thcolumn</th>\n      <th>0throw_5thcolumn</th>\n      <th>0throw_6thcolumn</th>\n      <th>0throw_7thcolumn</th>\n      <th>0throw_8thcolumn</th>\n      <th>0throw_9thcolumn</th>\n      <th>0throw_10thcolumn</th>\n      <th>...</th>\n      <th>195throw_196thcolumn</th>\n      <th>195throw_197thcolumn</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>...</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.060553</td>\n      <td>0.122315</td>\n      <td>0.060268</td>\n      <td>0.041287</td>\n      <td>0.069722</td>\n      <td>0.091007</td>\n      <td>0.066852</td>\n      <td>0.000252</td>\n      <td>0.014128</td>\n      <td>-0.002914</td>\n      <td>...</td>\n      <td>0.011075</td>\n      <td>-0.004938</td>\n      <td>-0.004378</td>\n      <td>0.001610</td>\n      <td>0.115171</td>\n      <td>0.049984</td>\n      <td>0.058144</td>\n      <td>0.093527</td>\n      <td>0.089403</td>\n      <td>0.128946</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.064178</td>\n      <td>0.054026</td>\n      <td>0.057495</td>\n      <td>0.043491</td>\n      <td>0.044222</td>\n      <td>0.049189</td>\n      <td>0.046864</td>\n      <td>0.049046</td>\n      <td>0.038205</td>\n      <td>0.042462</td>\n      <td>...</td>\n      <td>0.049632</td>\n      <td>0.046536</td>\n      <td>0.042900</td>\n      <td>0.047424</td>\n      <td>0.057128</td>\n      <td>0.051664</td>\n      <td>0.057674</td>\n      <td>0.054594</td>\n      <td>0.058036</td>\n      <td>0.058490</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.183279</td>\n      <td>-0.059932</td>\n      <td>-0.145566</td>\n      <td>-0.127827</td>\n      <td>-0.072043</td>\n      <td>-0.079184</td>\n      <td>-0.105722</td>\n      <td>-0.164297</td>\n      <td>-0.137728</td>\n      <td>-0.148490</td>\n      <td>...</td>\n      <td>-0.161666</td>\n      <td>-0.176523</td>\n      <td>-0.178688</td>\n      <td>-0.138048</td>\n      <td>-0.070094</td>\n      <td>-0.153540</td>\n      <td>-0.131455</td>\n      <td>-0.085566</td>\n      <td>-0.204160</td>\n      <td>-0.083077</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.018482</td>\n      <td>0.086102</td>\n      <td>0.026548</td>\n      <td>0.014457</td>\n      <td>0.042462</td>\n      <td>0.057614</td>\n      <td>0.036934</td>\n      <td>-0.031358</td>\n      <td>-0.010635</td>\n      <td>-0.030538</td>\n      <td>...</td>\n      <td>-0.021376</td>\n      <td>-0.033424</td>\n      <td>-0.033798</td>\n      <td>-0.030132</td>\n      <td>0.080291</td>\n      <td>0.015827</td>\n      <td>0.022316</td>\n      <td>0.059621</td>\n      <td>0.053224</td>\n      <td>0.090459</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.058276</td>\n      <td>0.123220</td>\n      <td>0.061339</td>\n      <td>0.043246</td>\n      <td>0.067066</td>\n      <td>0.086494</td>\n      <td>0.067247</td>\n      <td>0.002549</td>\n      <td>0.016130</td>\n      <td>-0.002604</td>\n      <td>...</td>\n      <td>0.010254</td>\n      <td>-0.004683</td>\n      <td>-0.003724</td>\n      <td>0.000990</td>\n      <td>0.113640</td>\n      <td>0.052705</td>\n      <td>0.059151</td>\n      <td>0.093397</td>\n      <td>0.088612</td>\n      <td>0.127913</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.100103</td>\n      <td>0.154518</td>\n      <td>0.099056</td>\n      <td>0.068408</td>\n      <td>0.096504</td>\n      <td>0.119404</td>\n      <td>0.095117</td>\n      <td>0.031053</td>\n      <td>0.038770</td>\n      <td>0.024507</td>\n      <td>...</td>\n      <td>0.044165</td>\n      <td>0.024913</td>\n      <td>0.024007</td>\n      <td>0.032268</td>\n      <td>0.150524</td>\n      <td>0.082526</td>\n      <td>0.095192</td>\n      <td>0.127144</td>\n      <td>0.127613</td>\n      <td>0.166523</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.321522</td>\n      <td>0.390895</td>\n      <td>0.278429</td>\n      <td>0.189825</td>\n      <td>0.317500</td>\n      <td>0.316811</td>\n      <td>0.270018</td>\n      <td>0.168196</td>\n      <td>0.145364</td>\n      <td>0.128301</td>\n      <td>...</td>\n      <td>0.194616</td>\n      <td>0.183152</td>\n      <td>0.180562</td>\n      <td>0.192015</td>\n      <td>0.375635</td>\n      <td>0.228748</td>\n      <td>0.322084</td>\n      <td>0.348153</td>\n      <td>0.267162</td>\n      <td>0.414304</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 19900 columns</p>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"train_categorical.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:29.727786Z","iopub.execute_input":"2025-02-09T04:01:29.728183Z","iopub.status.idle":"2025-02-09T04:01:29.761703Z","shell.execute_reply.started":"2025-02-09T04:01:29.728146Z","shell.execute_reply":"2025-02-09T04:01:29.760347Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\ncount              1213.000000             1213.000000   \nmean               2017.652102                2.014839   \nstd                   1.122522                1.135147   \nmin                2015.000000                1.000000   \n25%                2017.000000                1.000000   \n50%                2018.000000                1.000000   \n75%                2019.000000                3.000000   \nmax                2020.000000                4.000000   \n\n       PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\ncount                       1202.000000                  1213.000000   \nmean                           0.424293                     2.080791   \nstd                            0.687470                     3.164636   \nmin                            0.000000                     0.000000   \n25%                            0.000000                     0.000000   \n50%                            0.000000                     0.000000   \n75%                            1.000000                     2.000000   \nmax                            3.000000                    11.000000   \n\n       MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\ncount              1213.000000             1213.000000   \nmean                  2.288541               17.641385   \nstd                   0.758348                4.004639   \nmin                   0.000000                0.000000   \n25%                   2.000000               15.000000   \n50%                   2.000000               18.000000   \n75%                   3.000000               21.000000   \nmax                   4.000000               21.000000   \n\n       Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  \ncount             1213.000000             1213.000000             1213.000000  \nmean                24.892828               14.122012               24.719703  \nstd                 17.025899                7.201023               17.171113  \nmin                  0.000000                0.000000                0.000000  \n25%                  0.000000               12.000000                5.000000  \n50%                 30.000000               18.000000               30.000000  \n75%                 40.000000               21.000000               40.000000  \nmax                 45.000000               21.000000               45.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1202.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n      <td>1213.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2017.652102</td>\n      <td>2.014839</td>\n      <td>0.424293</td>\n      <td>2.080791</td>\n      <td>2.288541</td>\n      <td>17.641385</td>\n      <td>24.892828</td>\n      <td>14.122012</td>\n      <td>24.719703</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.122522</td>\n      <td>1.135147</td>\n      <td>0.687470</td>\n      <td>3.164636</td>\n      <td>0.758348</td>\n      <td>4.004639</td>\n      <td>17.025899</td>\n      <td>7.201023</td>\n      <td>17.171113</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2015.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2017.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n      <td>12.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2018.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>18.000000</td>\n      <td>30.000000</td>\n      <td>18.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2019.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>21.000000</td>\n      <td>40.000000</td>\n      <td>21.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2020.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>11.000000</td>\n      <td>4.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"train_categorical.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:29.762667Z","iopub.execute_input":"2025-02-09T04:01:29.762934Z","iopub.status.idle":"2025-02-09T04:01:29.769251Z","shell.execute_reply.started":"2025-02-09T04:01:29.762911Z","shell.execute_reply":"2025-02-09T04:01:29.767935Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"Index(['participant_id', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n       'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n       'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu',\n       'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu',\n       'Barratt_Barratt_P2_Occ'],\n      dtype='object')"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"train_categorical.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:29.772690Z","iopub.execute_input":"2025-02-09T04:01:29.772994Z","iopub.status.idle":"2025-02-09T04:01:29.796280Z","shell.execute_reply.started":"2025-02-09T04:01:29.772969Z","shell.execute_reply":"2025-02-09T04:01:29.795093Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"  participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n0   UmrK0vMLopoR                     2016                       1   \n1   CPaeQkhcjg7d                     2019                       3   \n2   Nb4EetVPm3gs                     2016                       1   \n3   p4vPhVu91o4b                     2018                       3   \n4   M09PXs7arQ5E                     2019                       3   \n\n   PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n0                               0.0                            0   \n1                               1.0                            2   \n2                               1.0                            8   \n3                               0.0                            8   \n4                               0.0                            1   \n\n   MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n0                        1                      21                      45   \n1                        3                      15                      15   \n2                        1                      18                      40   \n3                        3                      15                      30   \n4                        3                      15                      20   \n\n   Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  \n0                      21                      45  \n1                       0                       0  \n2                       0                       0  \n3                      18                       0  \n4                       0                       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UmrK0vMLopoR</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>45</td>\n      <td>21</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CPaeQkhcjg7d</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nb4EetVPm3gs</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>18</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p4vPhVu91o4b</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>15</td>\n      <td>30</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M09PXs7arQ5E</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"train_categorical = train_categorical.merge(train_connectome, on='participant_id', how = 'left')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:29.798017Z","iopub.execute_input":"2025-02-09T04:01:29.798445Z","iopub.status.idle":"2025-02-09T04:01:30.054545Z","shell.execute_reply.started":"2025-02-09T04:01:29.798398Z","shell.execute_reply":"2025-02-09T04:01:30.053430Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"df_train = train_categorical.merge(train_solutions, on='participant_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.055499Z","iopub.execute_input":"2025-02-09T04:01:30.055769Z","iopub.status.idle":"2025-02-09T04:01:30.315768Z","shell.execute_reply.started":"2025-02-09T04:01:30.055745Z","shell.execute_reply":"2025-02-09T04:01:30.314838Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.316843Z","iopub.execute_input":"2025-02-09T04:01:30.317257Z","iopub.status.idle":"2025-02-09T04:01:30.340128Z","shell.execute_reply.started":"2025-02-09T04:01:30.317208Z","shell.execute_reply":"2025-02-09T04:01:30.338880Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"  participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n0   UmrK0vMLopoR                     2016                       1   \n1   CPaeQkhcjg7d                     2019                       3   \n2   Nb4EetVPm3gs                     2016                       1   \n3   p4vPhVu91o4b                     2018                       3   \n4   M09PXs7arQ5E                     2019                       3   \n\n   PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n0                               0.0                            0   \n1                               1.0                            2   \n2                               1.0                            8   \n3                               0.0                            8   \n4                               0.0                            1   \n\n   MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n0                        1                      21                      45   \n1                        3                      15                      15   \n2                        1                      18                      40   \n3                        3                      15                      30   \n4                        3                      15                      20   \n\n   Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  ...  195throw_198thcolumn  \\\n0                      21                      45  ...             -0.058396   \n1                       0                       0  ...             -0.025624   \n2                       0                       0  ...              0.010771   \n3                      18                       0  ...             -0.007152   \n4                       0                       0  ...             -0.010196   \n\n   195throw_199thcolumn  196throw_197thcolumn  196throw_198thcolumn  \\\n0             -0.041544              0.142806             -0.006377   \n1             -0.031863              0.162011              0.067439   \n2             -0.044341              0.128386              0.047282   \n3              0.032584              0.121726              0.045089   \n4              0.035638              0.074978              0.030579   \n\n   196throw_199thcolumn  197throw_198thcolumn  197throw_199thcolumn  \\\n0              0.108005              0.148327              0.093230   \n1              0.017155              0.088893              0.064094   \n2              0.087678              0.146221             -0.009425   \n3              0.154464              0.106817              0.065336   \n4              0.025640              0.118199              0.112522   \n\n   198throw_199thcolumn  ADHD_Outcome  Sex_F  \n0             -0.004984             1      1  \n1              0.194381             1      0  \n2              0.035150             1      0  \n3              0.234708             1      1  \n4              0.143666             1      1  \n\n[5 rows x 19912 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n      <th>...</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UmrK0vMLopoR</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>45</td>\n      <td>21</td>\n      <td>45</td>\n      <td>...</td>\n      <td>-0.058396</td>\n      <td>-0.041544</td>\n      <td>0.142806</td>\n      <td>-0.006377</td>\n      <td>0.108005</td>\n      <td>0.148327</td>\n      <td>0.093230</td>\n      <td>-0.004984</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CPaeQkhcjg7d</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.025624</td>\n      <td>-0.031863</td>\n      <td>0.162011</td>\n      <td>0.067439</td>\n      <td>0.017155</td>\n      <td>0.088893</td>\n      <td>0.064094</td>\n      <td>0.194381</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nb4EetVPm3gs</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>18</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.010771</td>\n      <td>-0.044341</td>\n      <td>0.128386</td>\n      <td>0.047282</td>\n      <td>0.087678</td>\n      <td>0.146221</td>\n      <td>-0.009425</td>\n      <td>0.035150</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p4vPhVu91o4b</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>15</td>\n      <td>30</td>\n      <td>18</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.007152</td>\n      <td>0.032584</td>\n      <td>0.121726</td>\n      <td>0.045089</td>\n      <td>0.154464</td>\n      <td>0.106817</td>\n      <td>0.065336</td>\n      <td>0.234708</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M09PXs7arQ5E</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.010196</td>\n      <td>0.035638</td>\n      <td>0.074978</td>\n      <td>0.030579</td>\n      <td>0.025640</td>\n      <td>0.118199</td>\n      <td>0.112522</td>\n      <td>0.143666</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19912 columns</p>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"# Repeating same for the test datasets","metadata":{}},{"cell_type":"code","source":"test_quantitative = test_quantitative.merge(test_categorical, on='participant_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.341205Z","iopub.execute_input":"2025-02-09T04:01:30.341625Z","iopub.status.idle":"2025-02-09T04:01:30.349967Z","shell.execute_reply.started":"2025-02-09T04:01:30.341573Z","shell.execute_reply":"2025-02-09T04:01:30.348904Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"df_test = test_quantitative.merge(test_connectome, on='participant_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.351138Z","iopub.execute_input":"2025-02-09T04:01:30.351473Z","iopub.status.idle":"2025-02-09T04:01:30.419177Z","shell.execute_reply.started":"2025-02-09T04:01:30.351443Z","shell.execute_reply":"2025-02-09T04:01:30.418322Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.419955Z","iopub.execute_input":"2025-02-09T04:01:30.420201Z","iopub.status.idle":"2025-02-09T04:01:30.445239Z","shell.execute_reply.started":"2025-02-09T04:01:30.420180Z","shell.execute_reply":"2025-02-09T04:01:30.444146Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"  participant_id  EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\n0   Cfwaf5FX7jWK          60.03                  14.0             5.0   \n1   vhGrzmvA3Hjq          86.71                  12.0             3.0   \n2   ULliyEXjy4OV          26.68                  13.0             3.0   \n3   LZfeAb1xMtql          93.38                  13.0             3.0   \n4   EnFOUv0YK1RG         -93.38                  14.0             3.0   \n\n   APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  \\\n0            16.0             41.0             19.0            11.0   \n1            13.0             43.0             18.0            15.0   \n2            14.0             36.0             16.0            14.0   \n3            19.0             41.0             17.0            18.0   \n4            13.0             42.0             19.0            16.0   \n\n   APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  ...  195throw_196thcolumn  \\\n0            26.0                       2.0  ...              0.080423   \n1            28.0                       2.0  ...              0.198009   \n2            25.0                       1.0  ...              0.051319   \n3            27.0                       4.0  ...              0.046183   \n4            28.0                       2.0  ...              0.315734   \n\n   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n0             -0.054581             -0.088163             -0.028574   \n1             -0.000724              0.083122              0.033043   \n2              0.023630             -0.056819              0.117396   \n3             -0.238962              0.121868             -0.260970   \n4              0.002234              0.290791              0.344149   \n\n   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n0              0.444847              0.350149             -0.012601   \n1              0.687497              0.306229              0.717485   \n2              0.576086              0.517831              0.527044   \n3              0.646818              0.594902              0.608156   \n4              0.480214              0.539824              0.447322   \n\n   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n0              0.665750              0.560565              0.555732  \n1              0.461809              0.559632              0.350027  \n2              0.605038              0.609856              0.750987  \n3              0.595459              0.683189              0.542296  \n4              0.293088              0.148529              0.539823  \n\n[5 rows x 19928 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>...</th>\n      <th>195throw_196thcolumn</th>\n      <th>195throw_197thcolumn</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>60.03</td>\n      <td>14.0</td>\n      <td>5.0</td>\n      <td>16.0</td>\n      <td>41.0</td>\n      <td>19.0</td>\n      <td>11.0</td>\n      <td>26.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.080423</td>\n      <td>-0.054581</td>\n      <td>-0.088163</td>\n      <td>-0.028574</td>\n      <td>0.444847</td>\n      <td>0.350149</td>\n      <td>-0.012601</td>\n      <td>0.665750</td>\n      <td>0.560565</td>\n      <td>0.555732</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>86.71</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>13.0</td>\n      <td>43.0</td>\n      <td>18.0</td>\n      <td>15.0</td>\n      <td>28.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.198009</td>\n      <td>-0.000724</td>\n      <td>0.083122</td>\n      <td>0.033043</td>\n      <td>0.687497</td>\n      <td>0.306229</td>\n      <td>0.717485</td>\n      <td>0.461809</td>\n      <td>0.559632</td>\n      <td>0.350027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>26.68</td>\n      <td>13.0</td>\n      <td>3.0</td>\n      <td>14.0</td>\n      <td>36.0</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>25.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.051319</td>\n      <td>0.023630</td>\n      <td>-0.056819</td>\n      <td>0.117396</td>\n      <td>0.576086</td>\n      <td>0.517831</td>\n      <td>0.527044</td>\n      <td>0.605038</td>\n      <td>0.609856</td>\n      <td>0.750987</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>93.38</td>\n      <td>13.0</td>\n      <td>3.0</td>\n      <td>19.0</td>\n      <td>41.0</td>\n      <td>17.0</td>\n      <td>18.0</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.046183</td>\n      <td>-0.238962</td>\n      <td>0.121868</td>\n      <td>-0.260970</td>\n      <td>0.646818</td>\n      <td>0.594902</td>\n      <td>0.608156</td>\n      <td>0.595459</td>\n      <td>0.683189</td>\n      <td>0.542296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>-93.38</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>13.0</td>\n      <td>42.0</td>\n      <td>19.0</td>\n      <td>16.0</td>\n      <td>28.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.315734</td>\n      <td>0.002234</td>\n      <td>0.290791</td>\n      <td>0.344149</td>\n      <td>0.480214</td>\n      <td>0.539824</td>\n      <td>0.447322</td>\n      <td>0.293088</td>\n      <td>0.148529</td>\n      <td>0.539823</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19928 columns</p>\n</div>"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.446420Z","iopub.execute_input":"2025-02-09T04:01:30.446691Z","iopub.status.idle":"2025-02-09T04:01:30.463960Z","shell.execute_reply.started":"2025-02-09T04:01:30.446667Z","shell.execute_reply":"2025-02-09T04:01:30.463013Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"((1213, 19912), (304, 19928))"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.set_index('participant_id', inplace = True)\ndf_test.set_index('participant_id', inplace = True)\ntargets = ['ADHD_Outcome', 'Sex_F']\nfeatures = df_test.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.465114Z","iopub.execute_input":"2025-02-09T04:01:30.465531Z","iopub.status.idle":"2025-02-09T04:01:30.485544Z","shell.execute_reply.started":"2025-02-09T04:01:30.465489Z","shell.execute_reply":"2025-02-09T04:01:30.484274Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n# !pip install ydata-profiling","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.486534Z","iopub.execute_input":"2025-02-09T04:01:30.486857Z","iopub.status.idle":"2025-02-09T04:01:30.492588Z","shell.execute_reply.started":"2025-02-09T04:01:30.486819Z","shell.execute_reply":"2025-02-09T04:01:30.491581Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# import ydata_profiling as yp\n# profile = yp.ProfileReport(df_train)\n# profile.to_notebook_iframe()\n# profile.to_file('eda_report.html')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.493654Z","iopub.execute_input":"2025-02-09T04:01:30.493983Z","iopub.status.idle":"2025-02-09T04:01:30.510492Z","shell.execute_reply.started":"2025-02-09T04:01:30.493922Z","shell.execute_reply":"2025-02-09T04:01:30.509359Z"}},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":"## Key Findings\n\n### High Correlations\n\n- ADHD_Outcome is highly correlated with SDQ_SDQ_Externalizing and other fields.\n\n- APQ_P_APQ_P_INV is highly correlated with APQ_P_APQ_P_PP.\n\n- APQ_P_APQ_P_PM is highly correlated with MRI_Track_Age_at_Scan.\n\n- SDQ_SDQ_Difficulties_Total has strong correlations with multiple SDQ-related fields.\n\n### Missing Values\n\n- MRI_Track_Age_at_Scan has 360 missing values (29.7%).\n\n### Zero Values\n\n- SDQ_SDQ_Conduct_Problems has 348 zeros (28.7%).\n\n- SDQ_SDQ_Emotional_Problems has 299 zeros (24.6%).\n\n- SDQ_SDQ_Generating_Impact has 204 zeros (16.8%).\n\n### Variable Summary\n\n#### Categorical Variables\n\n- participant_id: Unique identifier (100% distinct).\n\n- ADHD_Outcome: Binary variable (1: 831, 0: 382).\n\n- Sex_F: Binary variable (0: 797, 1: 416).\n\n#### Numerical Variables\n\n- EHQ_EHQ_Total: Mean = 58.88, Min = -100, Max = 100, 12% negative values.\n\n- ColorVision_CV_Score: Mean = 13.16, Min = 0, Max = 14.\n\n- APQ_P_APQ_P_CP: Mean = 3.78, Min = 0, Max = 12.\n\n- SDQ_SDQ_Conduct_Problems: Mean = 2.06, Min = 0, Max = 10, 28.7% zeros.\n\n- SDQ_SDQ_Difficulties_Total: Mean = 12.12, Min = 0, Max = 34, 1.9% zeros.\n\n- MRI_Track_Age_at_Scan: Mean = 11.24, Min = 0, Max = 21.56, 360 missing values (29.7%).\n\n#### Correlations\n\n- Heatmap analysis shows strong positive correlations between SDQ_SDQ_Difficulties_Total and other SDQ subscales.\n\n- APQ_P_APQ_P_INV and APQ_P_APQ_P_PP show high correlations.\n\n#### Missing Values Visualization\n\nMRI_Track_Age_at_Scan has the highest percentage of missing values.","metadata":{}},{"cell_type":"code","source":"# profile2 = yp.ProfileReport(df_test)\n# profile2.to_notebook_iframe()\n# profile2.to_file('eda_report_test.html')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.511575Z","iopub.execute_input":"2025-02-09T04:01:30.511955Z","iopub.status.idle":"2025-02-09T04:01:30.530428Z","shell.execute_reply.started":"2025-02-09T04:01:30.511923Z","shell.execute_reply":"2025-02-09T04:01:30.529172Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# # Select only numeric columns\n# numeric_cols = df_train.select_dtypes(include=['number'])\n\n# # Pearson Correlation (Linear Relationships)\n# plt.figure(figsize=(12, 8))\n# sns.heatmap(numeric_cols.corr(), annot=False, cmap=\"coolwarm\", linewidths=0.5)\n# plt.title(\"Pearson Correlation Heatmap\")\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.531315Z","iopub.execute_input":"2025-02-09T04:01:30.531716Z","iopub.status.idle":"2025-02-09T04:01:30.549526Z","shell.execute_reply.started":"2025-02-09T04:01:30.531678Z","shell.execute_reply":"2025-02-09T04:01:30.548466Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"Let's see how different it's gonna be when combined with the test datasets\n","metadata":{}},{"cell_type":"code","source":"#quant_test = pd.merge(test_categorical, test_quantitative, on='participant_id', how='inner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.550770Z","iopub.execute_input":"2025-02-09T04:01:30.551173Z","iopub.status.idle":"2025-02-09T04:01:30.568086Z","shell.execute_reply.started":"2025-02-09T04:01:30.551134Z","shell.execute_reply":"2025-02-09T04:01:30.566805Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"!pip install sweetviz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:30.569141Z","iopub.execute_input":"2025-02-09T04:01:30.569478Z","iopub.status.idle":"2025-02-09T04:01:34.829022Z","shell.execute_reply.started":"2025-02-09T04:01:30.569451Z","shell.execute_reply":"2025-02-09T04:01:34.827722Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sweetviz in /usr/local/lib/python3.10/dist-packages (2.3.1)\nRequirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (2.2.2)\nRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (1.26.4)\nRequirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (3.7.5)\nRequirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (4.67.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (1.13.1)\nRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (3.1.4)\nRequirement already satisfied: importlib-resources>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (6.4.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.1->sweetviz) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.0->sweetviz) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.0->sweetviz) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.0->sweetviz) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.0->sweetviz) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.0->sweetviz) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.0->sweetviz) (2024.2.0)\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# import sweetviz as sv\n\n# my_report = sv.analyze(df_train)\n# my_report.show_html()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:34.833084Z","iopub.execute_input":"2025-02-09T04:01:34.833443Z","iopub.status.idle":"2025-02-09T04:01:34.838083Z","shell.execute_reply.started":"2025-02-09T04:01:34.833411Z","shell.execute_reply":"2025-02-09T04:01:34.836863Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"## Observations about df_train\n\n","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:34.840419Z","iopub.execute_input":"2025-02-09T04:01:34.840919Z","iopub.status.idle":"2025-02-09T04:01:34.882862Z","shell.execute_reply.started":"2025-02-09T04:01:34.840856Z","shell.execute_reply":"2025-02-09T04:01:34.881629Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"                Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\nparticipant_id                                                    \nUmrK0vMLopoR                       2016                       1   \nCPaeQkhcjg7d                       2019                       3   \nNb4EetVPm3gs                       2016                       1   \np4vPhVu91o4b                       2018                       3   \nM09PXs7arQ5E                       2019                       3   \n\n                PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\nparticipant_id                                                                  \nUmrK0vMLopoR                                 0.0                            0   \nCPaeQkhcjg7d                                 1.0                            2   \nNb4EetVPm3gs                                 1.0                            8   \np4vPhVu91o4b                                 0.0                            8   \nM09PXs7arQ5E                                 0.0                            1   \n\n                MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\nparticipant_id                                                    \nUmrK0vMLopoR                          1                      21   \nCPaeQkhcjg7d                          3                      15   \nNb4EetVPm3gs                          1                      18   \np4vPhVu91o4b                          3                      15   \nM09PXs7arQ5E                          3                      15   \n\n                Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  \\\nparticipant_id                                                   \nUmrK0vMLopoR                        45                      21   \nCPaeQkhcjg7d                        15                       0   \nNb4EetVPm3gs                        40                       0   \np4vPhVu91o4b                        30                      18   \nM09PXs7arQ5E                        20                       0   \n\n                Barratt_Barratt_P2_Occ  0throw_1thcolumn  ...  \\\nparticipant_id                                            ...   \nUmrK0vMLopoR                        45         -0.039820  ...   \nCPaeQkhcjg7d                         0          0.114480  ...   \nNb4EetVPm3gs                         0          0.226402  ...   \np4vPhVu91o4b                         0          0.060679  ...   \nM09PXs7arQ5E                         0          0.056123  ...   \n\n                195throw_198thcolumn  195throw_199thcolumn  \\\nparticipant_id                                               \nUmrK0vMLopoR               -0.058396             -0.041544   \nCPaeQkhcjg7d               -0.025624             -0.031863   \nNb4EetVPm3gs                0.010771             -0.044341   \np4vPhVu91o4b               -0.007152              0.032584   \nM09PXs7arQ5E               -0.010196              0.035638   \n\n                196throw_197thcolumn  196throw_198thcolumn  \\\nparticipant_id                                               \nUmrK0vMLopoR                0.142806             -0.006377   \nCPaeQkhcjg7d                0.162011              0.067439   \nNb4EetVPm3gs                0.128386              0.047282   \np4vPhVu91o4b                0.121726              0.045089   \nM09PXs7arQ5E                0.074978              0.030579   \n\n                196throw_199thcolumn  197throw_198thcolumn  \\\nparticipant_id                                               \nUmrK0vMLopoR                0.108005              0.148327   \nCPaeQkhcjg7d                0.017155              0.088893   \nNb4EetVPm3gs                0.087678              0.146221   \np4vPhVu91o4b                0.154464              0.106817   \nM09PXs7arQ5E                0.025640              0.118199   \n\n                197throw_199thcolumn  198throw_199thcolumn  ADHD_Outcome  \\\nparticipant_id                                                             \nUmrK0vMLopoR                0.093230             -0.004984             1   \nCPaeQkhcjg7d                0.064094              0.194381             1   \nNb4EetVPm3gs               -0.009425              0.035150             1   \np4vPhVu91o4b                0.065336              0.234708             1   \nM09PXs7arQ5E                0.112522              0.143666             1   \n\n                Sex_F  \nparticipant_id         \nUmrK0vMLopoR        1  \nCPaeQkhcjg7d        0  \nNb4EetVPm3gs        0  \np4vPhVu91o4b        1  \nM09PXs7arQ5E        1  \n\n[5 rows x 19911 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n      <th>0throw_1thcolumn</th>\n      <th>...</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>UmrK0vMLopoR</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>45</td>\n      <td>21</td>\n      <td>45</td>\n      <td>-0.039820</td>\n      <td>...</td>\n      <td>-0.058396</td>\n      <td>-0.041544</td>\n      <td>0.142806</td>\n      <td>-0.006377</td>\n      <td>0.108005</td>\n      <td>0.148327</td>\n      <td>0.093230</td>\n      <td>-0.004984</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>CPaeQkhcjg7d</th>\n      <td>2019</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.114480</td>\n      <td>...</td>\n      <td>-0.025624</td>\n      <td>-0.031863</td>\n      <td>0.162011</td>\n      <td>0.067439</td>\n      <td>0.017155</td>\n      <td>0.088893</td>\n      <td>0.064094</td>\n      <td>0.194381</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Nb4EetVPm3gs</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>18</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.226402</td>\n      <td>...</td>\n      <td>0.010771</td>\n      <td>-0.044341</td>\n      <td>0.128386</td>\n      <td>0.047282</td>\n      <td>0.087678</td>\n      <td>0.146221</td>\n      <td>-0.009425</td>\n      <td>0.035150</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>p4vPhVu91o4b</th>\n      <td>2018</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>15</td>\n      <td>30</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0.060679</td>\n      <td>...</td>\n      <td>-0.007152</td>\n      <td>0.032584</td>\n      <td>0.121726</td>\n      <td>0.045089</td>\n      <td>0.154464</td>\n      <td>0.106817</td>\n      <td>0.065336</td>\n      <td>0.234708</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>M09PXs7arQ5E</th>\n      <td>2019</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.056123</td>\n      <td>...</td>\n      <td>-0.010196</td>\n      <td>0.035638</td>\n      <td>0.074978</td>\n      <td>0.030579</td>\n      <td>0.025640</td>\n      <td>0.118199</td>\n      <td>0.112522</td>\n      <td>0.143666</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19911 columns</p>\n</div>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"X = df_train.drop(targets, axis = 1)\ny = train_solutions[targets]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:34.883981Z","iopub.execute_input":"2025-02-09T04:01:34.884445Z","iopub.status.idle":"2025-02-09T04:01:34.958363Z","shell.execute_reply.started":"2025-02-09T04:01:34.884403Z","shell.execute_reply":"2025-02-09T04:01:34.957162Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.metrics import f1_score, classification_report\n\n# Get all numeric columns for imputation\nnumeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=0.3, \n                                                    random_state=42,\n                                                    stratify=y)\n\n# Create the pipeline\nmodel = MultiOutputClassifier(make_pipeline(\n    ColumnTransformer([\n        ('imputer', SimpleImputer(strategy='mean'), numeric_features)\n    ],\n    remainder='passthrough',\n    verbose_feature_names_out=False).set_output(transform='pandas'),\n    \n    MinMaxScaler(),    \n    \n    RidgeClassifier(alpha=100, class_weight='balanced')\n))\n\n# Fit and evaluate\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# Evaluate each output separately\nfor i, column in enumerate(y.columns):\n    print(f'\\nMetrics for {column}:')\n    print(classification_report(y_test.iloc[:, i], y_pred[:, i]))\n    \n    # Calculate and print F1 score\n    f1 = f1_score(y_test.iloc[:, i], y_pred[:, i], average='binary')\n    print(f'F1 Score for {column}: {f1:.3f}')\n    \n    # Print confusion matrix\n    from sklearn.metrics import confusion_matrix\n    cm = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n    print(f'\\nConfusion Matrix for {column}:')\n    print(cm)\n\n\n# Make predictions on test set\ntest_predictions = model.predict(df_test)\n\n# Create submission dataframe\nsubmission = pd.DataFrame(\n    test_predictions, \n    columns=['ADHD_Outcome', 'Sex_F'],\n    index=df_test.index\n)\n\n# Save predictions\nsubmission.to_csv('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:18:08.019340Z","iopub.execute_input":"2025-02-09T04:18:08.019700Z","iopub.status.idle":"2025-02-09T04:18:15.343619Z","shell.execute_reply.started":"2025-02-09T04:18:08.019672Z","shell.execute_reply":"2025-02-09T04:18:15.342701Z"}},"outputs":[{"name":"stdout","text":"\nMetrics for ADHD_Outcome:\n              precision    recall  f1-score   support\n\n           0       0.45      0.08      0.13       115\n           1       0.69      0.96      0.80       249\n\n    accuracy                           0.68       364\n   macro avg       0.57      0.52      0.47       364\nweighted avg       0.62      0.68      0.59       364\n\nF1 Score for ADHD_Outcome: 0.803\n\nConfusion Matrix for ADHD_Outcome:\n[[  9 106]\n [ 11 238]]\n\nMetrics for Sex_F:\n              precision    recall  f1-score   support\n\n           0       0.73      0.96      0.83       239\n           1       0.80      0.31      0.45       125\n\n    accuracy                           0.74       364\n   macro avg       0.76      0.64      0.64       364\nweighted avg       0.75      0.74      0.70       364\n\nF1 Score for Sex_F: 0.448\n\nConfusion Matrix for Sex_F:\n[[229  10]\n [ 86  39]]\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"print('f1: ', f1_score(y_test,y_pred,average='micro'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T04:01:41.264125Z","iopub.execute_input":"2025-02-09T04:01:41.264501Z","iopub.status.idle":"2025-02-09T04:01:41.275681Z","shell.execute_reply.started":"2025-02-09T04:01:41.264474Z","shell.execute_reply":"2025-02-09T04:01:41.274750Z"}},"outputs":[{"name":"stdout","text":"f1:  0.7222946544980443\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"my_report_train = sv.analyze(quant_trained)\nmy_report_train.show_html()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:07:20.031192Z","iopub.execute_input":"2025-02-09T01:07:20.031595Z","iopub.status.idle":"2025-02-09T01:07:32.529019Z","shell.execute_reply.started":"2025-02-09T01:07:20.031551Z","shell.execute_reply":"2025-02-09T01:07:32.527946Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                             |          | [  0%]   00:00 -> (? left)","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf3574f5bc854530836a6b7a3c239c61"}},"metadata":{}},{"name":"stdout","text":"Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"From the sweetviz, we have the followoing observations: \n## Dataset Structure\n- 304 rows, 28 features\n- 13 categorical, 14 numerical, and 1 text column\n- No duplicates detected\n- Certain variables have missing values (e.g., Barratt_Barratt_P2_Edu and MRI_Track_Age_at_Scan)\n\n## Missing Values\n\n- 10% missing in some SDQ-related variables\n- 14% missing in Barratt_Barratt_P2_Occ\n- 5% missing in APQ_P features\n- 3% missing in ColorVision_CV_Score","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:07:57.936165Z","iopub.execute_input":"2025-02-09T01:07:57.936527Z","iopub.status.idle":"2025-02-09T01:07:58.400580Z","shell.execute_reply.started":"2025-02-09T01:07:57.936500Z","shell.execute_reply":"2025-02-09T01:07:58.399235Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_categorical.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:10:31.794195Z","iopub.execute_input":"2025-02-09T01:10:31.794611Z","iopub.status.idle":"2025-02-09T01:10:31.807603Z","shell.execute_reply.started":"2025-02-09T01:10:31.794580Z","shell.execute_reply":"2025-02-09T01:10:31.806520Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"  participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n0   UmrK0vMLopoR                     2016                       1   \n1   CPaeQkhcjg7d                     2019                       3   \n2   Nb4EetVPm3gs                     2016                       1   \n3   p4vPhVu91o4b                     2018                       3   \n4   M09PXs7arQ5E                     2019                       3   \n\n   PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n0                               0.0                            0   \n1                               1.0                            2   \n2                               1.0                            8   \n3                               0.0                            8   \n4                               0.0                            1   \n\n   MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n0                        1                      21                      45   \n1                        3                      15                      15   \n2                        1                      18                      40   \n3                        3                      15                      30   \n4                        3                      15                      20   \n\n   Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  \n0                      21                      45  \n1                       0                       0  \n2                       0                       0  \n3                      18                       0  \n4                       0                       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UmrK0vMLopoR</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21</td>\n      <td>45</td>\n      <td>21</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CPaeQkhcjg7d</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>15</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nb4EetVPm3gs</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>18</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p4vPhVu91o4b</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>15</td>\n      <td>30</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M09PXs7arQ5E</td>\n      <td>2019</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"train_categorical.shape, test_categorical.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:12:12.410654Z","iopub.execute_input":"2025-02-09T01:12:12.411138Z","iopub.status.idle":"2025-02-09T01:12:12.416937Z","shell.execute_reply.started":"2025-02-09T01:12:12.411105Z","shell.execute_reply":"2025-02-09T01:12:12.415798Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"((1213, 10), (304, 10))"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"There are errors encountered in displaying the test_categorical","metadata":{}},{"cell_type":"code","source":"test_categorical.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:19:02.192884Z","iopub.execute_input":"2025-02-09T01:19:02.193296Z","iopub.status.idle":"2025-02-09T01:19:02.225071Z","shell.execute_reply.started":"2025-02-09T01:19:02.193263Z","shell.execute_reply":"2025-02-09T01:19:02.223947Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\ncount               304.000000              304.000000   \nmean               2022.197368                4.009868   \nstd                   0.494718                0.099012   \nmin                2019.000000                4.000000   \n25%                2022.000000                4.000000   \n50%                2022.000000                4.000000   \n75%                2022.000000                4.000000   \nmax                2023.000000                5.000000   \n\n       PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\ncount                        301.000000                   298.000000   \nmean                           0.355482                     2.231544   \nstd                            0.665741                     3.392914   \nmin                            0.000000                     0.000000   \n25%                            0.000000                     0.000000   \n50%                            0.000000                     0.000000   \n75%                            1.000000                     3.000000   \nmax                            3.000000                    11.000000   \n\n       MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\ncount               304.000000              303.000000   \nmean                  3.638158               19.128713   \nstd                   0.481326                2.680553   \nmin                   3.000000                3.000000   \n25%                   3.000000               18.000000   \n50%                   4.000000               21.000000   \n75%                   4.000000               21.000000   \nmax                   4.000000               21.000000   \n\n       Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  \ncount              303.000000              268.000000              262.000000  \nmean                29.389439               18.458955               35.763359  \nstd                 16.484193                3.087093               11.978162  \nmin                  0.000000                3.000000                0.000000  \n25%                 25.000000               18.000000               30.000000  \n50%                 35.000000               18.000000               40.000000  \n75%                 45.000000               21.000000               45.000000  \nmax                 45.000000               21.000000               45.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>304.000000</td>\n      <td>304.000000</td>\n      <td>301.000000</td>\n      <td>298.000000</td>\n      <td>304.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>268.000000</td>\n      <td>262.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2022.197368</td>\n      <td>4.009868</td>\n      <td>0.355482</td>\n      <td>2.231544</td>\n      <td>3.638158</td>\n      <td>19.128713</td>\n      <td>29.389439</td>\n      <td>18.458955</td>\n      <td>35.763359</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.494718</td>\n      <td>0.099012</td>\n      <td>0.665741</td>\n      <td>3.392914</td>\n      <td>0.481326</td>\n      <td>2.680553</td>\n      <td>16.484193</td>\n      <td>3.087093</td>\n      <td>11.978162</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2019.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2022.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>18.000000</td>\n      <td>25.000000</td>\n      <td>18.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2022.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>21.000000</td>\n      <td>35.000000</td>\n      <td>18.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2022.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2023.000000</td>\n      <td>5.000000</td>\n      <td>3.000000</td>\n      <td>11.000000</td>\n      <td>4.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n      <td>21.000000</td>\n      <td>45.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"Checking for null values: ","metadata":{}},{"cell_type":"code","source":"quant_trained","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T01:20:15.234316Z","iopub.execute_input":"2025-02-09T01:20:15.234731Z","iopub.status.idle":"2025-02-09T01:20:15.281635Z","shell.execute_reply.started":"2025-02-09T01:20:15.234629Z","shell.execute_reply":"2025-02-09T01:20:15.280645Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0mrepr_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe_repr_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrepr_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             )\n\u001b[0;32m-> 1394\u001b[0;31m             return fmt.DataFrameRenderer(formatter).to_string(\n\u001b[0m\u001b[1;32m   1395\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mstring_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_string_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{text}{self.fmt.dimensions_info}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_string_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_empty_info_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_width\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_dot_separators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols_without_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_strcols_without_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             )\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m             fmt_values = _make_fixed_width(\n\u001b[1;32m    742\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_colwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting, fallback_formatter)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result_as_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         \u001b[0;31m# large values: more that 8 characters including decimal symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;31m# and first digit, hence > 1e6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m         \u001b[0mhas_large_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0mhas_small_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFloatingPointError\u001b[0m: invalid value encountered in greater"],"ename":"FloatingPointError","evalue":"invalid value encountered in greater","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             )\n\u001b[0;32m-> 1256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrameRenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self, buf, encoding, classes, notebook, border, table_id, render_links)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mrender_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         )\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_table\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</table>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_body\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_write_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<tbody>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;31m# write values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_get_formatted_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_columns_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_columns_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting, fallback_formatter)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result_as_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         \u001b[0;31m# large values: more that 8 characters including decimal symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;31m# and first digit, hence > 1e6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m         \u001b[0mhas_large_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0mhas_small_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs_vals\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFloatingPointError\u001b[0m: invalid value encountered in greater"],"ename":"FloatingPointError","evalue":"invalid value encountered in greater","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"# Convert categorical features to dummy variables for both training and test sets.\n# We use drop_first=True to avoid multicollinearity.\ntrain_cat_processed = pd.get_dummies(train_categorical, drop_first=True)\ntest_cat_processed = pd.get_dummies(test_categorical, drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:23.952295Z","iopub.execute_input":"2025-02-08T21:24:23.952682Z","iopub.status.idle":"2025-02-08T21:24:23.966323Z","shell.execute_reply.started":"2025-02-08T21:24:23.952642Z","shell.execute_reply":"2025-02-08T21:24:23.965287Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Ensure that both train and test have the same dummy columns.\ntrain_cat_processed, test_cat_processed = train_cat_processed.align(test_cat_processed, join='outer', axis=1, fill_value=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:23.967403Z","iopub.execute_input":"2025-02-08T21:24:23.967917Z","iopub.status.idle":"2025-02-08T21:24:23.977724Z","shell.execute_reply.started":"2025-02-08T21:24:23.967876Z","shell.execute_reply":"2025-02-08T21:24:23.976662Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_cat_processed.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:23.978679Z","iopub.execute_input":"2025-02-08T21:24:23.978923Z","iopub.status.idle":"2025-02-08T21:24:23.992116Z","shell.execute_reply.started":"2025-02-08T21:24:23.978901Z","shell.execute_reply":"2025-02-08T21:24:23.991102Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Index(['Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ',\n       'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ',\n       'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n       'MRI_Track_Scan_Location', 'PreInt_Demos_Fam_Child_Ethnicity',\n       'PreInt_Demos_Fam_Child_Race', 'participant_id_00fV0OyyoLfw',\n       ...\n       'participant_id_zWzLCi3NTBTd', 'participant_id_zeR6IKf0gn1Z',\n       'participant_id_zlT4AqBGFiGv', 'participant_id_zmxGvIrOD0bt',\n       'participant_id_zoCHkxMZDLeD', 'participant_id_zpU7rEseBMH8',\n       'participant_id_zpr8w4jCfVPe', 'participant_id_zwBG0rZ05Mcb',\n       'participant_id_zwXD5v17Rx01', 'participant_id_zwjJWCRzKhDz'],\n      dtype='object', length=1524)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def process_categorical(df, id_col='participant_id'):\n    # Check if the identifier exists and separate it\n    if id_col in df.columns:\n        ids = df[[id_col]]\n        df_features = df.drop(columns=[id_col])\n    else:\n        ids = pd.DataFrame()\n        df_features = df\n    # One-hot encode the remaining categorical features\n    df_dummies = pd.get_dummies(df_features, drop_first=True)\n    # Reattach the participant_id column if it was present\n    if not ids.empty:\n        df_processed = pd.concat([ids.reset_index(drop=True), df_dummies.reset_index(drop=True)], axis=1)\n    else:\n        df_processed = df_dummies\n    return df_processed\n\n# Process the categorical data for both train and test sets\ntrain_cat_processed = process_categorical(train_categorical)\ntest_cat_processed = process_categorical(test_categorical)\n\n# Now perform the merge using the participant_id key\nfinal_train_meta = pd.merge(quant_trained, train_cat_processed, on='participant_id', how='left')\nfinal_test_meta = pd.merge(quant_test, test_cat_processed, on='participant_id', how='left')\n\nprint(\"final_train_meta shape:\", final_train_meta.shape)\nprint(\"final_test_meta shape:\", final_test_meta.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:23.993040Z","iopub.execute_input":"2025-02-08T21:24:23.993389Z","iopub.status.idle":"2025-02-08T21:24:24.021597Z","shell.execute_reply.started":"2025-02-08T21:24:23.993360Z","shell.execute_reply":"2025-02-08T21:24:24.020423Z"}},"outputs":[{"name":"stdout","text":"final_train_meta shape: (1213, 30)\nfinal_test_meta shape: (304, 37)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Identify numeric columns in training and test metadata\ntrain_numeric_cols = final_train_meta.select_dtypes(include=[np.number]).columns\ntest_numeric_cols  = final_test_meta.select_dtypes(include=[np.number]).columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.022671Z","iopub.execute_input":"2025-02-08T21:24:24.023074Z","iopub.status.idle":"2025-02-08T21:24:24.029115Z","shell.execute_reply.started":"2025-02-08T21:24:24.023036Z","shell.execute_reply":"2025-02-08T21:24:24.028218Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Compute the common numeric columns (we exclude target columns for test, since they won't be there)\ncommon_numeric = list(set(train_numeric_cols).intersection(test_numeric_cols))\nprint(\"Common numeric columns for imputation:\", common_numeric)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.034056Z","iopub.execute_input":"2025-02-08T21:24:24.034387Z","iopub.status.idle":"2025-02-08T21:24:24.042700Z","shell.execute_reply.started":"2025-02-08T21:24:24.034360Z","shell.execute_reply":"2025-02-08T21:24:24.041740Z"}},"outputs":[{"name":"stdout","text":"Common numeric columns for imputation: ['SDQ_SDQ_Externalizing', 'SDQ_SDQ_Hyperactivity', 'APQ_P_APQ_P_INV', 'SDQ_SDQ_Internalizing', 'APQ_P_APQ_P_CP', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Prosocial', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'SDQ_SDQ_Difficulties_Total', 'MRI_Track_Age_at_Scan', 'EHQ_EHQ_Total', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Generating_Impact', 'ColorVision_CV_Score', 'SDQ_SDQ_Conduct_Problems', 'APQ_P_APQ_P_PP']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Create an imputer using the mean strategy\nimputer = SimpleImputer(strategy='mean')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.044871Z","iopub.execute_input":"2025-02-08T21:24:24.045187Z","iopub.status.idle":"2025-02-08T21:24:24.057953Z","shell.execute_reply.started":"2025-02-08T21:24:24.045143Z","shell.execute_reply":"2025-02-08T21:24:24.056934Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Fit the imputer on the common numeric columns from the training data\nfinal_train_meta[common_numeric] = imputer.fit_transform(final_train_meta[common_numeric])\n# Use the same columns from the test metadata for transformation\nfinal_test_meta[common_numeric] = imputer.transform(final_test_meta[common_numeric])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.059043Z","iopub.execute_input":"2025-02-08T21:24:24.059404Z","iopub.status.idle":"2025-02-08T21:24:24.083971Z","shell.execute_reply.started":"2025-02-08T21:24:24.059367Z","shell.execute_reply":"2025-02-08T21:24:24.082952Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_conn_features = train_connectome.drop(['participant_id'], axis=1)\ntest_conn_features = test_connectome.drop(['participant_id'], axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.084948Z","iopub.execute_input":"2025-02-08T21:24:24.085300Z","iopub.status.idle":"2025-02-08T21:24:24.196436Z","shell.execute_reply.started":"2025-02-08T21:24:24.085265Z","shell.execute_reply":"2025-02-08T21:24:24.195574Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Standardize the connectome features\nscaler = StandardScaler()\ntrain_conn_scaled = scaler.fit_transform(train_conn_features)\ntest_conn_scaled  = scaler.transform(test_conn_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:24.197326Z","iopub.execute_input":"2025-02-08T21:24:24.197583Z","iopub.status.idle":"2025-02-08T21:24:25.261799Z","shell.execute_reply.started":"2025-02-08T21:24:24.197556Z","shell.execute_reply":"2025-02-08T21:24:25.260884Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"pca = PCA().fit(train_conn_scaled)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:25.262783Z","iopub.execute_input":"2025-02-08T21:24:25.263248Z","iopub.status.idle":"2025-02-08T21:24:41.788961Z","shell.execute_reply.started":"2025-02-08T21:24:25.263208Z","shell.execute_reply":"2025-02-08T21:24:41.787814Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Text(0, 0.5, 'cumulative explained variance')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"pca = PCA().fit(train_conn_scaled)\n\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 1214, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 1213, step=100)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:41.790012Z","iopub.execute_input":"2025-02-08T21:24:41.790386Z","iopub.status.idle":"2025-02-08T21:24:58.700355Z","shell.execute_reply.started":"2025-02-08T21:24:41.790358Z","shell.execute_reply":"2025-02-08T21:24:58.699288Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"n_components = 500\npca = PCA(n_components=n_components)\ntrain_conn_pca = pca.fit_transform(train_conn_scaled)\ntest_conn_pca  = pca.transform(test_conn_scaled)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:24:58.701358Z","iopub.execute_input":"2025-02-08T21:24:58.701635Z","iopub.status.idle":"2025-02-08T21:25:05.095754Z","shell.execute_reply.started":"2025-02-08T21:24:58.701611Z","shell.execute_reply":"2025-02-08T21:25:05.094642Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"!pip install plotly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:05.096967Z","iopub.execute_input":"2025-02-08T21:25:05.097366Z","iopub.status.idle":"2025-02-08T21:25:09.280658Z","shell.execute_reply.started":"2025-02-08T21:25:05.097328Z","shell.execute_reply":"2025-02-08T21:25:09.279518Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.io as pio\n\npio.renderers.default = \"iframe\"  # You can also try \"notebook_connected\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:09.281960Z","iopub.execute_input":"2025-02-08T21:25:09.282320Z","iopub.status.idle":"2025-02-08T21:25:10.444088Z","shell.execute_reply.started":"2025-02-08T21:25:09.282288Z","shell.execute_reply":"2025-02-08T21:25:10.443139Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"total_var = pca.explained_variance_ratio_.sum() * 100\nprint(total_var)\n\nfig = px.scatter(train_conn_pca, x=0, y=2)\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:10.445237Z","iopub.execute_input":"2025-02-08T21:25:10.445633Z","iopub.status.idle":"2025-02-08T21:25:12.121168Z","shell.execute_reply.started":"2025-02-08T21:25:10.445591Z","shell.execute_reply":"2025-02-08T21:25:12.120250Z"}},"outputs":[{"name":"stdout","text":"54.20043630705086\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_36.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"!pip install lazypredict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:12.257544Z","iopub.execute_input":"2025-02-08T21:25:12.258004Z","iopub.status.idle":"2025-02-08T21:25:16.758638Z","shell.execute_reply.started":"2025-02-08T21:25:12.257935Z","shell.execute_reply":"2025-02-08T21:25:16.757364Z"}},"outputs":[{"name":"stdout","text":"Collecting lazypredict\n  Downloading lazypredict-0.2.13-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.67.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.5.0)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.0.3)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.13.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->lightgbm->lazypredict) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->lightgbm->lazypredict) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->lightgbm->lazypredict) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->lightgbm->lazypredict) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.0->lightgbm->lazypredict) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.0->lightgbm->lazypredict) (2024.2.0)\nDownloading lazypredict-0.2.13-py2.py3-none-any.whl (12 kB)\nInstalling collected packages: lazypredict\nSuccessfully installed lazypredict-0.2.13\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:16.759891Z","iopub.execute_input":"2025-02-08T21:25:16.760257Z","iopub.status.idle":"2025-02-08T21:25:21.639328Z","shell.execute_reply.started":"2025-02-08T21:25:16.760216Z","shell.execute_reply":"2025-02-08T21:25:21.638121Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"n_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=77)\nresults = []\n\n# Use only the ADHD_Outcome column for stratification\nfor train_index, test_index in skf.split(X_train, y_train['ADHD_Outcome']):\n    X_train_t, X_test_t = X_train.iloc[train_index], X_train.iloc[test_index]\n    y_train_t, y_test_t = y_train['ADHD_Outcome'].iloc[train_index], y_train['ADHD_Outcome'].iloc[test_index]\n\n    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n    models, predictions = clf.fit(X_train_t, X_test_t, y_train_t, y_test_t)\n    results.append(models)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:25:21.640260Z","iopub.execute_input":"2025-02-08T21:25:21.641073Z","iopub.status.idle":"2025-02-08T21:27:13.246668Z","shell.execute_reply.started":"2025-02-08T21:25:21.641041Z","shell.execute_reply":"2025-02-08T21:27:13.245593Z"}},"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [00:18<00:00,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 664, number of negative: 306\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128213\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.684536 -> initscore=0.774697\n[LightGBM] [Info] Start training from score 0.774697\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.36it/s]\n 97%|█████████▋| 28/29 [00:19<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 665, number of negative: 305\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007815 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128215\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.685567 -> initscore=0.779475\n[LightGBM] [Info] Start training from score 0.779475\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:22<00:00,  1.29it/s]\n 97%|█████████▋| 28/29 [00:20<00:01,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 665, number of negative: 305\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128210\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.685567 -> initscore=0.779475\n[LightGBM] [Info] Start training from score 0.779475\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:23<00:00,  1.26it/s]\n 97%|█████████▋| 28/29 [00:20<00:00,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 665, number of negative: 306\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128216\n[LightGBM] [Info] Number of data points in the train set: 971, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.684861 -> initscore=0.776202\n[LightGBM] [Info] Start training from score 0.776202\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:23<00:00,  1.25it/s]\n 97%|█████████▋| 28/29 [00:18<00:00,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 665, number of negative: 306\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128213\n[LightGBM] [Info] Number of data points in the train set: 971, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.684861 -> initscore=0.776202\n[LightGBM] [Info] Start training from score 0.776202\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.35it/s]\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"metrics_df = pd.concat(results)\nmetrics_summary = metrics_df.groupby(metrics_df.index).agg(['mean', 'std'])\nmetrics_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:27:13.247574Z","iopub.execute_input":"2025-02-08T21:27:13.247857Z","iopub.status.idle":"2025-02-08T21:27:13.277874Z","shell.execute_reply.started":"2025-02-08T21:27:13.247830Z","shell.execute_reply":"2025-02-08T21:27:13.276824Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                              Accuracy      Balanced Accuracy      ROC AUC  \\\n                                  mean  std              mean  std    mean   \nModel                                                                        \nAdaBoostClassifier                0.76 0.03              0.71 0.04    0.71   \nBaggingClassifier                 0.78 0.03              0.73 0.03    0.73   \nBernoulliNB                       0.72 0.04              0.71 0.05    0.71   \nCalibratedClassifierCV            0.71 0.01              0.55 0.02    0.55   \nDecisionTreeClassifier            0.72 0.02              0.67 0.03    0.67   \nDummyClassifier                   0.69 0.00              0.50 0.00    0.50   \nExtraTreeClassifier               0.69 0.05              0.64 0.05    0.64   \nExtraTreesClassifier              0.78 0.01              0.69 0.02    0.69   \nGaussianNB                        0.68 0.02              0.57 0.02    0.57   \nKNeighborsClassifier              0.69 0.01              0.51 0.01    0.51   \nLGBMClassifier                    0.80 0.02              0.74 0.02    0.74   \nLinearDiscriminantAnalysis        0.69 0.04              0.66 0.03    0.66   \nLinearSVC                         0.69 0.04              0.66 0.04    0.66   \nLogisticRegression                0.70 0.04              0.66 0.04    0.66   \nNearestCentroid                   0.73 0.03              0.72 0.03    0.72   \nNuSVC                             0.76 0.02              0.67 0.01    0.67   \nPassiveAggressiveClassifier       0.69 0.04              0.66 0.04    0.66   \nPerceptron                        0.69 0.03              0.65 0.03    0.65   \nQuadraticDiscriminantAnalysis     0.69 0.00              0.50 0.00    0.50   \nRandomForestClassifier            0.79 0.01              0.70 0.02    0.70   \nRidgeClassifier                   0.69 0.04              0.66 0.03    0.66   \nRidgeClassifierCV                 0.69 0.04              0.65 0.03    0.65   \nSGDClassifier                     0.72 0.03              0.65 0.04    0.65   \nSVC                               0.76 0.01              0.64 0.01    0.64   \nXGBClassifier                     0.79 0.01              0.73 0.01    0.73   \n\n                                   F1 Score      Time Taken       \n                               std     mean  std       mean  std  \nModel                                                             \nAdaBoostClassifier            0.04     0.76 0.03       3.49 0.02  \nBaggingClassifier             0.03     0.78 0.03       5.28 0.90  \nBernoulliNB                   0.05     0.73 0.04       0.08 0.01  \nCalibratedClassifierCV        0.02     0.63 0.03       0.99 0.08  \nDecisionTreeClassifier        0.03     0.72 0.02       0.74 0.11  \nDummyClassifier               0.00     0.56 0.00       0.06 0.00  \nExtraTreeClassifier           0.05     0.69 0.04       0.06 0.00  \nExtraTreesClassifier          0.02     0.76 0.01       0.52 0.01  \nGaussianNB                    0.02     0.65 0.02       0.07 0.00  \nKNeighborsClassifier          0.01     0.57 0.01       0.09 0.03  \nLGBMClassifier                0.02     0.79 0.02       2.90 0.04  \nLinearDiscriminantAnalysis    0.03     0.69 0.03       0.19 0.01  \nLinearSVC                     0.04     0.70 0.03       0.48 0.05  \nLogisticRegression            0.04     0.70 0.04       0.09 0.00  \nNearestCentroid               0.03     0.74 0.02       0.06 0.00  \nNuSVC                         0.01     0.74 0.01       0.34 0.00  \nPassiveAggressiveClassifier   0.04     0.70 0.04       0.17 0.01  \nPerceptron                    0.03     0.69 0.03       0.09 0.01  \nQuadraticDiscriminantAnalysis 0.00     0.56 0.00       0.18 0.00  \nRandomForestClassifier        0.02     0.77 0.02       2.06 0.05  \nRidgeClassifier               0.03     0.70 0.03       0.08 0.00  \nRidgeClassifierCV             0.03     0.69 0.03       0.18 0.00  \nSGDClassifier                 0.04     0.71 0.03       0.09 0.00  \nSVC                           0.01     0.72 0.01       0.31 0.01  \nXGBClassifier                 0.01     0.79 0.01       3.22 0.68  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">Accuracy</th>\n      <th colspan=\"2\" halign=\"left\">Balanced Accuracy</th>\n      <th colspan=\"2\" halign=\"left\">ROC AUC</th>\n      <th colspan=\"2\" halign=\"left\">F1 Score</th>\n      <th colspan=\"2\" halign=\"left\">Time Taken</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.76</td>\n      <td>0.03</td>\n      <td>0.71</td>\n      <td>0.04</td>\n      <td>0.71</td>\n      <td>0.04</td>\n      <td>0.76</td>\n      <td>0.03</td>\n      <td>3.49</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.78</td>\n      <td>0.03</td>\n      <td>0.73</td>\n      <td>0.03</td>\n      <td>0.73</td>\n      <td>0.03</td>\n      <td>0.78</td>\n      <td>0.03</td>\n      <td>5.28</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.72</td>\n      <td>0.04</td>\n      <td>0.71</td>\n      <td>0.05</td>\n      <td>0.71</td>\n      <td>0.05</td>\n      <td>0.73</td>\n      <td>0.04</td>\n      <td>0.08</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.71</td>\n      <td>0.01</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.63</td>\n      <td>0.03</td>\n      <td>0.99</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.72</td>\n      <td>0.02</td>\n      <td>0.67</td>\n      <td>0.03</td>\n      <td>0.67</td>\n      <td>0.03</td>\n      <td>0.72</td>\n      <td>0.02</td>\n      <td>0.74</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.69</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.69</td>\n      <td>0.05</td>\n      <td>0.64</td>\n      <td>0.05</td>\n      <td>0.64</td>\n      <td>0.05</td>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.78</td>\n      <td>0.01</td>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.76</td>\n      <td>0.01</td>\n      <td>0.52</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.68</td>\n      <td>0.02</td>\n      <td>0.57</td>\n      <td>0.02</td>\n      <td>0.57</td>\n      <td>0.02</td>\n      <td>0.65</td>\n      <td>0.02</td>\n      <td>0.07</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.69</td>\n      <td>0.01</td>\n      <td>0.51</td>\n      <td>0.01</td>\n      <td>0.51</td>\n      <td>0.01</td>\n      <td>0.57</td>\n      <td>0.01</td>\n      <td>0.09</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.80</td>\n      <td>0.02</td>\n      <td>0.74</td>\n      <td>0.02</td>\n      <td>0.74</td>\n      <td>0.02</td>\n      <td>0.79</td>\n      <td>0.02</td>\n      <td>2.90</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.19</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.70</td>\n      <td>0.03</td>\n      <td>0.48</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.70</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.70</td>\n      <td>0.04</td>\n      <td>0.09</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.73</td>\n      <td>0.03</td>\n      <td>0.72</td>\n      <td>0.03</td>\n      <td>0.72</td>\n      <td>0.03</td>\n      <td>0.74</td>\n      <td>0.02</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.76</td>\n      <td>0.02</td>\n      <td>0.67</td>\n      <td>0.01</td>\n      <td>0.67</td>\n      <td>0.01</td>\n      <td>0.74</td>\n      <td>0.01</td>\n      <td>0.34</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.70</td>\n      <td>0.04</td>\n      <td>0.17</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.65</td>\n      <td>0.03</td>\n      <td>0.65</td>\n      <td>0.03</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.69</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.79</td>\n      <td>0.01</td>\n      <td>0.70</td>\n      <td>0.02</td>\n      <td>0.70</td>\n      <td>0.02</td>\n      <td>0.77</td>\n      <td>0.02</td>\n      <td>2.06</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.70</td>\n      <td>0.03</td>\n      <td>0.08</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.69</td>\n      <td>0.04</td>\n      <td>0.65</td>\n      <td>0.03</td>\n      <td>0.65</td>\n      <td>0.03</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.18</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.72</td>\n      <td>0.03</td>\n      <td>0.65</td>\n      <td>0.04</td>\n      <td>0.65</td>\n      <td>0.04</td>\n      <td>0.71</td>\n      <td>0.03</td>\n      <td>0.09</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.76</td>\n      <td>0.01</td>\n      <td>0.64</td>\n      <td>0.01</td>\n      <td>0.64</td>\n      <td>0.01</td>\n      <td>0.72</td>\n      <td>0.01</td>\n      <td>0.31</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.79</td>\n      <td>0.01</td>\n      <td>0.73</td>\n      <td>0.01</td>\n      <td>0.73</td>\n      <td>0.01</td>\n      <td>0.79</td>\n      <td>0.01</td>\n      <td>3.22</td>\n      <td>0.68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"n_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=77)\nresults = []\n\n# Use only the SEX_outcome column for stratification\nfor train_index, test_index in skf.split(X_train, y_train['Sex_F']):\n    X_train_t, X_test_t = X_train.iloc[train_index], X_train.iloc[test_index]\n    y_train_t, y_test_t = y_train['Sex_F'].iloc[train_index], y_train['Sex_F'].iloc[test_index]\n\n    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n    models, predictions = clf.fit(X_train_t, X_test_t, y_train_t, y_test_t)\n    results.append(models)\nmetrics_df = pd.concat(results)\nmetrics_summary = metrics_df.groupby(metrics_df.index).agg(['mean', 'std'])\nmetrics_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:27:13.279085Z","iopub.execute_input":"2025-02-08T21:27:13.279502Z","iopub.status.idle":"2025-02-08T21:28:59.982326Z","shell.execute_reply.started":"2025-02-08T21:27:13.279463Z","shell.execute_reply":"2025-02-08T21:28:59.981218Z"}},"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [00:19<00:00,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 332, number of negative: 638\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128212\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.342268 -> initscore=-0.653203\n[LightGBM] [Info] Start training from score -0.653203\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:22<00:00,  1.31it/s]\n 97%|█████████▋| 28/29 [00:18<00:00,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 333, number of negative: 637\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008161 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128211\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.343299 -> initscore=-0.648627\n[LightGBM] [Info] Start training from score -0.648627\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.37it/s]\n 97%|█████████▋| 28/29 [00:18<00:00,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 333, number of negative: 637\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128212\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.343299 -> initscore=-0.648627\n[LightGBM] [Info] Start training from score -0.648627\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.38it/s]\n 97%|█████████▋| 28/29 [00:18<00:01,  1.00s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 333, number of negative: 638\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007888 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128213\n[LightGBM] [Info] Number of data points in the train set: 971, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.342945 -> initscore=-0.650196\n[LightGBM] [Info] Start training from score -0.650196\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.34it/s]\n 97%|█████████▋| 28/29 [00:17<00:00,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 333, number of negative: 638\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128215\n[LightGBM] [Info] Number of data points in the train set: 971, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.342945 -> initscore=-0.650196\n[LightGBM] [Info] Start training from score -0.650196\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:20<00:00,  1.41it/s]\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                              Accuracy      Balanced Accuracy      ROC AUC  \\\n                                  mean  std              mean  std    mean   \nModel                                                                        \nAdaBoostClassifier                0.62 0.03              0.55 0.04    0.55   \nBaggingClassifier                 0.64 0.03              0.53 0.03    0.53   \nBernoulliNB                       0.67 0.03              0.61 0.04    0.61   \nCalibratedClassifierCV            0.69 0.01              0.56 0.01    0.56   \nDecisionTreeClassifier            0.58 0.03              0.53 0.02    0.53   \nDummyClassifier                   0.66 0.00              0.50 0.00    0.50   \nExtraTreeClassifier               0.55 0.03              0.50 0.04    0.50   \nExtraTreesClassifier              0.66 0.01              0.50 0.01    0.50   \nGaussianNB                        0.45 0.09              0.55 0.04    0.55   \nKNeighborsClassifier              0.52 0.06              0.51 0.02    0.51   \nLGBMClassifier                    0.69 0.02              0.57 0.03    0.57   \nLinearDiscriminantAnalysis        0.69 0.03              0.66 0.03    0.66   \nLinearSVC                         0.68 0.02              0.64 0.03    0.64   \nLogisticRegression                0.68 0.01              0.64 0.02    0.64   \nNearestCentroid                   0.69 0.02              0.66 0.02    0.66   \nNuSVC                             0.71 0.01              0.62 0.02    0.62   \nPassiveAggressiveClassifier       0.67 0.02              0.64 0.02    0.64   \nPerceptron                        0.67 0.02              0.64 0.02    0.64   \nQuadraticDiscriminantAnalysis     0.66 0.00              0.50 0.00    0.50   \nRandomForestClassifier            0.66 0.01              0.51 0.02    0.51   \nRidgeClassifier                   0.69 0.03              0.66 0.03    0.66   \nRidgeClassifierCV                 0.69 0.02              0.66 0.02    0.66   \nSGDClassifier                     0.70 0.01              0.65 0.02    0.65   \nSVC                               0.67 0.01              0.52 0.01    0.52   \nXGBClassifier                     0.68 0.02              0.58 0.03    0.58   \n\n                                   F1 Score      Time Taken       \n                               std     mean  std       mean  std  \nModel                                                             \nAdaBoostClassifier            0.04     0.60 0.04       3.51 0.02  \nBaggingClassifier             0.03     0.59 0.03       3.87 0.38  \nBernoulliNB                   0.04     0.66 0.04       0.08 0.00  \nCalibratedClassifierCV        0.01     0.62 0.02       1.22 0.08  \nDecisionTreeClassifier        0.02     0.57 0.03       0.62 0.05  \nDummyClassifier               0.00     0.52 0.00       0.06 0.00  \nExtraTreeClassifier           0.04     0.55 0.04       0.06 0.00  \nExtraTreesClassifier          0.01     0.53 0.01       0.54 0.01  \nGaussianNB                    0.04     0.39 0.14       0.07 0.00  \nKNeighborsClassifier          0.02     0.52 0.06       0.08 0.00  \nLGBMClassifier                0.03     0.63 0.03       2.87 0.03  \nLinearDiscriminantAnalysis    0.03     0.69 0.03       0.19 0.00  \nLinearSVC                     0.03     0.68 0.02       0.60 0.15  \nLogisticRegression            0.02     0.68 0.01       0.09 0.00  \nNearestCentroid               0.02     0.69 0.02       0.06 0.00  \nNuSVC                         0.02     0.68 0.01       0.37 0.01  \nPassiveAggressiveClassifier   0.02     0.67 0.02       0.16 0.01  \nPerceptron                    0.02     0.68 0.02       0.09 0.01  \nQuadraticDiscriminantAnalysis 0.00     0.52 0.00       0.18 0.00  \nRandomForestClassifier        0.02     0.54 0.02       1.89 0.05  \nRidgeClassifier               0.03     0.69 0.03       0.08 0.01  \nRidgeClassifierCV             0.02     0.69 0.02       0.20 0.04  \nSGDClassifier                 0.02     0.69 0.01       0.09 0.01  \nSVC                           0.01     0.55 0.02       0.37 0.02  \nXGBClassifier                 0.03     0.64 0.03       3.50 0.27  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">Accuracy</th>\n      <th colspan=\"2\" halign=\"left\">Balanced Accuracy</th>\n      <th colspan=\"2\" halign=\"left\">ROC AUC</th>\n      <th colspan=\"2\" halign=\"left\">F1 Score</th>\n      <th colspan=\"2\" halign=\"left\">Time Taken</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.62</td>\n      <td>0.03</td>\n      <td>0.55</td>\n      <td>0.04</td>\n      <td>0.55</td>\n      <td>0.04</td>\n      <td>0.60</td>\n      <td>0.04</td>\n      <td>3.51</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.64</td>\n      <td>0.03</td>\n      <td>0.53</td>\n      <td>0.03</td>\n      <td>0.53</td>\n      <td>0.03</td>\n      <td>0.59</td>\n      <td>0.03</td>\n      <td>3.87</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.67</td>\n      <td>0.03</td>\n      <td>0.61</td>\n      <td>0.04</td>\n      <td>0.61</td>\n      <td>0.04</td>\n      <td>0.66</td>\n      <td>0.04</td>\n      <td>0.08</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.69</td>\n      <td>0.01</td>\n      <td>0.56</td>\n      <td>0.01</td>\n      <td>0.56</td>\n      <td>0.01</td>\n      <td>0.62</td>\n      <td>0.02</td>\n      <td>1.22</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.58</td>\n      <td>0.03</td>\n      <td>0.53</td>\n      <td>0.02</td>\n      <td>0.53</td>\n      <td>0.02</td>\n      <td>0.57</td>\n      <td>0.03</td>\n      <td>0.62</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.66</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.00</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.55</td>\n      <td>0.03</td>\n      <td>0.50</td>\n      <td>0.04</td>\n      <td>0.50</td>\n      <td>0.04</td>\n      <td>0.55</td>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.66</td>\n      <td>0.01</td>\n      <td>0.50</td>\n      <td>0.01</td>\n      <td>0.50</td>\n      <td>0.01</td>\n      <td>0.53</td>\n      <td>0.01</td>\n      <td>0.54</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.45</td>\n      <td>0.09</td>\n      <td>0.55</td>\n      <td>0.04</td>\n      <td>0.55</td>\n      <td>0.04</td>\n      <td>0.39</td>\n      <td>0.14</td>\n      <td>0.07</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.52</td>\n      <td>0.06</td>\n      <td>0.51</td>\n      <td>0.02</td>\n      <td>0.51</td>\n      <td>0.02</td>\n      <td>0.52</td>\n      <td>0.06</td>\n      <td>0.08</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.57</td>\n      <td>0.03</td>\n      <td>0.57</td>\n      <td>0.03</td>\n      <td>0.63</td>\n      <td>0.03</td>\n      <td>2.87</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.19</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.68</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.03</td>\n      <td>0.64</td>\n      <td>0.03</td>\n      <td>0.68</td>\n      <td>0.02</td>\n      <td>0.60</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.68</td>\n      <td>0.01</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.68</td>\n      <td>0.01</td>\n      <td>0.09</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.66</td>\n      <td>0.02</td>\n      <td>0.66</td>\n      <td>0.02</td>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.06</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.71</td>\n      <td>0.01</td>\n      <td>0.62</td>\n      <td>0.02</td>\n      <td>0.62</td>\n      <td>0.02</td>\n      <td>0.68</td>\n      <td>0.01</td>\n      <td>0.37</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.67</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.67</td>\n      <td>0.02</td>\n      <td>0.16</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.67</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.64</td>\n      <td>0.02</td>\n      <td>0.68</td>\n      <td>0.02</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.66</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.66</td>\n      <td>0.01</td>\n      <td>0.51</td>\n      <td>0.02</td>\n      <td>0.51</td>\n      <td>0.02</td>\n      <td>0.54</td>\n      <td>0.02</td>\n      <td>1.89</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.66</td>\n      <td>0.03</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>0.08</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.66</td>\n      <td>0.02</td>\n      <td>0.66</td>\n      <td>0.02</td>\n      <td>0.69</td>\n      <td>0.02</td>\n      <td>0.20</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.70</td>\n      <td>0.01</td>\n      <td>0.65</td>\n      <td>0.02</td>\n      <td>0.65</td>\n      <td>0.02</td>\n      <td>0.69</td>\n      <td>0.01</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.67</td>\n      <td>0.01</td>\n      <td>0.52</td>\n      <td>0.01</td>\n      <td>0.52</td>\n      <td>0.01</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.37</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.68</td>\n      <td>0.02</td>\n      <td>0.58</td>\n      <td>0.03</td>\n      <td>0.58</td>\n      <td>0.03</td>\n      <td>0.64</td>\n      <td>0.03</td>\n      <td>3.50</td>\n      <td>0.27</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"## Without KFOLDs","metadata":{}},{"cell_type":"code","source":"\nX_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n    X_train, y_train['ADHD_Outcome'], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:28:59.983575Z","iopub.execute_input":"2025-02-08T21:28:59.983922Z","iopub.status.idle":"2025-02-08T21:28:59.993665Z","shell.execute_reply.started":"2025-02-08T21:28:59.983853Z","shell.execute_reply":"2025-02-08T21:28:59.992310Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:28:59.994493Z","iopub.execute_input":"2025-02-08T21:28:59.994879Z","iopub.status.idle":"2025-02-08T21:29:00.009063Z","shell.execute_reply.started":"2025-02-08T21:28:59.994848Z","shell.execute_reply":"2025-02-08T21:29:00.007878Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"models, predictions = clf.fit(X_train_split, X_test_split, y_train_split, y_test_split)\n\n\nprint(\"Model performance on ADHD_Outcome:\")\nmodels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:00.010601Z","iopub.execute_input":"2025-02-08T21:29:00.010927Z","iopub.status.idle":"2025-02-08T21:29:21.102127Z","shell.execute_reply.started":"2025-02-08T21:29:00.010896Z","shell.execute_reply":"2025-02-08T21:29:21.101124Z"}},"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [00:18<00:00,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 653, number of negative: 317\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007728 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128215\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.673196 -> initscore=0.722675\n[LightGBM] [Info] Start training from score 0.722675\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Model performance on ADHD_Outcome:\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nNearestCentroid                    0.77               0.76     0.76      0.78   \nBernoulliNB                        0.76               0.74     0.74      0.77   \nXGBClassifier                      0.79               0.72     0.72      0.79   \nBaggingClassifier                  0.77               0.69     0.69      0.76   \nLGBMClassifier                     0.79               0.69     0.69      0.78   \nExtraTreeClassifier                0.72               0.68     0.68      0.73   \nExtraTreesClassifier               0.80               0.67     0.67      0.77   \nRandomForestClassifier             0.78               0.67     0.67      0.77   \nAdaBoostClassifier                 0.75               0.66     0.66      0.74   \nSVC                                0.79               0.65     0.65      0.76   \nNuSVC                              0.75               0.65     0.65      0.74   \nLinearDiscriminantAnalysis         0.70               0.65     0.65      0.71   \nRidgeClassifier                    0.70               0.64     0.64      0.71   \nRidgeClassifierCV                  0.70               0.64     0.64      0.70   \nSGDClassifier                      0.72               0.64     0.64      0.72   \nPassiveAggressiveClassifier        0.66               0.62     0.62      0.67   \nPerceptron                         0.66               0.61     0.61      0.67   \nLinearSVC                          0.65               0.61     0.61      0.66   \nLogisticRegression                 0.66               0.60     0.60      0.67   \nDecisionTreeClassifier             0.64               0.58     0.58      0.65   \nGaussianNB                         0.72               0.57     0.57      0.69   \nCalibratedClassifierCV             0.74               0.56     0.56      0.69   \nKNeighborsClassifier               0.74               0.51     0.51      0.63   \nDummyClassifier                    0.73               0.50     0.50      0.62   \nQuadraticDiscriminantAnalysis      0.73               0.50     0.50      0.62   \n\n                               Time Taken  \nModel                                      \nNearestCentroid                      0.06  \nBernoulliNB                          0.08  \nXGBClassifier                        2.88  \nBaggingClassifier                    4.44  \nLGBMClassifier                       2.97  \nExtraTreeClassifier                  0.06  \nExtraTreesClassifier                 0.51  \nRandomForestClassifier               1.99  \nAdaBoostClassifier                   3.47  \nSVC                                  0.32  \nNuSVC                                0.35  \nLinearDiscriminantAnalysis           0.18  \nRidgeClassifier                      0.08  \nRidgeClassifierCV                    0.18  \nSGDClassifier                        0.11  \nPassiveAggressiveClassifier          0.16  \nPerceptron                           0.08  \nLinearSVC                            0.44  \nLogisticRegression                   0.09  \nDecisionTreeClassifier               0.74  \nGaussianNB                           0.07  \nCalibratedClassifierCV               1.02  \nKNeighborsClassifier                 0.08  \nDummyClassifier                      0.06  \nQuadraticDiscriminantAnalysis        0.18  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.77</td>\n      <td>0.76</td>\n      <td>0.76</td>\n      <td>0.78</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.76</td>\n      <td>0.74</td>\n      <td>0.74</td>\n      <td>0.77</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.79</td>\n      <td>0.72</td>\n      <td>0.72</td>\n      <td>0.79</td>\n      <td>2.88</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.77</td>\n      <td>0.69</td>\n      <td>0.69</td>\n      <td>0.76</td>\n      <td>4.44</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.79</td>\n      <td>0.69</td>\n      <td>0.69</td>\n      <td>0.78</td>\n      <td>2.97</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.72</td>\n      <td>0.68</td>\n      <td>0.68</td>\n      <td>0.73</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.80</td>\n      <td>0.67</td>\n      <td>0.67</td>\n      <td>0.77</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.78</td>\n      <td>0.67</td>\n      <td>0.67</td>\n      <td>0.77</td>\n      <td>1.99</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.75</td>\n      <td>0.66</td>\n      <td>0.66</td>\n      <td>0.74</td>\n      <td>3.47</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.79</td>\n      <td>0.65</td>\n      <td>0.65</td>\n      <td>0.76</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.75</td>\n      <td>0.65</td>\n      <td>0.65</td>\n      <td>0.74</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.70</td>\n      <td>0.65</td>\n      <td>0.65</td>\n      <td>0.71</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.70</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.71</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.70</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.70</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.72</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.72</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.66</td>\n      <td>0.62</td>\n      <td>0.62</td>\n      <td>0.67</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.66</td>\n      <td>0.61</td>\n      <td>0.61</td>\n      <td>0.67</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.65</td>\n      <td>0.61</td>\n      <td>0.61</td>\n      <td>0.66</td>\n      <td>0.44</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.66</td>\n      <td>0.60</td>\n      <td>0.60</td>\n      <td>0.67</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.64</td>\n      <td>0.58</td>\n      <td>0.58</td>\n      <td>0.65</td>\n      <td>0.74</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.72</td>\n      <td>0.57</td>\n      <td>0.57</td>\n      <td>0.69</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.74</td>\n      <td>0.56</td>\n      <td>0.56</td>\n      <td>0.69</td>\n      <td>1.02</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.74</td>\n      <td>0.51</td>\n      <td>0.51</td>\n      <td>0.63</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.73</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.62</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.73</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.62</td>\n      <td>0.18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"predictions.to_csv('lazy_predict_adhd_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:21.103094Z","iopub.execute_input":"2025-02-08T21:29:21.103431Z","iopub.status.idle":"2025-02-08T21:29:21.113363Z","shell.execute_reply.started":"2025-02-08T21:29:21.103395Z","shell.execute_reply":"2025-02-08T21:29:21.112416Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"X_train_split2, X_test_split2, y_train_split2, y_test_split2 = train_test_split(\n    X_train, y_train['Sex_F'], test_size=0.2, random_state=42\n)\n\nclf2 = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\nmodels2, predictions2 = clf2.fit(X_train_split2, X_test_split2, y_train_split2, y_test_split2)\nprint(\"Model performance on Sex_F:\")\nprint(models2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:21.114272Z","iopub.execute_input":"2025-02-08T21:29:21.114557Z","iopub.status.idle":"2025-02-08T21:29:43.042575Z","shell.execute_reply.started":"2025-02-08T21:29:21.114531Z","shell.execute_reply":"2025-02-08T21:29:43.041636Z"}},"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [00:19<00:01,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 344, number of negative: 626\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007668 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 128215\n[LightGBM] [Info] Number of data points in the train set: 970, number of used features: 527\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.354639 -> initscore=-0.598709\n[LightGBM] [Info] Start training from score -0.598709\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:21<00:00,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Model performance on Sex_F:\n                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nRidgeClassifier                    0.72               0.68     0.68      0.72   \nLogisticRegression                 0.72               0.68     0.68      0.73   \nLinearDiscriminantAnalysis         0.72               0.68     0.68      0.72   \nRidgeClassifierCV                  0.72               0.67     0.67      0.72   \nSGDClassifier                      0.73               0.67     0.67      0.73   \nPerceptron                         0.72               0.67     0.67      0.72   \nPassiveAggressiveClassifier        0.70               0.67     0.67      0.71   \nLinearSVC                          0.68               0.65     0.65      0.69   \nNearestCentroid                    0.67               0.62     0.62      0.67   \nNuSVC                              0.73               0.61     0.61      0.70   \nBernoulliNB                        0.71               0.61     0.61      0.69   \nLGBMClassifier                     0.73               0.59     0.59      0.68   \nCalibratedClassifierCV             0.74               0.57     0.57      0.67   \nXGBClassifier                      0.70               0.57     0.57      0.67   \nAdaBoostClassifier                 0.63               0.56     0.56      0.63   \nSVC                                0.72               0.53     0.53      0.63   \nGaussianNB                         0.35               0.53     0.53      0.26   \nRandomForestClassifier             0.71               0.52     0.52      0.61   \nExtraTreeClassifier                0.56               0.51     0.51      0.57   \nBaggingClassifier                  0.65               0.50     0.50      0.60   \nQuadraticDiscriminantAnalysis      0.70               0.50     0.50      0.58   \nDummyClassifier                    0.70               0.50     0.50      0.58   \nExtraTreesClassifier               0.70               0.50     0.50      0.58   \nDecisionTreeClassifier             0.52               0.49     0.49      0.54   \nKNeighborsClassifier               0.40               0.47     0.47      0.40   \n\n                               Time Taken  \nModel                                      \nRidgeClassifier                      0.08  \nLogisticRegression                   0.09  \nLinearDiscriminantAnalysis           0.19  \nRidgeClassifierCV                    0.18  \nSGDClassifier                        0.09  \nPerceptron                           0.09  \nPassiveAggressiveClassifier          0.16  \nLinearSVC                            0.52  \nNearestCentroid                      0.06  \nNuSVC                                0.36  \nBernoulliNB                          0.07  \nLGBMClassifier                       2.83  \nCalibratedClassifierCV               1.28  \nXGBClassifier                        4.74  \nAdaBoostClassifier                   3.47  \nSVC                                  0.36  \nGaussianNB                           0.07  \nRandomForestClassifier               1.82  \nExtraTreeClassifier                  0.06  \nBaggingClassifier                    3.46  \nQuadraticDiscriminantAnalysis        0.18  \nDummyClassifier                      0.06  \nExtraTreesClassifier                 0.53  \nDecisionTreeClassifier               0.59  \nKNeighborsClassifier                 0.08  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"From the LazyPredict, we can try the following models independently.\n\nFor PCA components of 80, we have the following: \n1. ADHD + KFOLD:\n- LinearDiscriminantAnalysis (ROC AUC: 0.74, F1: 0.79)\n- XGBClassifier (ROC AUC: 0.74, F1: 0.79)\n- RidgeClassifierCV (ROC AUC: 0.73, F1: 0.79)\n- LGBMClassifier (ROC AUC: 0.73, F1: 0.78)\n- RandomForestClassifier (ROC AUC: 0.73, F1: 0.78)\n\n2. SEX_F + KFOLD\nFor the SEX_F data (with k-fold), the absolute numbers are lower. The highest performers (by F1/ROC AUC) include:\n- LinearSVC (ROC AUC: 0.66, F1: 0.70)\n- LogisticRegression (ROC AUC: 0.65, F1: 0.70)\n- NuSVC (ROC AUC: 0.64, F1: 0.69)\n- LinearDiscriminantAnalysis (ROC AUC: 0.63, F1: 0.68)\n- RidgeClassifier (ROC AUC: 0.62, F1: 0.67)\n\n\n3. ADHD w/o KFOLD\nWhen not using cross‑validation, many models perform very similarly. Still, a set of five top performers (by highest F1 combined with good ROC AUC) might be:\n\n- LinearSVC (ROC AUC: 0.73, F1: 0.80)\n- NuSVC (ROC AUC: 0.72, F1: 0.80)\n- NearestCentroid (ROC AUC: 0.76, F1: 0.76)\n- XGBClassifier (ROC AUC: 0.72, F1: 0.79)\n- RandomForestClassifier (ROC AUC: 0.72, F1: 0.79)\nHere LinearSVC and NuSVC lead with F1 scores of 0.80, while several others (including XGB and RF) are nearly as good.\n\n\n4. SEX_F w/o KFOLD\nFor SEX_F without k-fold, the overall numbers are again a bit lower. The best five might be:\n\n- RidgeClassifierCV (ROC AUC: 0.66, F1: 0.74)\n- RidgeClassifier (ROC AUC: 0.66, F1: 0.73)\n- LinearDiscriminantAnalysis (ROC AUC: 0.65, F1: 0.72)\n- XGBClassifier (ROC AUC: 0.63, F1: 0.71)\n- LogisticRegression (ROC AUC: 0.64, F1: 0.70)\nIn this group the Ridge models come out ahead, with LDA, XGB, and LogisticRegression following closely.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For different PCA\n\n1. ADHD + Kfold\nLooking at the F1 scores and ROC AUC values, the following models are leading:\n\n- LGBMClassifier\n    - F1 Score: 0.79\n    - ROC AUC: 0.74\n- XGBClassifier\n    - F1 Score: 0.79\n    - ROC AUC: 0.73\n- BaggingClassifier\n    - F1 Score: 0.78\n    - ROC AUC: 0.73\n- RandomForestClassifier\n    - F1 Score: 0.77\n    - ROC AUC: 0.70\n- NearestCentroid\n    - F1 Score: 0.74\n    - ROC AUC: 0.72\nNote: While several other classifiers (e.g., AdaBoostClassifier with F1 = 0.76, ROC AUC = 0.71) come close, these five models have the highest F1/ROC AUC combination.\n\n2. SEX_F + Kfold\nFor the SEX_F dataset with k-fold cross-validation, the overall scores are lower. The top performers here (all with F1 scores around 0.69) include:\n\n- LinearDiscriminantAnalysis\n    - F1 Score: 0.69\n    - ROC AUC: 0.66\n- NearestCentroid\n    - F1 Score: 0.69\n    - ROC AUC: 0.66\n- RidgeClassifier\n    - F1 Score: 0.69\n    - ROC AUC: 0.66\n- RidgeClassifierCV\n    - F1 Score: 0.69\n    - ROC AUC: 0.66\n- SGDClassifier\n    - F1 Score: 0.69\n    - ROC AUC: 0.65\nNote: Other classifiers (like LinearSVC and LogisticRegression at F1 ≈ 0.68) are slightly behind these top performers.\n\n3. ADHD w/o Kfold\nWithout cross‑validation, the numbers shift a bit. The best models based on F1 and ROC AUC appear to be:\n\n- XGBClassifier\n    - F1 Score: 0.79\n    - ROC AUC: 0.72\n- NearestCentroid\n    - F1 Score: 0.78\n    - ROC AUC: 0.76\n- LGBMClassifier\n    - F1 Score: 0.78\n    - ROC AUC: 0.69\n- BernoulliNB\n    - F1 Score: 0.77\n    - ROC AUC: 0.74\n- RandomForestClassifier\n    - F1 Score: 0.77\n    - ROC AUC: 0.67\nNote: Although ExtraTreesClassifier also shows F1 = 0.77, its ROC AUC (0.67) is comparable to RandomForestClassifier, so either could be chosen. In this list, RandomForestClassifier rounds out the top five.\n\n4. SEX_F w/o Kfold\nFor SEX_F without k-fold, the models generally have F1 scores in the low 0.70s. The best five (with a slight edge given to those with ROC AUC near 0.68) are:\n\n- LogisticRegression\n    - F1 Score: 0.73\n    - ROC AUC: 0.68\n- SGDClassifier\n    - F1 Score: 0.73\n    - ROC AUC: 0.67\n- RidgeClassifier\n    - F1 Score: 0.72\n    - ROC AUC: 0.68\n- LinearDiscriminantAnalysis\n    - F1 Score: 0.72\n    - ROC AUC: 0.68\n- RidgeClassifierCV\n    - F1 Score: 0.72\n    - ROC AUC: 0.67\nNote: Perceptron is another contender (F1 = 0.72, ROC AUC = 0.67) but is very similar to RidgeClassifierCV.","metadata":{}},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:43.043618Z","iopub.execute_input":"2025-02-08T21:29:43.043932Z","iopub.status.idle":"2025-02-08T21:29:43.064373Z","shell.execute_reply.started":"2025-02-08T21:29:43.043895Z","shell.execute_reply":"2025-02-08T21:29:43.063304Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"      EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  APQ_P_APQ_P_ID  \\\n0             40.00                 13.00            3.00           10.00   \n1            -94.47                 14.00            3.00           13.00   \n2            -46.67                 14.00            4.00           10.00   \n3            -26.68                 10.00            5.00           12.00   \n4              0.00                 14.00            5.00           15.00   \n...             ...                   ...             ...             ...   \n1208          87.80                 14.00            5.00           14.00   \n1209          77.80                 14.00            3.00           10.00   \n1210          16.68                 14.00            3.00           16.00   \n1211          53.40                 14.00            3.00           14.00   \n1212         -57.80                 14.00            5.00           11.00   \n\n      APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  \\\n0               47.00            13.00           11.00           28.00   \n1               34.00            18.00           23.00           30.00   \n2               35.00            16.00           10.00           29.00   \n3               39.00            19.00           16.00           28.00   \n4               40.00            20.00           24.00           28.00   \n...               ...              ...             ...             ...   \n1208            39.00            20.00           15.00           21.00   \n1209            32.00            20.00           11.00           23.00   \n1210            28.00            15.00           19.00           27.00   \n1211            34.00            18.00           23.00           23.00   \n1212            42.00            18.00           16.00           24.00   \n\n      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  ...  pc_491  \\\n0                         0.00                        6.00  ...    0.21   \n1                         0.00                       18.00  ...   -3.05   \n2                         1.00                       14.00  ...   -4.01   \n3                         6.00                       24.00  ...    6.40   \n4                         1.00                       18.00  ...   -3.19   \n...                        ...                         ...  ...     ...   \n1208                      1.00                        9.00  ...    0.49   \n1209                      6.00                       18.00  ...    0.08   \n1210                      3.00                        4.00  ...    2.52   \n1211                      4.00                        9.00  ...   -5.96   \n1212                      3.00                       12.00  ...    5.14   \n\n      pc_492  pc_493  pc_494  pc_495  pc_496  pc_497  pc_498  pc_499  pc_500  \n0       0.24    0.33   -3.67   -0.83   -0.79   -1.70   -0.61   -2.54   -2.51  \n1       3.16   -0.64    4.55   -4.54   -6.54   -1.75    6.10    6.47    0.33  \n2      -0.13    2.70   -4.49   -6.54    4.13   -0.13   -7.26    3.18    5.22  \n3      -2.73    4.98   -4.41   -0.27   -4.48   -5.64   -3.86    1.84    2.03  \n4      -3.63    0.34   -0.04   -4.05    2.22   -5.62   -1.86   -4.47    3.39  \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n1208    4.51   -5.09   -1.70    1.14   -2.06   -0.23    0.65   -4.06    6.91  \n1209   -1.41    1.15   -4.19   -0.94   -0.52   -1.39   -0.43    1.20    1.53  \n1210    3.81   -2.11   -2.12    0.85    1.68    4.10   -1.86    2.27    2.55  \n1211    2.51    0.65   -1.08   -2.86   -2.74   -2.38    0.58    6.00    1.07  \n1212    4.27    0.53    1.41    2.09   -0.45    2.04   -2.20   -2.21    5.53  \n\n[1213 rows x 527 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>...</th>\n      <th>pc_491</th>\n      <th>pc_492</th>\n      <th>pc_493</th>\n      <th>pc_494</th>\n      <th>pc_495</th>\n      <th>pc_496</th>\n      <th>pc_497</th>\n      <th>pc_498</th>\n      <th>pc_499</th>\n      <th>pc_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>47.00</td>\n      <td>13.00</td>\n      <td>11.00</td>\n      <td>28.00</td>\n      <td>0.00</td>\n      <td>6.00</td>\n      <td>...</td>\n      <td>0.21</td>\n      <td>0.24</td>\n      <td>0.33</td>\n      <td>-3.67</td>\n      <td>-0.83</td>\n      <td>-0.79</td>\n      <td>-1.70</td>\n      <td>-0.61</td>\n      <td>-2.54</td>\n      <td>-2.51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-94.47</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>13.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>30.00</td>\n      <td>0.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.05</td>\n      <td>3.16</td>\n      <td>-0.64</td>\n      <td>4.55</td>\n      <td>-4.54</td>\n      <td>-6.54</td>\n      <td>-1.75</td>\n      <td>6.10</td>\n      <td>6.47</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-46.67</td>\n      <td>14.00</td>\n      <td>4.00</td>\n      <td>10.00</td>\n      <td>35.00</td>\n      <td>16.00</td>\n      <td>10.00</td>\n      <td>29.00</td>\n      <td>1.00</td>\n      <td>14.00</td>\n      <td>...</td>\n      <td>-4.01</td>\n      <td>-0.13</td>\n      <td>2.70</td>\n      <td>-4.49</td>\n      <td>-6.54</td>\n      <td>4.13</td>\n      <td>-0.13</td>\n      <td>-7.26</td>\n      <td>3.18</td>\n      <td>5.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-26.68</td>\n      <td>10.00</td>\n      <td>5.00</td>\n      <td>12.00</td>\n      <td>39.00</td>\n      <td>19.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>6.00</td>\n      <td>24.00</td>\n      <td>...</td>\n      <td>6.40</td>\n      <td>-2.73</td>\n      <td>4.98</td>\n      <td>-4.41</td>\n      <td>-0.27</td>\n      <td>-4.48</td>\n      <td>-5.64</td>\n      <td>-3.86</td>\n      <td>1.84</td>\n      <td>2.03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>15.00</td>\n      <td>40.00</td>\n      <td>20.00</td>\n      <td>24.00</td>\n      <td>28.00</td>\n      <td>1.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.19</td>\n      <td>-3.63</td>\n      <td>0.34</td>\n      <td>-0.04</td>\n      <td>-4.05</td>\n      <td>2.22</td>\n      <td>-5.62</td>\n      <td>-1.86</td>\n      <td>-4.47</td>\n      <td>3.39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>87.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>14.00</td>\n      <td>39.00</td>\n      <td>20.00</td>\n      <td>15.00</td>\n      <td>21.00</td>\n      <td>1.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>0.49</td>\n      <td>4.51</td>\n      <td>-5.09</td>\n      <td>-1.70</td>\n      <td>1.14</td>\n      <td>-2.06</td>\n      <td>-0.23</td>\n      <td>0.65</td>\n      <td>-4.06</td>\n      <td>6.91</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>77.80</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>32.00</td>\n      <td>20.00</td>\n      <td>11.00</td>\n      <td>23.00</td>\n      <td>6.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>-1.41</td>\n      <td>1.15</td>\n      <td>-4.19</td>\n      <td>-0.94</td>\n      <td>-0.52</td>\n      <td>-1.39</td>\n      <td>-0.43</td>\n      <td>1.20</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>16.68</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>15.00</td>\n      <td>19.00</td>\n      <td>27.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>...</td>\n      <td>2.52</td>\n      <td>3.81</td>\n      <td>-2.11</td>\n      <td>-2.12</td>\n      <td>0.85</td>\n      <td>1.68</td>\n      <td>4.10</td>\n      <td>-1.86</td>\n      <td>2.27</td>\n      <td>2.55</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>53.40</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>14.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>23.00</td>\n      <td>4.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>-5.96</td>\n      <td>2.51</td>\n      <td>0.65</td>\n      <td>-1.08</td>\n      <td>-2.86</td>\n      <td>-2.74</td>\n      <td>-2.38</td>\n      <td>0.58</td>\n      <td>6.00</td>\n      <td>1.07</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>-57.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>11.00</td>\n      <td>42.00</td>\n      <td>18.00</td>\n      <td>16.00</td>\n      <td>24.00</td>\n      <td>3.00</td>\n      <td>12.00</td>\n      <td>...</td>\n      <td>5.14</td>\n      <td>4.27</td>\n      <td>0.53</td>\n      <td>1.41</td>\n      <td>2.09</td>\n      <td>-0.45</td>\n      <td>2.04</td>\n      <td>-2.20</td>\n      <td>-2.21</td>\n      <td>5.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 527 columns</p>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:43.065487Z","iopub.execute_input":"2025-02-08T21:29:43.065829Z","iopub.status.idle":"2025-02-08T21:29:43.085402Z","shell.execute_reply.started":"2025-02-08T21:29:43.065801Z","shell.execute_reply":"2025-02-08T21:29:43.084290Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"      ADHD_Outcome  Sex_F\n0                1      1\n1                1      0\n2                1      0\n3                1      1\n4                1      1\n...            ...    ...\n1208             0      0\n1209             0      1\n1210             0      1\n1211             0      0\n1212             0      0\n\n[1213 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:29:43.086497Z","iopub.execute_input":"2025-02-08T21:29:43.086852Z","iopub.status.idle":"2025-02-08T21:29:43.111891Z","shell.execute_reply.started":"2025-02-08T21:29:43.086816Z","shell.execute_reply":"2025-02-08T21:29:43.110837Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"     Basic_Demos_Enroll_Year_x  Basic_Demos_Study_Site_x  \\\n0                         2022                         4   \n1                         2023                         4   \n2                         2022                         4   \n3                         2022                         4   \n4                         2022                         4   \n..                         ...                       ...   \n299                       2023                         4   \n300                       2023                         4   \n301                       2023                         4   \n302                       2022                         4   \n303                       2022                         4   \n\n     PreInt_Demos_Fam_Child_Ethnicity_x  PreInt_Demos_Fam_Child_Race_x  \\\n0                                  0.00                           0.00   \n1                                  0.00                           0.00   \n2                                  0.00                           0.00   \n3                                  0.00                           0.00   \n4                                  2.00                           0.00   \n..                                  ...                            ...   \n299                                0.00                           0.00   \n300                                0.00                           1.00   \n301                                0.00                           8.00   \n302                                0.00                           8.00   \n303                                1.00                           2.00   \n\n     MRI_Track_Scan_Location_x  Barratt_Barratt_P1_Edu_x  \\\n0                            4                     21.00   \n1                            4                     21.00   \n2                            4                     21.00   \n3                            3                     21.00   \n4                            4                     18.00   \n..                         ...                       ...   \n299                          4                     18.00   \n300                          3                     18.00   \n301                          4                     21.00   \n302                          4                     21.00   \n303                          4                     18.00   \n\n     Barratt_Barratt_P1_Occ_x  Barratt_Barratt_P2_Edu_x  \\\n0                       30.00                     18.00   \n1                       45.00                       NaN   \n2                       40.00                     18.00   \n3                       45.00                     21.00   \n4                        0.00                     21.00   \n..                        ...                       ...   \n299                      0.00                     18.00   \n300                     35.00                     21.00   \n301                     25.00                     15.00   \n302                      0.00                     21.00   \n303                      0.00                     12.00   \n\n     Barratt_Barratt_P2_Occ_x  EHQ_EHQ_Total  ...  pc_491  pc_492  pc_493  \\\n0                       30.00          60.03  ...    2.72   -4.41   -1.38   \n1                       30.00          86.71  ...    4.55   -2.12    2.10   \n2                       40.00          26.68  ...   12.55   -5.50    1.74   \n3                       45.00          93.38  ...    6.46   -6.19   -5.25   \n4                       45.00         -93.38  ...    1.40   -1.23    2.07   \n..                        ...            ...  ...     ...     ...     ...   \n299                     35.00          86.71  ...    1.14   -7.70    5.91   \n300                     40.00          73.37  ...   -6.65   -6.98   -2.96   \n301                       NaN          87.84  ...    1.56  -12.41   -0.58   \n302                     45.00          46.76  ...    4.52   -4.57    3.50   \n303                     35.00          87.84  ...   -5.42    6.61   -4.70   \n\n     pc_494  pc_495  pc_496  pc_497  pc_498  pc_499  pc_500  \n0     -9.93  -11.28   -0.53   -5.56   -6.11   -3.46   -3.18  \n1     -4.82    1.41   -9.20    5.92  -10.07    1.04   -4.84  \n2      4.90   -5.00   -2.03    1.44    8.71    3.32   -2.07  \n3      4.82   -3.94   -6.45   -4.88    7.53    5.00   -4.56  \n4      5.91   -0.18   -0.13   -4.12    1.49    2.53   -8.30  \n..      ...     ...     ...     ...     ...     ...     ...  \n299   -1.72   -2.22   -5.81   -5.96    3.62    7.84   -6.37  \n300   -3.64    0.93   -5.36   -9.96    0.02    5.73   -8.26  \n301    1.31   -1.14   -2.32   -9.51    0.14    3.44    1.13  \n302   -4.26   -3.59   -5.86   -2.40    0.22    9.59    1.99  \n303    0.01   -4.10    0.06    2.92   -0.31    3.86    1.76  \n\n[304 rows x 536 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year_x</th>\n      <th>Basic_Demos_Study_Site_x</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity_x</th>\n      <th>PreInt_Demos_Fam_Child_Race_x</th>\n      <th>MRI_Track_Scan_Location_x</th>\n      <th>Barratt_Barratt_P1_Edu_x</th>\n      <th>Barratt_Barratt_P1_Occ_x</th>\n      <th>Barratt_Barratt_P2_Edu_x</th>\n      <th>Barratt_Barratt_P2_Occ_x</th>\n      <th>EHQ_EHQ_Total</th>\n      <th>...</th>\n      <th>pc_491</th>\n      <th>pc_492</th>\n      <th>pc_493</th>\n      <th>pc_494</th>\n      <th>pc_495</th>\n      <th>pc_496</th>\n      <th>pc_497</th>\n      <th>pc_498</th>\n      <th>pc_499</th>\n      <th>pc_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>30.00</td>\n      <td>18.00</td>\n      <td>30.00</td>\n      <td>60.03</td>\n      <td>...</td>\n      <td>2.72</td>\n      <td>-4.41</td>\n      <td>-1.38</td>\n      <td>-9.93</td>\n      <td>-11.28</td>\n      <td>-0.53</td>\n      <td>-5.56</td>\n      <td>-6.11</td>\n      <td>-3.46</td>\n      <td>-3.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>NaN</td>\n      <td>30.00</td>\n      <td>86.71</td>\n      <td>...</td>\n      <td>4.55</td>\n      <td>-2.12</td>\n      <td>2.10</td>\n      <td>-4.82</td>\n      <td>1.41</td>\n      <td>-9.20</td>\n      <td>5.92</td>\n      <td>-10.07</td>\n      <td>1.04</td>\n      <td>-4.84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>40.00</td>\n      <td>18.00</td>\n      <td>40.00</td>\n      <td>26.68</td>\n      <td>...</td>\n      <td>12.55</td>\n      <td>-5.50</td>\n      <td>1.74</td>\n      <td>4.90</td>\n      <td>-5.00</td>\n      <td>-2.03</td>\n      <td>1.44</td>\n      <td>8.71</td>\n      <td>3.32</td>\n      <td>-2.07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>3</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>93.38</td>\n      <td>...</td>\n      <td>6.46</td>\n      <td>-6.19</td>\n      <td>-5.25</td>\n      <td>4.82</td>\n      <td>-3.94</td>\n      <td>-6.45</td>\n      <td>-4.88</td>\n      <td>7.53</td>\n      <td>5.00</td>\n      <td>-4.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>-93.38</td>\n      <td>...</td>\n      <td>1.40</td>\n      <td>-1.23</td>\n      <td>2.07</td>\n      <td>5.91</td>\n      <td>-0.18</td>\n      <td>-0.13</td>\n      <td>-4.12</td>\n      <td>1.49</td>\n      <td>2.53</td>\n      <td>-8.30</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>18.00</td>\n      <td>35.00</td>\n      <td>86.71</td>\n      <td>...</td>\n      <td>1.14</td>\n      <td>-7.70</td>\n      <td>5.91</td>\n      <td>-1.72</td>\n      <td>-2.22</td>\n      <td>-5.81</td>\n      <td>-5.96</td>\n      <td>3.62</td>\n      <td>7.84</td>\n      <td>-6.37</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>3</td>\n      <td>18.00</td>\n      <td>35.00</td>\n      <td>21.00</td>\n      <td>40.00</td>\n      <td>73.37</td>\n      <td>...</td>\n      <td>-6.65</td>\n      <td>-6.98</td>\n      <td>-2.96</td>\n      <td>-3.64</td>\n      <td>0.93</td>\n      <td>-5.36</td>\n      <td>-9.96</td>\n      <td>0.02</td>\n      <td>5.73</td>\n      <td>-8.26</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>8.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>25.00</td>\n      <td>15.00</td>\n      <td>NaN</td>\n      <td>87.84</td>\n      <td>...</td>\n      <td>1.56</td>\n      <td>-12.41</td>\n      <td>-0.58</td>\n      <td>1.31</td>\n      <td>-1.14</td>\n      <td>-2.32</td>\n      <td>-9.51</td>\n      <td>0.14</td>\n      <td>3.44</td>\n      <td>1.13</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>8.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>0.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>46.76</td>\n      <td>...</td>\n      <td>4.52</td>\n      <td>-4.57</td>\n      <td>3.50</td>\n      <td>-4.26</td>\n      <td>-3.59</td>\n      <td>-5.86</td>\n      <td>-2.40</td>\n      <td>0.22</td>\n      <td>9.59</td>\n      <td>1.99</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>12.00</td>\n      <td>35.00</td>\n      <td>87.84</td>\n      <td>...</td>\n      <td>-5.42</td>\n      <td>6.61</td>\n      <td>-4.70</td>\n      <td>0.01</td>\n      <td>-4.10</td>\n      <td>0.06</td>\n      <td>2.92</td>\n      <td>-0.31</td>\n      <td>3.86</td>\n      <td>1.76</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 536 columns</p>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"### MULTI-OUTPUT CLASSIFICATION","metadata":{}},{"cell_type":"code","source":"X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:43:59.418437Z","iopub.execute_input":"2025-02-08T21:43:59.418843Z","iopub.status.idle":"2025-02-08T21:43:59.429635Z","shell.execute_reply.started":"2025-02-08T21:43:59.418811Z","shell.execute_reply":"2025-02-08T21:43:59.428432Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"features = X_train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:52:00.557490Z","iopub.execute_input":"2025-02-08T21:52:00.557945Z","iopub.status.idle":"2025-02-08T21:52:00.562246Z","shell.execute_reply.started":"2025-02-08T21:52:00.557847Z","shell.execute_reply":"2025-02-08T21:52:00.561298Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\n\nmodel = MultiOutputClassifier(\n    make_pipeline(\n        ColumnTransformer(\n            transformers=[\n                ('imputer', SimpleImputer(strategy='mean'), features)\n            ],\n            remainder='passthrough'\n        ),\n        StandardScaler(),\n        XGBClassifier(\n            n_estimators=500,         # More trees\n            learning_rate=0.03,       # Lower learning rate\n            max_depth=8,              # Deeper trees\n            colsample_bytree=0.8,     # Random feature selection (column sampling)\n            subsample=0.8,            # Better generalization (row subsampling)\n            gamma=1,                  # Minimum loss reduction required for further partitioning\n            reg_lambda=10,            # L2 regularization\n            reg_alpha=1,              # L1 regularization\n            random_state=42\n        )\n    )\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:52:02.529705Z","iopub.execute_input":"2025-02-08T21:52:02.530164Z","iopub.status.idle":"2025-02-08T21:52:02.538868Z","shell.execute_reply.started":"2025-02-08T21:52:02.530109Z","shell.execute_reply":"2025-02-08T21:52:02.537532Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:50:17.874619Z","iopub.execute_input":"2025-02-08T21:50:17.875037Z","iopub.status.idle":"2025-02-08T21:50:17.897650Z","shell.execute_reply.started":"2025-02-08T21:50:17.875008Z","shell.execute_reply":"2025-02-08T21:50:17.896435Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"      EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  APQ_P_APQ_P_ID  \\\n0             40.00                 13.00            3.00           10.00   \n1            -94.47                 14.00            3.00           13.00   \n2            -46.67                 14.00            4.00           10.00   \n3            -26.68                 10.00            5.00           12.00   \n4              0.00                 14.00            5.00           15.00   \n...             ...                   ...             ...             ...   \n1208          87.80                 14.00            5.00           14.00   \n1209          77.80                 14.00            3.00           10.00   \n1210          16.68                 14.00            3.00           16.00   \n1211          53.40                 14.00            3.00           14.00   \n1212         -57.80                 14.00            5.00           11.00   \n\n      APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  \\\n0               47.00            13.00           11.00           28.00   \n1               34.00            18.00           23.00           30.00   \n2               35.00            16.00           10.00           29.00   \n3               39.00            19.00           16.00           28.00   \n4               40.00            20.00           24.00           28.00   \n...               ...              ...             ...             ...   \n1208            39.00            20.00           15.00           21.00   \n1209            32.00            20.00           11.00           23.00   \n1210            28.00            15.00           19.00           27.00   \n1211            34.00            18.00           23.00           23.00   \n1212            42.00            18.00           16.00           24.00   \n\n      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  ...  pc_491  \\\n0                         0.00                        6.00  ...    0.21   \n1                         0.00                       18.00  ...   -3.05   \n2                         1.00                       14.00  ...   -4.01   \n3                         6.00                       24.00  ...    6.40   \n4                         1.00                       18.00  ...   -3.19   \n...                        ...                         ...  ...     ...   \n1208                      1.00                        9.00  ...    0.49   \n1209                      6.00                       18.00  ...    0.08   \n1210                      3.00                        4.00  ...    2.52   \n1211                      4.00                        9.00  ...   -5.96   \n1212                      3.00                       12.00  ...    5.14   \n\n      pc_492  pc_493  pc_494  pc_495  pc_496  pc_497  pc_498  pc_499  pc_500  \n0       0.24    0.33   -3.67   -0.83   -0.79   -1.70   -0.61   -2.54   -2.51  \n1       3.16   -0.64    4.55   -4.54   -6.54   -1.75    6.10    6.47    0.33  \n2      -0.13    2.70   -4.49   -6.54    4.13   -0.13   -7.26    3.18    5.22  \n3      -2.73    4.98   -4.41   -0.27   -4.48   -5.64   -3.86    1.84    2.03  \n4      -3.63    0.34   -0.04   -4.05    2.22   -5.62   -1.86   -4.47    3.39  \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n1208    4.51   -5.09   -1.70    1.14   -2.06   -0.23    0.65   -4.06    6.91  \n1209   -1.41    1.15   -4.19   -0.94   -0.52   -1.39   -0.43    1.20    1.53  \n1210    3.81   -2.11   -2.12    0.85    1.68    4.10   -1.86    2.27    2.55  \n1211    2.51    0.65   -1.08   -2.86   -2.74   -2.38    0.58    6.00    1.07  \n1212    4.27    0.53    1.41    2.09   -0.45    2.04   -2.20   -2.21    5.53  \n\n[1213 rows x 527 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>...</th>\n      <th>pc_491</th>\n      <th>pc_492</th>\n      <th>pc_493</th>\n      <th>pc_494</th>\n      <th>pc_495</th>\n      <th>pc_496</th>\n      <th>pc_497</th>\n      <th>pc_498</th>\n      <th>pc_499</th>\n      <th>pc_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>47.00</td>\n      <td>13.00</td>\n      <td>11.00</td>\n      <td>28.00</td>\n      <td>0.00</td>\n      <td>6.00</td>\n      <td>...</td>\n      <td>0.21</td>\n      <td>0.24</td>\n      <td>0.33</td>\n      <td>-3.67</td>\n      <td>-0.83</td>\n      <td>-0.79</td>\n      <td>-1.70</td>\n      <td>-0.61</td>\n      <td>-2.54</td>\n      <td>-2.51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-94.47</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>13.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>30.00</td>\n      <td>0.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.05</td>\n      <td>3.16</td>\n      <td>-0.64</td>\n      <td>4.55</td>\n      <td>-4.54</td>\n      <td>-6.54</td>\n      <td>-1.75</td>\n      <td>6.10</td>\n      <td>6.47</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-46.67</td>\n      <td>14.00</td>\n      <td>4.00</td>\n      <td>10.00</td>\n      <td>35.00</td>\n      <td>16.00</td>\n      <td>10.00</td>\n      <td>29.00</td>\n      <td>1.00</td>\n      <td>14.00</td>\n      <td>...</td>\n      <td>-4.01</td>\n      <td>-0.13</td>\n      <td>2.70</td>\n      <td>-4.49</td>\n      <td>-6.54</td>\n      <td>4.13</td>\n      <td>-0.13</td>\n      <td>-7.26</td>\n      <td>3.18</td>\n      <td>5.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-26.68</td>\n      <td>10.00</td>\n      <td>5.00</td>\n      <td>12.00</td>\n      <td>39.00</td>\n      <td>19.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>6.00</td>\n      <td>24.00</td>\n      <td>...</td>\n      <td>6.40</td>\n      <td>-2.73</td>\n      <td>4.98</td>\n      <td>-4.41</td>\n      <td>-0.27</td>\n      <td>-4.48</td>\n      <td>-5.64</td>\n      <td>-3.86</td>\n      <td>1.84</td>\n      <td>2.03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>15.00</td>\n      <td>40.00</td>\n      <td>20.00</td>\n      <td>24.00</td>\n      <td>28.00</td>\n      <td>1.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.19</td>\n      <td>-3.63</td>\n      <td>0.34</td>\n      <td>-0.04</td>\n      <td>-4.05</td>\n      <td>2.22</td>\n      <td>-5.62</td>\n      <td>-1.86</td>\n      <td>-4.47</td>\n      <td>3.39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>87.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>14.00</td>\n      <td>39.00</td>\n      <td>20.00</td>\n      <td>15.00</td>\n      <td>21.00</td>\n      <td>1.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>0.49</td>\n      <td>4.51</td>\n      <td>-5.09</td>\n      <td>-1.70</td>\n      <td>1.14</td>\n      <td>-2.06</td>\n      <td>-0.23</td>\n      <td>0.65</td>\n      <td>-4.06</td>\n      <td>6.91</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>77.80</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>32.00</td>\n      <td>20.00</td>\n      <td>11.00</td>\n      <td>23.00</td>\n      <td>6.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>-1.41</td>\n      <td>1.15</td>\n      <td>-4.19</td>\n      <td>-0.94</td>\n      <td>-0.52</td>\n      <td>-1.39</td>\n      <td>-0.43</td>\n      <td>1.20</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>16.68</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>15.00</td>\n      <td>19.00</td>\n      <td>27.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>...</td>\n      <td>2.52</td>\n      <td>3.81</td>\n      <td>-2.11</td>\n      <td>-2.12</td>\n      <td>0.85</td>\n      <td>1.68</td>\n      <td>4.10</td>\n      <td>-1.86</td>\n      <td>2.27</td>\n      <td>2.55</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>53.40</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>14.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>23.00</td>\n      <td>4.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>-5.96</td>\n      <td>2.51</td>\n      <td>0.65</td>\n      <td>-1.08</td>\n      <td>-2.86</td>\n      <td>-2.74</td>\n      <td>-2.38</td>\n      <td>0.58</td>\n      <td>6.00</td>\n      <td>1.07</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>-57.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>11.00</td>\n      <td>42.00</td>\n      <td>18.00</td>\n      <td>16.00</td>\n      <td>24.00</td>\n      <td>3.00</td>\n      <td>12.00</td>\n      <td>...</td>\n      <td>5.14</td>\n      <td>4.27</td>\n      <td>0.53</td>\n      <td>1.41</td>\n      <td>2.09</td>\n      <td>-0.45</td>\n      <td>2.04</td>\n      <td>-2.20</td>\n      <td>-2.21</td>\n      <td>5.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 527 columns</p>\n</div>"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"print(X_train.columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:51:16.711065Z","iopub.execute_input":"2025-02-08T21:51:16.711495Z","iopub.status.idle":"2025-02-08T21:51:16.716831Z","shell.execute_reply.started":"2025-02-08T21:51:16.711461Z","shell.execute_reply":"2025-02-08T21:51:16.715784Z"}},"outputs":[{"name":"stdout","text":"['EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site', 'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'pc_1', 'pc_2', 'pc_3', 'pc_4', 'pc_5', 'pc_6', 'pc_7', 'pc_8', 'pc_9', 'pc_10', 'pc_11', 'pc_12', 'pc_13', 'pc_14', 'pc_15', 'pc_16', 'pc_17', 'pc_18', 'pc_19', 'pc_20', 'pc_21', 'pc_22', 'pc_23', 'pc_24', 'pc_25', 'pc_26', 'pc_27', 'pc_28', 'pc_29', 'pc_30', 'pc_31', 'pc_32', 'pc_33', 'pc_34', 'pc_35', 'pc_36', 'pc_37', 'pc_38', 'pc_39', 'pc_40', 'pc_41', 'pc_42', 'pc_43', 'pc_44', 'pc_45', 'pc_46', 'pc_47', 'pc_48', 'pc_49', 'pc_50', 'pc_51', 'pc_52', 'pc_53', 'pc_54', 'pc_55', 'pc_56', 'pc_57', 'pc_58', 'pc_59', 'pc_60', 'pc_61', 'pc_62', 'pc_63', 'pc_64', 'pc_65', 'pc_66', 'pc_67', 'pc_68', 'pc_69', 'pc_70', 'pc_71', 'pc_72', 'pc_73', 'pc_74', 'pc_75', 'pc_76', 'pc_77', 'pc_78', 'pc_79', 'pc_80', 'pc_81', 'pc_82', 'pc_83', 'pc_84', 'pc_85', 'pc_86', 'pc_87', 'pc_88', 'pc_89', 'pc_90', 'pc_91', 'pc_92', 'pc_93', 'pc_94', 'pc_95', 'pc_96', 'pc_97', 'pc_98', 'pc_99', 'pc_100', 'pc_101', 'pc_102', 'pc_103', 'pc_104', 'pc_105', 'pc_106', 'pc_107', 'pc_108', 'pc_109', 'pc_110', 'pc_111', 'pc_112', 'pc_113', 'pc_114', 'pc_115', 'pc_116', 'pc_117', 'pc_118', 'pc_119', 'pc_120', 'pc_121', 'pc_122', 'pc_123', 'pc_124', 'pc_125', 'pc_126', 'pc_127', 'pc_128', 'pc_129', 'pc_130', 'pc_131', 'pc_132', 'pc_133', 'pc_134', 'pc_135', 'pc_136', 'pc_137', 'pc_138', 'pc_139', 'pc_140', 'pc_141', 'pc_142', 'pc_143', 'pc_144', 'pc_145', 'pc_146', 'pc_147', 'pc_148', 'pc_149', 'pc_150', 'pc_151', 'pc_152', 'pc_153', 'pc_154', 'pc_155', 'pc_156', 'pc_157', 'pc_158', 'pc_159', 'pc_160', 'pc_161', 'pc_162', 'pc_163', 'pc_164', 'pc_165', 'pc_166', 'pc_167', 'pc_168', 'pc_169', 'pc_170', 'pc_171', 'pc_172', 'pc_173', 'pc_174', 'pc_175', 'pc_176', 'pc_177', 'pc_178', 'pc_179', 'pc_180', 'pc_181', 'pc_182', 'pc_183', 'pc_184', 'pc_185', 'pc_186', 'pc_187', 'pc_188', 'pc_189', 'pc_190', 'pc_191', 'pc_192', 'pc_193', 'pc_194', 'pc_195', 'pc_196', 'pc_197', 'pc_198', 'pc_199', 'pc_200', 'pc_201', 'pc_202', 'pc_203', 'pc_204', 'pc_205', 'pc_206', 'pc_207', 'pc_208', 'pc_209', 'pc_210', 'pc_211', 'pc_212', 'pc_213', 'pc_214', 'pc_215', 'pc_216', 'pc_217', 'pc_218', 'pc_219', 'pc_220', 'pc_221', 'pc_222', 'pc_223', 'pc_224', 'pc_225', 'pc_226', 'pc_227', 'pc_228', 'pc_229', 'pc_230', 'pc_231', 'pc_232', 'pc_233', 'pc_234', 'pc_235', 'pc_236', 'pc_237', 'pc_238', 'pc_239', 'pc_240', 'pc_241', 'pc_242', 'pc_243', 'pc_244', 'pc_245', 'pc_246', 'pc_247', 'pc_248', 'pc_249', 'pc_250', 'pc_251', 'pc_252', 'pc_253', 'pc_254', 'pc_255', 'pc_256', 'pc_257', 'pc_258', 'pc_259', 'pc_260', 'pc_261', 'pc_262', 'pc_263', 'pc_264', 'pc_265', 'pc_266', 'pc_267', 'pc_268', 'pc_269', 'pc_270', 'pc_271', 'pc_272', 'pc_273', 'pc_274', 'pc_275', 'pc_276', 'pc_277', 'pc_278', 'pc_279', 'pc_280', 'pc_281', 'pc_282', 'pc_283', 'pc_284', 'pc_285', 'pc_286', 'pc_287', 'pc_288', 'pc_289', 'pc_290', 'pc_291', 'pc_292', 'pc_293', 'pc_294', 'pc_295', 'pc_296', 'pc_297', 'pc_298', 'pc_299', 'pc_300', 'pc_301', 'pc_302', 'pc_303', 'pc_304', 'pc_305', 'pc_306', 'pc_307', 'pc_308', 'pc_309', 'pc_310', 'pc_311', 'pc_312', 'pc_313', 'pc_314', 'pc_315', 'pc_316', 'pc_317', 'pc_318', 'pc_319', 'pc_320', 'pc_321', 'pc_322', 'pc_323', 'pc_324', 'pc_325', 'pc_326', 'pc_327', 'pc_328', 'pc_329', 'pc_330', 'pc_331', 'pc_332', 'pc_333', 'pc_334', 'pc_335', 'pc_336', 'pc_337', 'pc_338', 'pc_339', 'pc_340', 'pc_341', 'pc_342', 'pc_343', 'pc_344', 'pc_345', 'pc_346', 'pc_347', 'pc_348', 'pc_349', 'pc_350', 'pc_351', 'pc_352', 'pc_353', 'pc_354', 'pc_355', 'pc_356', 'pc_357', 'pc_358', 'pc_359', 'pc_360', 'pc_361', 'pc_362', 'pc_363', 'pc_364', 'pc_365', 'pc_366', 'pc_367', 'pc_368', 'pc_369', 'pc_370', 'pc_371', 'pc_372', 'pc_373', 'pc_374', 'pc_375', 'pc_376', 'pc_377', 'pc_378', 'pc_379', 'pc_380', 'pc_381', 'pc_382', 'pc_383', 'pc_384', 'pc_385', 'pc_386', 'pc_387', 'pc_388', 'pc_389', 'pc_390', 'pc_391', 'pc_392', 'pc_393', 'pc_394', 'pc_395', 'pc_396', 'pc_397', 'pc_398', 'pc_399', 'pc_400', 'pc_401', 'pc_402', 'pc_403', 'pc_404', 'pc_405', 'pc_406', 'pc_407', 'pc_408', 'pc_409', 'pc_410', 'pc_411', 'pc_412', 'pc_413', 'pc_414', 'pc_415', 'pc_416', 'pc_417', 'pc_418', 'pc_419', 'pc_420', 'pc_421', 'pc_422', 'pc_423', 'pc_424', 'pc_425', 'pc_426', 'pc_427', 'pc_428', 'pc_429', 'pc_430', 'pc_431', 'pc_432', 'pc_433', 'pc_434', 'pc_435', 'pc_436', 'pc_437', 'pc_438', 'pc_439', 'pc_440', 'pc_441', 'pc_442', 'pc_443', 'pc_444', 'pc_445', 'pc_446', 'pc_447', 'pc_448', 'pc_449', 'pc_450', 'pc_451', 'pc_452', 'pc_453', 'pc_454', 'pc_455', 'pc_456', 'pc_457', 'pc_458', 'pc_459', 'pc_460', 'pc_461', 'pc_462', 'pc_463', 'pc_464', 'pc_465', 'pc_466', 'pc_467', 'pc_468', 'pc_469', 'pc_470', 'pc_471', 'pc_472', 'pc_473', 'pc_474', 'pc_475', 'pc_476', 'pc_477', 'pc_478', 'pc_479', 'pc_480', 'pc_481', 'pc_482', 'pc_483', 'pc_484', 'pc_485', 'pc_486', 'pc_487', 'pc_488', 'pc_489', 'pc_490', 'pc_491', 'pc_492', 'pc_493', 'pc_494', 'pc_495', 'pc_496', 'pc_497', 'pc_498', 'pc_499', 'pc_500']\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:52:21.775492Z","iopub.execute_input":"2025-02-08T21:52:21.775937Z","iopub.status.idle":"2025-02-08T21:53:05.135747Z","shell.execute_reply.started":"2025-02-08T21:52:21.775896Z","shell.execute_reply":"2025-02-08T21:53:05.134574Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"MultiOutputClassifier(estimator=Pipeline(steps=[('columntransformer',\n                                                 ColumnTransformer(remainder='passthrough',\n                                                                   transformers=[('imputer',\n                                                                                  SimpleImputer(),\n                                                                                  Index(['EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n       'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n       'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n       'SDQ_SDQ_Difficulties...\n                                                               gamma=1,\n                                                               grow_policy=None,\n                                                               importance_type=None,\n                                                               interaction_constraints=None,\n                                                               learning_rate=0.03,\n                                                               max_bin=None,\n                                                               max_cat_threshold=None,\n                                                               max_cat_to_onehot=None,\n                                                               max_delta_step=None,\n                                                               max_depth=8,\n                                                               max_leaves=None,\n                                                               min_child_weight=None,\n                                                               missing=nan,\n                                                               monotone_constraints=None,\n                                                               multi_strategy=None,\n                                                               n_estimators=500,\n                                                               n_jobs=None,\n                                                               num_parallel_tree=None,\n                                                               random_state=42, ...))]))","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                                                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                                                   transformers=[(&#x27;imputer&#x27;,\n                                                                                  SimpleImputer(),\n                                                                                  Index([&#x27;EHQ_EHQ_Total&#x27;, &#x27;ColorVision_CV_Score&#x27;, &#x27;APQ_P_APQ_P_CP&#x27;,\n       &#x27;APQ_P_APQ_P_ID&#x27;, &#x27;APQ_P_APQ_P_INV&#x27;, &#x27;APQ_P_APQ_P_OPD&#x27;,\n       &#x27;APQ_P_APQ_P_PM&#x27;, &#x27;APQ_P_APQ_P_PP&#x27;, &#x27;SDQ_SDQ_Conduct_Problems&#x27;,\n       &#x27;SDQ_SDQ_Difficulties...\n                                                               gamma=1,\n                                                               grow_policy=None,\n                                                               importance_type=None,\n                                                               interaction_constraints=None,\n                                                               learning_rate=0.03,\n                                                               max_bin=None,\n                                                               max_cat_threshold=None,\n                                                               max_cat_to_onehot=None,\n                                                               max_delta_step=None,\n                                                               max_depth=8,\n                                                               max_leaves=None,\n                                                               min_child_weight=None,\n                                                               missing=nan,\n                                                               monotone_constraints=None,\n                                                               multi_strategy=None,\n                                                               n_estimators=500,\n                                                               n_jobs=None,\n                                                               num_parallel_tree=None,\n                                                               random_state=42, ...))]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                                                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                                                   transformers=[(&#x27;imputer&#x27;,\n                                                                                  SimpleImputer(),\n                                                                                  Index([&#x27;EHQ_EHQ_Total&#x27;, &#x27;ColorVision_CV_Score&#x27;, &#x27;APQ_P_APQ_P_CP&#x27;,\n       &#x27;APQ_P_APQ_P_ID&#x27;, &#x27;APQ_P_APQ_P_INV&#x27;, &#x27;APQ_P_APQ_P_OPD&#x27;,\n       &#x27;APQ_P_APQ_P_PM&#x27;, &#x27;APQ_P_APQ_P_PP&#x27;, &#x27;SDQ_SDQ_Conduct_Problems&#x27;,\n       &#x27;SDQ_SDQ_Difficulties...\n                                                               gamma=1,\n                                                               grow_policy=None,\n                                                               importance_type=None,\n                                                               interaction_constraints=None,\n                                                               learning_rate=0.03,\n                                                               max_bin=None,\n                                                               max_cat_threshold=None,\n                                                               max_cat_to_onehot=None,\n                                                               max_delta_step=None,\n                                                               max_depth=8,\n                                                               max_leaves=None,\n                                                               min_child_weight=None,\n                                                               missing=nan,\n                                                               monotone_constraints=None,\n                                                               multi_strategy=None,\n                                                               n_estimators=500,\n                                                               n_jobs=None,\n                                                               num_parallel_tree=None,\n                                                               random_state=42, ...))]))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;imputer&#x27;, SimpleImputer(),\n                                                  Index([&#x27;EHQ_EHQ_Total&#x27;, &#x27;ColorVision_CV_Score&#x27;, &#x27;APQ_P_APQ_P_CP&#x27;,\n       &#x27;APQ_P_APQ_P_ID&#x27;, &#x27;APQ_P_APQ_P_INV&#x27;, &#x27;APQ_P_APQ_P_OPD&#x27;,\n       &#x27;APQ_P_APQ_P_PM&#x27;, &#x27;APQ_P_APQ_P_PP&#x27;, &#x27;SDQ_SDQ_Conduct_Problems&#x27;,\n       &#x27;SDQ_SDQ_Difficulties_Total&#x27;,\n       ...\n       &#x27;pc_491&#x27;, &#x27;pc_492&#x27;, &#x27;pc...\n                               feature_types=None, gamma=1, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=0.03,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=8, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=500, n_jobs=None,\n                               num_parallel_tree=None, random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;imputer&#x27;, SimpleImputer(),\n                                 Index([&#x27;EHQ_EHQ_Total&#x27;, &#x27;ColorVision_CV_Score&#x27;, &#x27;APQ_P_APQ_P_CP&#x27;,\n       &#x27;APQ_P_APQ_P_ID&#x27;, &#x27;APQ_P_APQ_P_INV&#x27;, &#x27;APQ_P_APQ_P_OPD&#x27;,\n       &#x27;APQ_P_APQ_P_PM&#x27;, &#x27;APQ_P_APQ_P_PP&#x27;, &#x27;SDQ_SDQ_Conduct_Problems&#x27;,\n       &#x27;SDQ_SDQ_Difficulties_Total&#x27;,\n       ...\n       &#x27;pc_491&#x27;, &#x27;pc_492&#x27;, &#x27;pc_493&#x27;, &#x27;pc_494&#x27;, &#x27;pc_495&#x27;, &#x27;pc_496&#x27;, &#x27;pc_497&#x27;,\n       &#x27;pc_498&#x27;, &#x27;pc_499&#x27;, &#x27;pc_500&#x27;],\n      dtype=&#x27;object&#x27;, length=527))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;EHQ_EHQ_Total&#x27;, &#x27;ColorVision_CV_Score&#x27;, &#x27;APQ_P_APQ_P_CP&#x27;,\n       &#x27;APQ_P_APQ_P_ID&#x27;, &#x27;APQ_P_APQ_P_INV&#x27;, &#x27;APQ_P_APQ_P_OPD&#x27;,\n       &#x27;APQ_P_APQ_P_PM&#x27;, &#x27;APQ_P_APQ_P_PP&#x27;, &#x27;SDQ_SDQ_Conduct_Problems&#x27;,\n       &#x27;SDQ_SDQ_Difficulties_Total&#x27;,\n       ...\n       &#x27;pc_491&#x27;, &#x27;pc_492&#x27;, &#x27;pc_493&#x27;, &#x27;pc_494&#x27;, &#x27;pc_495&#x27;, &#x27;pc_496&#x27;, &#x27;pc_497&#x27;,\n       &#x27;pc_498&#x27;, &#x27;pc_499&#x27;, &#x27;pc_500&#x27;],\n      dtype=&#x27;object&#x27;, length=527)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=1, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.03, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=8, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:54:56.230544Z","iopub.execute_input":"2025-02-08T21:54:56.230899Z","iopub.status.idle":"2025-02-08T21:54:56.252520Z","shell.execute_reply.started":"2025-02-08T21:54:56.230860Z","shell.execute_reply":"2025-02-08T21:54:56.251465Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"     Basic_Demos_Enroll_Year_x  Basic_Demos_Study_Site_x  \\\n0                         2022                         4   \n1                         2023                         4   \n2                         2022                         4   \n3                         2022                         4   \n4                         2022                         4   \n..                         ...                       ...   \n299                       2023                         4   \n300                       2023                         4   \n301                       2023                         4   \n302                       2022                         4   \n303                       2022                         4   \n\n     PreInt_Demos_Fam_Child_Ethnicity_x  PreInt_Demos_Fam_Child_Race_x  \\\n0                                  0.00                           0.00   \n1                                  0.00                           0.00   \n2                                  0.00                           0.00   \n3                                  0.00                           0.00   \n4                                  2.00                           0.00   \n..                                  ...                            ...   \n299                                0.00                           0.00   \n300                                0.00                           1.00   \n301                                0.00                           8.00   \n302                                0.00                           8.00   \n303                                1.00                           2.00   \n\n     MRI_Track_Scan_Location_x  Barratt_Barratt_P1_Edu_x  \\\n0                            4                     21.00   \n1                            4                     21.00   \n2                            4                     21.00   \n3                            3                     21.00   \n4                            4                     18.00   \n..                         ...                       ...   \n299                          4                     18.00   \n300                          3                     18.00   \n301                          4                     21.00   \n302                          4                     21.00   \n303                          4                     18.00   \n\n     Barratt_Barratt_P1_Occ_x  Barratt_Barratt_P2_Edu_x  \\\n0                       30.00                     18.00   \n1                       45.00                       NaN   \n2                       40.00                     18.00   \n3                       45.00                     21.00   \n4                        0.00                     21.00   \n..                        ...                       ...   \n299                      0.00                     18.00   \n300                     35.00                     21.00   \n301                     25.00                     15.00   \n302                      0.00                     21.00   \n303                      0.00                     12.00   \n\n     Barratt_Barratt_P2_Occ_x  EHQ_EHQ_Total  ...  pc_491  pc_492  pc_493  \\\n0                       30.00          60.03  ...    2.72   -4.41   -1.38   \n1                       30.00          86.71  ...    4.55   -2.12    2.10   \n2                       40.00          26.68  ...   12.55   -5.50    1.74   \n3                       45.00          93.38  ...    6.46   -6.19   -5.25   \n4                       45.00         -93.38  ...    1.40   -1.23    2.07   \n..                        ...            ...  ...     ...     ...     ...   \n299                     35.00          86.71  ...    1.14   -7.70    5.91   \n300                     40.00          73.37  ...   -6.65   -6.98   -2.96   \n301                       NaN          87.84  ...    1.56  -12.41   -0.58   \n302                     45.00          46.76  ...    4.52   -4.57    3.50   \n303                     35.00          87.84  ...   -5.42    6.61   -4.70   \n\n     pc_494  pc_495  pc_496  pc_497  pc_498  pc_499  pc_500  \n0     -9.93  -11.28   -0.53   -5.56   -6.11   -3.46   -3.18  \n1     -4.82    1.41   -9.20    5.92  -10.07    1.04   -4.84  \n2      4.90   -5.00   -2.03    1.44    8.71    3.32   -2.07  \n3      4.82   -3.94   -6.45   -4.88    7.53    5.00   -4.56  \n4      5.91   -0.18   -0.13   -4.12    1.49    2.53   -8.30  \n..      ...     ...     ...     ...     ...     ...     ...  \n299   -1.72   -2.22   -5.81   -5.96    3.62    7.84   -6.37  \n300   -3.64    0.93   -5.36   -9.96    0.02    5.73   -8.26  \n301    1.31   -1.14   -2.32   -9.51    0.14    3.44    1.13  \n302   -4.26   -3.59   -5.86   -2.40    0.22    9.59    1.99  \n303    0.01   -4.10    0.06    2.92   -0.31    3.86    1.76  \n\n[304 rows x 536 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year_x</th>\n      <th>Basic_Demos_Study_Site_x</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity_x</th>\n      <th>PreInt_Demos_Fam_Child_Race_x</th>\n      <th>MRI_Track_Scan_Location_x</th>\n      <th>Barratt_Barratt_P1_Edu_x</th>\n      <th>Barratt_Barratt_P1_Occ_x</th>\n      <th>Barratt_Barratt_P2_Edu_x</th>\n      <th>Barratt_Barratt_P2_Occ_x</th>\n      <th>EHQ_EHQ_Total</th>\n      <th>...</th>\n      <th>pc_491</th>\n      <th>pc_492</th>\n      <th>pc_493</th>\n      <th>pc_494</th>\n      <th>pc_495</th>\n      <th>pc_496</th>\n      <th>pc_497</th>\n      <th>pc_498</th>\n      <th>pc_499</th>\n      <th>pc_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>30.00</td>\n      <td>18.00</td>\n      <td>30.00</td>\n      <td>60.03</td>\n      <td>...</td>\n      <td>2.72</td>\n      <td>-4.41</td>\n      <td>-1.38</td>\n      <td>-9.93</td>\n      <td>-11.28</td>\n      <td>-0.53</td>\n      <td>-5.56</td>\n      <td>-6.11</td>\n      <td>-3.46</td>\n      <td>-3.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>NaN</td>\n      <td>30.00</td>\n      <td>86.71</td>\n      <td>...</td>\n      <td>4.55</td>\n      <td>-2.12</td>\n      <td>2.10</td>\n      <td>-4.82</td>\n      <td>1.41</td>\n      <td>-9.20</td>\n      <td>5.92</td>\n      <td>-10.07</td>\n      <td>1.04</td>\n      <td>-4.84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>40.00</td>\n      <td>18.00</td>\n      <td>40.00</td>\n      <td>26.68</td>\n      <td>...</td>\n      <td>12.55</td>\n      <td>-5.50</td>\n      <td>1.74</td>\n      <td>4.90</td>\n      <td>-5.00</td>\n      <td>-2.03</td>\n      <td>1.44</td>\n      <td>8.71</td>\n      <td>3.32</td>\n      <td>-2.07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>3</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>93.38</td>\n      <td>...</td>\n      <td>6.46</td>\n      <td>-6.19</td>\n      <td>-5.25</td>\n      <td>4.82</td>\n      <td>-3.94</td>\n      <td>-6.45</td>\n      <td>-4.88</td>\n      <td>7.53</td>\n      <td>5.00</td>\n      <td>-4.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>2.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>-93.38</td>\n      <td>...</td>\n      <td>1.40</td>\n      <td>-1.23</td>\n      <td>2.07</td>\n      <td>5.91</td>\n      <td>-0.18</td>\n      <td>-0.13</td>\n      <td>-4.12</td>\n      <td>1.49</td>\n      <td>2.53</td>\n      <td>-8.30</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>18.00</td>\n      <td>35.00</td>\n      <td>86.71</td>\n      <td>...</td>\n      <td>1.14</td>\n      <td>-7.70</td>\n      <td>5.91</td>\n      <td>-1.72</td>\n      <td>-2.22</td>\n      <td>-5.81</td>\n      <td>-5.96</td>\n      <td>3.62</td>\n      <td>7.84</td>\n      <td>-6.37</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>3</td>\n      <td>18.00</td>\n      <td>35.00</td>\n      <td>21.00</td>\n      <td>40.00</td>\n      <td>73.37</td>\n      <td>...</td>\n      <td>-6.65</td>\n      <td>-6.98</td>\n      <td>-2.96</td>\n      <td>-3.64</td>\n      <td>0.93</td>\n      <td>-5.36</td>\n      <td>-9.96</td>\n      <td>0.02</td>\n      <td>5.73</td>\n      <td>-8.26</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>2023</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>8.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>25.00</td>\n      <td>15.00</td>\n      <td>NaN</td>\n      <td>87.84</td>\n      <td>...</td>\n      <td>1.56</td>\n      <td>-12.41</td>\n      <td>-0.58</td>\n      <td>1.31</td>\n      <td>-1.14</td>\n      <td>-2.32</td>\n      <td>-9.51</td>\n      <td>0.14</td>\n      <td>3.44</td>\n      <td>1.13</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>0.00</td>\n      <td>8.00</td>\n      <td>4</td>\n      <td>21.00</td>\n      <td>0.00</td>\n      <td>21.00</td>\n      <td>45.00</td>\n      <td>46.76</td>\n      <td>...</td>\n      <td>4.52</td>\n      <td>-4.57</td>\n      <td>3.50</td>\n      <td>-4.26</td>\n      <td>-3.59</td>\n      <td>-5.86</td>\n      <td>-2.40</td>\n      <td>0.22</td>\n      <td>9.59</td>\n      <td>1.99</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>2022</td>\n      <td>4</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>4</td>\n      <td>18.00</td>\n      <td>0.00</td>\n      <td>12.00</td>\n      <td>35.00</td>\n      <td>87.84</td>\n      <td>...</td>\n      <td>-5.42</td>\n      <td>6.61</td>\n      <td>-4.70</td>\n      <td>0.01</td>\n      <td>-4.10</td>\n      <td>0.06</td>\n      <td>2.92</td>\n      <td>-0.31</td>\n      <td>3.86</td>\n      <td>1.76</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 536 columns</p>\n</div>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T21:55:05.183493Z","iopub.execute_input":"2025-02-08T21:55:05.183837Z","iopub.status.idle":"2025-02-08T21:55:05.204460Z","shell.execute_reply.started":"2025-02-08T21:55:05.183810Z","shell.execute_reply":"2025-02-08T21:55:05.203286Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"      EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  APQ_P_APQ_P_ID  \\\n0             40.00                 13.00            3.00           10.00   \n1            -94.47                 14.00            3.00           13.00   \n2            -46.67                 14.00            4.00           10.00   \n3            -26.68                 10.00            5.00           12.00   \n4              0.00                 14.00            5.00           15.00   \n...             ...                   ...             ...             ...   \n1208          87.80                 14.00            5.00           14.00   \n1209          77.80                 14.00            3.00           10.00   \n1210          16.68                 14.00            3.00           16.00   \n1211          53.40                 14.00            3.00           14.00   \n1212         -57.80                 14.00            5.00           11.00   \n\n      APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  \\\n0               47.00            13.00           11.00           28.00   \n1               34.00            18.00           23.00           30.00   \n2               35.00            16.00           10.00           29.00   \n3               39.00            19.00           16.00           28.00   \n4               40.00            20.00           24.00           28.00   \n...               ...              ...             ...             ...   \n1208            39.00            20.00           15.00           21.00   \n1209            32.00            20.00           11.00           23.00   \n1210            28.00            15.00           19.00           27.00   \n1211            34.00            18.00           23.00           23.00   \n1212            42.00            18.00           16.00           24.00   \n\n      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  ...  pc_491  \\\n0                         0.00                        6.00  ...    0.21   \n1                         0.00                       18.00  ...   -3.05   \n2                         1.00                       14.00  ...   -4.01   \n3                         6.00                       24.00  ...    6.40   \n4                         1.00                       18.00  ...   -3.19   \n...                        ...                         ...  ...     ...   \n1208                      1.00                        9.00  ...    0.49   \n1209                      6.00                       18.00  ...    0.08   \n1210                      3.00                        4.00  ...    2.52   \n1211                      4.00                        9.00  ...   -5.96   \n1212                      3.00                       12.00  ...    5.14   \n\n      pc_492  pc_493  pc_494  pc_495  pc_496  pc_497  pc_498  pc_499  pc_500  \n0       0.24    0.33   -3.67   -0.83   -0.79   -1.70   -0.61   -2.54   -2.51  \n1       3.16   -0.64    4.55   -4.54   -6.54   -1.75    6.10    6.47    0.33  \n2      -0.13    2.70   -4.49   -6.54    4.13   -0.13   -7.26    3.18    5.22  \n3      -2.73    4.98   -4.41   -0.27   -4.48   -5.64   -3.86    1.84    2.03  \n4      -3.63    0.34   -0.04   -4.05    2.22   -5.62   -1.86   -4.47    3.39  \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n1208    4.51   -5.09   -1.70    1.14   -2.06   -0.23    0.65   -4.06    6.91  \n1209   -1.41    1.15   -4.19   -0.94   -0.52   -1.39   -0.43    1.20    1.53  \n1210    3.81   -2.11   -2.12    0.85    1.68    4.10   -1.86    2.27    2.55  \n1211    2.51    0.65   -1.08   -2.86   -2.74   -2.38    0.58    6.00    1.07  \n1212    4.27    0.53    1.41    2.09   -0.45    2.04   -2.20   -2.21    5.53  \n\n[1213 rows x 527 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>...</th>\n      <th>pc_491</th>\n      <th>pc_492</th>\n      <th>pc_493</th>\n      <th>pc_494</th>\n      <th>pc_495</th>\n      <th>pc_496</th>\n      <th>pc_497</th>\n      <th>pc_498</th>\n      <th>pc_499</th>\n      <th>pc_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>47.00</td>\n      <td>13.00</td>\n      <td>11.00</td>\n      <td>28.00</td>\n      <td>0.00</td>\n      <td>6.00</td>\n      <td>...</td>\n      <td>0.21</td>\n      <td>0.24</td>\n      <td>0.33</td>\n      <td>-3.67</td>\n      <td>-0.83</td>\n      <td>-0.79</td>\n      <td>-1.70</td>\n      <td>-0.61</td>\n      <td>-2.54</td>\n      <td>-2.51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-94.47</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>13.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>30.00</td>\n      <td>0.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.05</td>\n      <td>3.16</td>\n      <td>-0.64</td>\n      <td>4.55</td>\n      <td>-4.54</td>\n      <td>-6.54</td>\n      <td>-1.75</td>\n      <td>6.10</td>\n      <td>6.47</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-46.67</td>\n      <td>14.00</td>\n      <td>4.00</td>\n      <td>10.00</td>\n      <td>35.00</td>\n      <td>16.00</td>\n      <td>10.00</td>\n      <td>29.00</td>\n      <td>1.00</td>\n      <td>14.00</td>\n      <td>...</td>\n      <td>-4.01</td>\n      <td>-0.13</td>\n      <td>2.70</td>\n      <td>-4.49</td>\n      <td>-6.54</td>\n      <td>4.13</td>\n      <td>-0.13</td>\n      <td>-7.26</td>\n      <td>3.18</td>\n      <td>5.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-26.68</td>\n      <td>10.00</td>\n      <td>5.00</td>\n      <td>12.00</td>\n      <td>39.00</td>\n      <td>19.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>6.00</td>\n      <td>24.00</td>\n      <td>...</td>\n      <td>6.40</td>\n      <td>-2.73</td>\n      <td>4.98</td>\n      <td>-4.41</td>\n      <td>-0.27</td>\n      <td>-4.48</td>\n      <td>-5.64</td>\n      <td>-3.86</td>\n      <td>1.84</td>\n      <td>2.03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>15.00</td>\n      <td>40.00</td>\n      <td>20.00</td>\n      <td>24.00</td>\n      <td>28.00</td>\n      <td>1.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>-3.19</td>\n      <td>-3.63</td>\n      <td>0.34</td>\n      <td>-0.04</td>\n      <td>-4.05</td>\n      <td>2.22</td>\n      <td>-5.62</td>\n      <td>-1.86</td>\n      <td>-4.47</td>\n      <td>3.39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>87.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>14.00</td>\n      <td>39.00</td>\n      <td>20.00</td>\n      <td>15.00</td>\n      <td>21.00</td>\n      <td>1.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>0.49</td>\n      <td>4.51</td>\n      <td>-5.09</td>\n      <td>-1.70</td>\n      <td>1.14</td>\n      <td>-2.06</td>\n      <td>-0.23</td>\n      <td>0.65</td>\n      <td>-4.06</td>\n      <td>6.91</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>77.80</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>32.00</td>\n      <td>20.00</td>\n      <td>11.00</td>\n      <td>23.00</td>\n      <td>6.00</td>\n      <td>18.00</td>\n      <td>...</td>\n      <td>0.08</td>\n      <td>-1.41</td>\n      <td>1.15</td>\n      <td>-4.19</td>\n      <td>-0.94</td>\n      <td>-0.52</td>\n      <td>-1.39</td>\n      <td>-0.43</td>\n      <td>1.20</td>\n      <td>1.53</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>16.68</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>16.00</td>\n      <td>28.00</td>\n      <td>15.00</td>\n      <td>19.00</td>\n      <td>27.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>...</td>\n      <td>2.52</td>\n      <td>3.81</td>\n      <td>-2.11</td>\n      <td>-2.12</td>\n      <td>0.85</td>\n      <td>1.68</td>\n      <td>4.10</td>\n      <td>-1.86</td>\n      <td>2.27</td>\n      <td>2.55</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>53.40</td>\n      <td>14.00</td>\n      <td>3.00</td>\n      <td>14.00</td>\n      <td>34.00</td>\n      <td>18.00</td>\n      <td>23.00</td>\n      <td>23.00</td>\n      <td>4.00</td>\n      <td>9.00</td>\n      <td>...</td>\n      <td>-5.96</td>\n      <td>2.51</td>\n      <td>0.65</td>\n      <td>-1.08</td>\n      <td>-2.86</td>\n      <td>-2.74</td>\n      <td>-2.38</td>\n      <td>0.58</td>\n      <td>6.00</td>\n      <td>1.07</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>-57.80</td>\n      <td>14.00</td>\n      <td>5.00</td>\n      <td>11.00</td>\n      <td>42.00</td>\n      <td>18.00</td>\n      <td>16.00</td>\n      <td>24.00</td>\n      <td>3.00</td>\n      <td>12.00</td>\n      <td>...</td>\n      <td>5.14</td>\n      <td>4.27</td>\n      <td>0.53</td>\n      <td>1.41</td>\n      <td>2.09</td>\n      <td>-0.45</td>\n      <td>2.04</td>\n      <td>-2.20</td>\n      <td>-2.21</td>\n      <td>5.53</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 527 columns</p>\n</div>"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"# First, let's ensure both train and test have the same columns\ndef align_datasets(train_df, test_df):\n    # Get all columns from both datasets\n    all_columns = set(train_df.columns) | set(test_df.columns)\n    \n    # Add missing columns to each dataset with zeros\n    for col in all_columns:\n        if col not in train_df.columns:\n            train_df[col] = 0\n        if col not in test_df.columns:\n            test_df[col] = 0\n    \n    # Ensure both datasets have the same column order\n    train_df = train_df[sorted(all_columns)]\n    test_df = test_df[sorted(all_columns)]\n    \n    return train_df, test_df\n\n# Align the datasets\nX_train_aligned, X_test_aligned = align_datasets(X_train, X_test)\n\n# Verify the columns match\nassert all(X_train_aligned.columns == X_test_aligned.columns), \"Columns still don't match!\"\n\n# Now use these aligned datasets with your model\nmodel.fit(X_train_aligned, y_train)\npred = model.predict(X_test_aligned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:01:13.070902Z","iopub.execute_input":"2025-02-08T22:01:13.071445Z","iopub.status.idle":"2025-02-08T22:01:53.437581Z","shell.execute_reply.started":"2025-02-08T22:01:13.071405Z","shell.execute_reply":"2025-02-08T22:01:53.436723Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# print(X_train.columns.tolist()), print(X_test.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:01:53.438452Z","iopub.execute_input":"2025-02-08T22:01:53.438731Z","iopub.status.idle":"2025-02-08T22:01:53.442848Z","shell.execute_reply.started":"2025-02-08T22:01:53.438707Z","shell.execute_reply":"2025-02-08T22:01:53.441730Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# You can convert predictions to a DataFrame for better visualization\npredictions_df = pd.DataFrame(\n    pred, \n    columns=['ADHD_Outcome', 'Sex_F'],\n    index=X_test_aligned.index\n)\n\n# Add participant_id if needed\npredictions_df['participant_id'] = final_test['participant_id']\n\n# You can also get probability predictions\npred_proba = model.predict_proba(X_test_aligned)\n\n# pred_proba will be a list of two elements:\n# pred_proba[0] = probabilities for ADHD_Outcome\n# pred_proba[1] = probabilities for Sex_F\n\n# Create probability DataFrames\nadhd_probs = pd.DataFrame(\n    pred_proba[0], \n    columns=['ADHD_prob_0', 'ADHD_prob_1'],\n    index=X_test_aligned.index\n)\n\nsex_probs = pd.DataFrame(\n    pred_proba[1], \n    columns=['Sex_prob_0', 'Sex_prob_1'],\n    index=X_test_aligned.index\n)\n\n# Combine all predictions\nfinal_predictions = pd.concat([\n    predictions_df,\n    adhd_probs,\n    sex_probs\n], axis=1)\n\n# Save predictions\nfinal_predictions.to_csv('multi_output_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:02:57.409168Z","iopub.execute_input":"2025-02-08T22:02:57.409831Z","iopub.status.idle":"2025-02-08T22:02:57.471277Z","shell.execute_reply.started":"2025-02-08T22:02:57.409776Z","shell.execute_reply":"2025-02-08T22:02:57.469863Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"final_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:03:41.044111Z","iopub.execute_input":"2025-02-08T22:03:41.044672Z","iopub.status.idle":"2025-02-08T22:03:41.061600Z","shell.execute_reply.started":"2025-02-08T22:03:41.044631Z","shell.execute_reply":"2025-02-08T22:03:41.060544Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"     ADHD_Outcome  Sex_F participant_id  ADHD_prob_0  ADHD_prob_1  Sex_prob_0  \\\n0               1      0   Cfwaf5FX7jWK         0.25         0.75        0.74   \n1               1      0   vhGrzmvA3Hjq         0.29         0.71        0.57   \n2               1      0   ULliyEXjy4OV         0.36         0.64        0.55   \n3               1      0   LZfeAb1xMtql         0.22         0.78        0.69   \n4               1      0   EnFOUv0YK1RG         0.10         0.90        0.69   \n..            ...    ...            ...          ...          ...         ...   \n299             1      1   UadZfjdEg7eG         0.30         0.70        0.48   \n300             1      0   IUEHiLmQAqCi         0.20         0.80        0.78   \n301             1      0   cRySmCadYFRO         0.43         0.57        0.56   \n302             1      0   E3MvDUtJadc5         0.26         0.74        0.61   \n303             0      1   dQJXfyRazknD         0.56         0.44        0.46   \n\n     Sex_prob_1  \n0          0.26  \n1          0.43  \n2          0.45  \n3          0.31  \n4          0.31  \n..          ...  \n299        0.52  \n300        0.22  \n301        0.44  \n302        0.39  \n303        0.54  \n\n[304 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n      <th>participant_id</th>\n      <th>ADHD_prob_0</th>\n      <th>ADHD_prob_1</th>\n      <th>Sex_prob_0</th>\n      <th>Sex_prob_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Cfwaf5FX7jWK</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.74</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>vhGrzmvA3Hjq</td>\n      <td>0.29</td>\n      <td>0.71</td>\n      <td>0.57</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>ULliyEXjy4OV</td>\n      <td>0.36</td>\n      <td>0.64</td>\n      <td>0.55</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>LZfeAb1xMtql</td>\n      <td>0.22</td>\n      <td>0.78</td>\n      <td>0.69</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>EnFOUv0YK1RG</td>\n      <td>0.10</td>\n      <td>0.90</td>\n      <td>0.69</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>1</td>\n      <td>1</td>\n      <td>UadZfjdEg7eG</td>\n      <td>0.30</td>\n      <td>0.70</td>\n      <td>0.48</td>\n      <td>0.52</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>1</td>\n      <td>0</td>\n      <td>IUEHiLmQAqCi</td>\n      <td>0.20</td>\n      <td>0.80</td>\n      <td>0.78</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>1</td>\n      <td>0</td>\n      <td>cRySmCadYFRO</td>\n      <td>0.43</td>\n      <td>0.57</td>\n      <td>0.56</td>\n      <td>0.44</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>1</td>\n      <td>0</td>\n      <td>E3MvDUtJadc5</td>\n      <td>0.26</td>\n      <td>0.74</td>\n      <td>0.61</td>\n      <td>0.39</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>0</td>\n      <td>1</td>\n      <td>dQJXfyRazknD</td>\n      <td>0.56</td>\n      <td>0.44</td>\n      <td>0.46</td>\n      <td>0.54</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"# First, let's do the train-test split correctly\nX_train_multi, X_val_multi, y_train_multi, y_val_multi = train_test_split(\n    X_train, \n    y_train, \n    test_size=0.2, \n    random_state=42,\n    stratify=y_train['ADHD_Outcome']  # Stratify by ADHD outcome\n)\n\n# Align training and validation sets\nX_train_aligned, X_val_aligned = align_datasets(X_train_multi, X_val_multi)\n\n# Train the model\nmodel.fit(X_train_aligned, y_train_multi)\n\n# Make predictions on validation set\nval_pred = model.predict(X_val_aligned)\nval_pred_proba = model.predict_proba(X_val_aligned)\n\n# Split predictions by target\nadhd_preds = val_pred[:, 0]\nsex_preds = val_pred[:, 1]\n\n# Evaluate performance\nprint(\"ADHD Prediction Performance:\")\nprint(classification_report(y_val_multi['ADHD_Outcome'], adhd_preds))\nprint(\"\\nADHD ROC-AUC:\", roc_auc_score(y_val_multi['ADHD_Outcome'], adhd_preds))\n\nprint(\"\\nSex Prediction Performance:\")\nprint(classification_report(y_val_multi['Sex_F'], sex_preds))\nprint(\"\\nSex ROC-AUC:\", roc_auc_score(y_val_multi['Sex_F'], sex_preds))\n\n# For final predictions on test set\nX_train_aligned_final, X_test_aligned_final = align_datasets(X_train, X_test)\nmodel_final = MultiOutputClassifier(\n    XGBClassifier(\n        n_estimators=500,\n        learning_rate=0.03,\n        max_depth=8,\n        colsample_bytree=0.8,\n        subsample=0.8,\n        gamma=1,\n        reg_lambda=10,\n        reg_alpha=1,\n        random_state=42\n    )\n)\nmodel_final.fit(X_train_aligned_final, y_train)\ntest_pred = model_final.predict(X_test_aligned_final)\ntest_pred_proba = model_final.predict_proba(X_test_aligned_final)\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    'participant_id': final_test['participant_id'],\n    'ADHD_Outcome': test_pred[:, 0],\n    'Sex_F': test_pred[:, 1]\n})\n\n# Save predictions\nsubmission_df.to_csv('multi_output_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:04:19.704791Z","iopub.execute_input":"2025-02-08T22:04:19.705293Z","iopub.status.idle":"2025-02-08T22:05:35.287019Z","shell.execute_reply.started":"2025-02-08T22:04:19.705236Z","shell.execute_reply":"2025-02-08T22:05:35.286126Z"}},"outputs":[{"name":"stdout","text":"ADHD Prediction Performance:\n              precision    recall  f1-score   support\n\n           0       0.76      0.53      0.63        77\n           1       0.81      0.92      0.86       166\n\n    accuracy                           0.80       243\n   macro avg       0.78      0.73      0.74       243\nweighted avg       0.79      0.80      0.79       243\n\n\nADHD ROC-AUC: 0.7270771397277421\n\nSex Prediction Performance:\n              precision    recall  f1-score   support\n\n           0       0.67      0.96      0.79       158\n           1       0.62      0.12      0.20        85\n\n    accuracy                           0.67       243\n   macro avg       0.65      0.54      0.49       243\nweighted avg       0.65      0.67      0.58       243\n\n\nSex ROC-AUC: 0.5398361876396128\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:05:35.288594Z","iopub.execute_input":"2025-02-08T22:05:35.288982Z","iopub.status.idle":"2025-02-08T22:05:35.299642Z","shell.execute_reply.started":"2025-02-08T22:05:35.288942Z","shell.execute_reply":"2025-02-08T22:05:35.298473Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"    participant_id  ADHD_Outcome  Sex_F\n0     Cfwaf5FX7jWK             1      0\n1     vhGrzmvA3Hjq             1      0\n2     ULliyEXjy4OV             1      0\n3     LZfeAb1xMtql             1      0\n4     EnFOUv0YK1RG             1      0\n..             ...           ...    ...\n299   UadZfjdEg7eG             1      1\n300   IUEHiLmQAqCi             1      0\n301   cRySmCadYFRO             1      0\n302   E3MvDUtJadc5             1      0\n303   dQJXfyRazknD             1      1\n\n[304 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>UadZfjdEg7eG</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>IUEHiLmQAqCi</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>cRySmCadYFRO</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>E3MvDUtJadc5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>dQJXfyRazknD</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Separate models for ADHD and Sex prediction\ndef train_balanced_model(X_train, y_train, X_test, target_name='ADHD_Outcome'):\n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Apply SMOTE for balance\n    smote = SMOTE(random_state=42)\n    X_train_balanced, y_train_balanced = smote.fit_resample(\n        X_train_scaled, y_train[target_name]\n    )\n    \n    # Initialize model with class weights\n    model = XGBClassifier(\n        n_estimators=500,\n        learning_rate=0.03,\n        max_depth=8,\n        colsample_bytree=0.8,\n        subsample=0.8,\n        gamma=1,\n        reg_lambda=10,\n        reg_alpha=1,\n        scale_pos_weight=1,  # Will be balanced by SMOTE\n        random_state=42\n    )\n    \n    # Calibrate probabilities\n    calibrated_model = CalibratedClassifierCV(\n        model, \n        cv=5, \n        method='sigmoid'\n    )\n    \n    # Train model\n    calibrated_model.fit(X_train_balanced, y_train_balanced)\n    \n    # Get predictions\n    y_pred = calibrated_model.predict(X_test_scaled)\n    y_pred_proba = calibrated_model.predict_proba(X_test_scaled)\n    \n    return y_pred, y_pred_proba\n\n# Train separate models\nadhd_pred, adhd_proba = train_balanced_model(X_train, y_train, X_test, 'ADHD_Outcome')\nsex_pred, sex_proba = train_balanced_model(X_train, y_train, X_test, 'Sex_F')\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    'participant_id': X_test.index,\n    'ADHD_Outcome': adhd_pred,\n    'Sex_F': sex_pred\n})\n\n# Add probability thresholding for better balance\nadhd_ratio = y_train['ADHD_Outcome'].mean()\nsex_ratio = y_train['Sex_F'].mean()\n\n# Adjust predictions based on desired class ratios\nsubmission_df['ADHD_Outcome'] = (adhd_proba[:, 1] > np.percentile(adhd_proba[:, 1], (1-adhd_ratio)*100)).astype(int)\nsubmission_df['Sex_F'] = (sex_proba[:, 1] > np.percentile(sex_proba[:, 1], (1-sex_ratio)*100)).astype(int)\n\n# Save predictions\nsubmission_df.to_csv('balanced_predictions.csv', index=False)\n\n# Print class distributions\nprint(\"ADHD Distribution:\", submission_df['ADHD_Outcome'].value_counts(normalize=True))\nprint(\"Sex Distribution:\", submission_df['Sex_F'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:11:21.523630Z","iopub.execute_input":"2025-02-08T22:11:21.524152Z","iopub.status.idle":"2025-02-08T22:11:21.808513Z","shell.execute_reply.started":"2025-02-08T22:11:21.524107Z","shell.execute_reply":"2025-02-08T22:11:21.806783Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-cf3d394c0d5c>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Train separate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0madhd_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madhd_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_balanced_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0msex_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msex_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_balanced_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex_F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-84-cf3d394c0d5c>\u001b[0m in \u001b[0;36mtrain_balanced_model\u001b[0;34m(X_train, y_train, X_test, target_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Apply SMOTE for balance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 )\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     def _validate_data(\n","\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"],"ename":"ValueError","evalue":"The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n","output_type":"error"}],"execution_count":84},{"cell_type":"code","source":"# Check our data structure\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_test shape:\", X_test.shape)\n\n# Check column names\nprint(\"\\nX_train columns:\", X_train.columns.tolist())\nprint(\"\\ny_train columns:\", y_train.columns.tolist())\nprint(\"\\nX_test columns:\", X_test.columns.tolist())\n\n# Check for any missing values\nprint(\"\\nMissing values in X_train:\", X_train.isnull().sum().sum())\nprint(\"Missing values in X_test:\", X_test.isnull().sum().sum())\n\n# Check target distributions\nprint(\"\\nADHD_Outcome distribution in training:\")\nprint(y_train['ADHD_Outcome'].value_counts(normalize=True))\nprint(\"\\nSex_F distribution in training:\")\nprint(y_train['Sex_F'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:12:29.542651Z","iopub.execute_input":"2025-02-08T22:12:29.543097Z","iopub.status.idle":"2025-02-08T22:12:29.565904Z","shell.execute_reply.started":"2025-02-08T22:12:29.543068Z","shell.execute_reply":"2025-02-08T22:12:29.564999Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (1213, 545)\ny_train shape: (1213, 2)\nX_test shape: (304, 545)\n\nX_train columns: ['EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site', 'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'pc_1', 'pc_2', 'pc_3', 'pc_4', 'pc_5', 'pc_6', 'pc_7', 'pc_8', 'pc_9', 'pc_10', 'pc_11', 'pc_12', 'pc_13', 'pc_14', 'pc_15', 'pc_16', 'pc_17', 'pc_18', 'pc_19', 'pc_20', 'pc_21', 'pc_22', 'pc_23', 'pc_24', 'pc_25', 'pc_26', 'pc_27', 'pc_28', 'pc_29', 'pc_30', 'pc_31', 'pc_32', 'pc_33', 'pc_34', 'pc_35', 'pc_36', 'pc_37', 'pc_38', 'pc_39', 'pc_40', 'pc_41', 'pc_42', 'pc_43', 'pc_44', 'pc_45', 'pc_46', 'pc_47', 'pc_48', 'pc_49', 'pc_50', 'pc_51', 'pc_52', 'pc_53', 'pc_54', 'pc_55', 'pc_56', 'pc_57', 'pc_58', 'pc_59', 'pc_60', 'pc_61', 'pc_62', 'pc_63', 'pc_64', 'pc_65', 'pc_66', 'pc_67', 'pc_68', 'pc_69', 'pc_70', 'pc_71', 'pc_72', 'pc_73', 'pc_74', 'pc_75', 'pc_76', 'pc_77', 'pc_78', 'pc_79', 'pc_80', 'pc_81', 'pc_82', 'pc_83', 'pc_84', 'pc_85', 'pc_86', 'pc_87', 'pc_88', 'pc_89', 'pc_90', 'pc_91', 'pc_92', 'pc_93', 'pc_94', 'pc_95', 'pc_96', 'pc_97', 'pc_98', 'pc_99', 'pc_100', 'pc_101', 'pc_102', 'pc_103', 'pc_104', 'pc_105', 'pc_106', 'pc_107', 'pc_108', 'pc_109', 'pc_110', 'pc_111', 'pc_112', 'pc_113', 'pc_114', 'pc_115', 'pc_116', 'pc_117', 'pc_118', 'pc_119', 'pc_120', 'pc_121', 'pc_122', 'pc_123', 'pc_124', 'pc_125', 'pc_126', 'pc_127', 'pc_128', 'pc_129', 'pc_130', 'pc_131', 'pc_132', 'pc_133', 'pc_134', 'pc_135', 'pc_136', 'pc_137', 'pc_138', 'pc_139', 'pc_140', 'pc_141', 'pc_142', 'pc_143', 'pc_144', 'pc_145', 'pc_146', 'pc_147', 'pc_148', 'pc_149', 'pc_150', 'pc_151', 'pc_152', 'pc_153', 'pc_154', 'pc_155', 'pc_156', 'pc_157', 'pc_158', 'pc_159', 'pc_160', 'pc_161', 'pc_162', 'pc_163', 'pc_164', 'pc_165', 'pc_166', 'pc_167', 'pc_168', 'pc_169', 'pc_170', 'pc_171', 'pc_172', 'pc_173', 'pc_174', 'pc_175', 'pc_176', 'pc_177', 'pc_178', 'pc_179', 'pc_180', 'pc_181', 'pc_182', 'pc_183', 'pc_184', 'pc_185', 'pc_186', 'pc_187', 'pc_188', 'pc_189', 'pc_190', 'pc_191', 'pc_192', 'pc_193', 'pc_194', 'pc_195', 'pc_196', 'pc_197', 'pc_198', 'pc_199', 'pc_200', 'pc_201', 'pc_202', 'pc_203', 'pc_204', 'pc_205', 'pc_206', 'pc_207', 'pc_208', 'pc_209', 'pc_210', 'pc_211', 'pc_212', 'pc_213', 'pc_214', 'pc_215', 'pc_216', 'pc_217', 'pc_218', 'pc_219', 'pc_220', 'pc_221', 'pc_222', 'pc_223', 'pc_224', 'pc_225', 'pc_226', 'pc_227', 'pc_228', 'pc_229', 'pc_230', 'pc_231', 'pc_232', 'pc_233', 'pc_234', 'pc_235', 'pc_236', 'pc_237', 'pc_238', 'pc_239', 'pc_240', 'pc_241', 'pc_242', 'pc_243', 'pc_244', 'pc_245', 'pc_246', 'pc_247', 'pc_248', 'pc_249', 'pc_250', 'pc_251', 'pc_252', 'pc_253', 'pc_254', 'pc_255', 'pc_256', 'pc_257', 'pc_258', 'pc_259', 'pc_260', 'pc_261', 'pc_262', 'pc_263', 'pc_264', 'pc_265', 'pc_266', 'pc_267', 'pc_268', 'pc_269', 'pc_270', 'pc_271', 'pc_272', 'pc_273', 'pc_274', 'pc_275', 'pc_276', 'pc_277', 'pc_278', 'pc_279', 'pc_280', 'pc_281', 'pc_282', 'pc_283', 'pc_284', 'pc_285', 'pc_286', 'pc_287', 'pc_288', 'pc_289', 'pc_290', 'pc_291', 'pc_292', 'pc_293', 'pc_294', 'pc_295', 'pc_296', 'pc_297', 'pc_298', 'pc_299', 'pc_300', 'pc_301', 'pc_302', 'pc_303', 'pc_304', 'pc_305', 'pc_306', 'pc_307', 'pc_308', 'pc_309', 'pc_310', 'pc_311', 'pc_312', 'pc_313', 'pc_314', 'pc_315', 'pc_316', 'pc_317', 'pc_318', 'pc_319', 'pc_320', 'pc_321', 'pc_322', 'pc_323', 'pc_324', 'pc_325', 'pc_326', 'pc_327', 'pc_328', 'pc_329', 'pc_330', 'pc_331', 'pc_332', 'pc_333', 'pc_334', 'pc_335', 'pc_336', 'pc_337', 'pc_338', 'pc_339', 'pc_340', 'pc_341', 'pc_342', 'pc_343', 'pc_344', 'pc_345', 'pc_346', 'pc_347', 'pc_348', 'pc_349', 'pc_350', 'pc_351', 'pc_352', 'pc_353', 'pc_354', 'pc_355', 'pc_356', 'pc_357', 'pc_358', 'pc_359', 'pc_360', 'pc_361', 'pc_362', 'pc_363', 'pc_364', 'pc_365', 'pc_366', 'pc_367', 'pc_368', 'pc_369', 'pc_370', 'pc_371', 'pc_372', 'pc_373', 'pc_374', 'pc_375', 'pc_376', 'pc_377', 'pc_378', 'pc_379', 'pc_380', 'pc_381', 'pc_382', 'pc_383', 'pc_384', 'pc_385', 'pc_386', 'pc_387', 'pc_388', 'pc_389', 'pc_390', 'pc_391', 'pc_392', 'pc_393', 'pc_394', 'pc_395', 'pc_396', 'pc_397', 'pc_398', 'pc_399', 'pc_400', 'pc_401', 'pc_402', 'pc_403', 'pc_404', 'pc_405', 'pc_406', 'pc_407', 'pc_408', 'pc_409', 'pc_410', 'pc_411', 'pc_412', 'pc_413', 'pc_414', 'pc_415', 'pc_416', 'pc_417', 'pc_418', 'pc_419', 'pc_420', 'pc_421', 'pc_422', 'pc_423', 'pc_424', 'pc_425', 'pc_426', 'pc_427', 'pc_428', 'pc_429', 'pc_430', 'pc_431', 'pc_432', 'pc_433', 'pc_434', 'pc_435', 'pc_436', 'pc_437', 'pc_438', 'pc_439', 'pc_440', 'pc_441', 'pc_442', 'pc_443', 'pc_444', 'pc_445', 'pc_446', 'pc_447', 'pc_448', 'pc_449', 'pc_450', 'pc_451', 'pc_452', 'pc_453', 'pc_454', 'pc_455', 'pc_456', 'pc_457', 'pc_458', 'pc_459', 'pc_460', 'pc_461', 'pc_462', 'pc_463', 'pc_464', 'pc_465', 'pc_466', 'pc_467', 'pc_468', 'pc_469', 'pc_470', 'pc_471', 'pc_472', 'pc_473', 'pc_474', 'pc_475', 'pc_476', 'pc_477', 'pc_478', 'pc_479', 'pc_480', 'pc_481', 'pc_482', 'pc_483', 'pc_484', 'pc_485', 'pc_486', 'pc_487', 'pc_488', 'pc_489', 'pc_490', 'pc_491', 'pc_492', 'pc_493', 'pc_494', 'pc_495', 'pc_496', 'pc_497', 'pc_498', 'pc_499', 'pc_500', 'Barratt_Barratt_P1_Occ_y', 'Barratt_Barratt_P2_Occ_y', 'Barratt_Barratt_P2_Occ_x', 'PreInt_Demos_Fam_Child_Ethnicity_x', 'MRI_Track_Scan_Location_y', 'PreInt_Demos_Fam_Child_Ethnicity_y', 'Barratt_Barratt_P2_Edu_y', 'Barratt_Barratt_P1_Edu_x', 'Barratt_Barratt_P2_Edu_x', 'PreInt_Demos_Fam_Child_Race_x', 'PreInt_Demos_Fam_Child_Race_y', 'Basic_Demos_Study_Site_x', 'Barratt_Barratt_P1_Edu_y', 'Barratt_Barratt_P1_Occ_x', 'MRI_Track_Scan_Location_x', 'Basic_Demos_Study_Site_y', 'Basic_Demos_Enroll_Year_x', 'Basic_Demos_Enroll_Year_y']\n\ny_train columns: ['ADHD_Outcome', 'Sex_F']\n\nX_test columns: ['Basic_Demos_Enroll_Year_x', 'Basic_Demos_Study_Site_x', 'PreInt_Demos_Fam_Child_Ethnicity_x', 'PreInt_Demos_Fam_Child_Race_x', 'MRI_Track_Scan_Location_x', 'Barratt_Barratt_P1_Edu_x', 'Barratt_Barratt_P1_Occ_x', 'Barratt_Barratt_P2_Edu_x', 'Barratt_Barratt_P2_Occ_x', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan', 'Basic_Demos_Enroll_Year_y', 'Basic_Demos_Study_Site_y', 'PreInt_Demos_Fam_Child_Ethnicity_y', 'PreInt_Demos_Fam_Child_Race_y', 'MRI_Track_Scan_Location_y', 'Barratt_Barratt_P1_Edu_y', 'Barratt_Barratt_P1_Occ_y', 'Barratt_Barratt_P2_Edu_y', 'Barratt_Barratt_P2_Occ_y', 'pc_1', 'pc_2', 'pc_3', 'pc_4', 'pc_5', 'pc_6', 'pc_7', 'pc_8', 'pc_9', 'pc_10', 'pc_11', 'pc_12', 'pc_13', 'pc_14', 'pc_15', 'pc_16', 'pc_17', 'pc_18', 'pc_19', 'pc_20', 'pc_21', 'pc_22', 'pc_23', 'pc_24', 'pc_25', 'pc_26', 'pc_27', 'pc_28', 'pc_29', 'pc_30', 'pc_31', 'pc_32', 'pc_33', 'pc_34', 'pc_35', 'pc_36', 'pc_37', 'pc_38', 'pc_39', 'pc_40', 'pc_41', 'pc_42', 'pc_43', 'pc_44', 'pc_45', 'pc_46', 'pc_47', 'pc_48', 'pc_49', 'pc_50', 'pc_51', 'pc_52', 'pc_53', 'pc_54', 'pc_55', 'pc_56', 'pc_57', 'pc_58', 'pc_59', 'pc_60', 'pc_61', 'pc_62', 'pc_63', 'pc_64', 'pc_65', 'pc_66', 'pc_67', 'pc_68', 'pc_69', 'pc_70', 'pc_71', 'pc_72', 'pc_73', 'pc_74', 'pc_75', 'pc_76', 'pc_77', 'pc_78', 'pc_79', 'pc_80', 'pc_81', 'pc_82', 'pc_83', 'pc_84', 'pc_85', 'pc_86', 'pc_87', 'pc_88', 'pc_89', 'pc_90', 'pc_91', 'pc_92', 'pc_93', 'pc_94', 'pc_95', 'pc_96', 'pc_97', 'pc_98', 'pc_99', 'pc_100', 'pc_101', 'pc_102', 'pc_103', 'pc_104', 'pc_105', 'pc_106', 'pc_107', 'pc_108', 'pc_109', 'pc_110', 'pc_111', 'pc_112', 'pc_113', 'pc_114', 'pc_115', 'pc_116', 'pc_117', 'pc_118', 'pc_119', 'pc_120', 'pc_121', 'pc_122', 'pc_123', 'pc_124', 'pc_125', 'pc_126', 'pc_127', 'pc_128', 'pc_129', 'pc_130', 'pc_131', 'pc_132', 'pc_133', 'pc_134', 'pc_135', 'pc_136', 'pc_137', 'pc_138', 'pc_139', 'pc_140', 'pc_141', 'pc_142', 'pc_143', 'pc_144', 'pc_145', 'pc_146', 'pc_147', 'pc_148', 'pc_149', 'pc_150', 'pc_151', 'pc_152', 'pc_153', 'pc_154', 'pc_155', 'pc_156', 'pc_157', 'pc_158', 'pc_159', 'pc_160', 'pc_161', 'pc_162', 'pc_163', 'pc_164', 'pc_165', 'pc_166', 'pc_167', 'pc_168', 'pc_169', 'pc_170', 'pc_171', 'pc_172', 'pc_173', 'pc_174', 'pc_175', 'pc_176', 'pc_177', 'pc_178', 'pc_179', 'pc_180', 'pc_181', 'pc_182', 'pc_183', 'pc_184', 'pc_185', 'pc_186', 'pc_187', 'pc_188', 'pc_189', 'pc_190', 'pc_191', 'pc_192', 'pc_193', 'pc_194', 'pc_195', 'pc_196', 'pc_197', 'pc_198', 'pc_199', 'pc_200', 'pc_201', 'pc_202', 'pc_203', 'pc_204', 'pc_205', 'pc_206', 'pc_207', 'pc_208', 'pc_209', 'pc_210', 'pc_211', 'pc_212', 'pc_213', 'pc_214', 'pc_215', 'pc_216', 'pc_217', 'pc_218', 'pc_219', 'pc_220', 'pc_221', 'pc_222', 'pc_223', 'pc_224', 'pc_225', 'pc_226', 'pc_227', 'pc_228', 'pc_229', 'pc_230', 'pc_231', 'pc_232', 'pc_233', 'pc_234', 'pc_235', 'pc_236', 'pc_237', 'pc_238', 'pc_239', 'pc_240', 'pc_241', 'pc_242', 'pc_243', 'pc_244', 'pc_245', 'pc_246', 'pc_247', 'pc_248', 'pc_249', 'pc_250', 'pc_251', 'pc_252', 'pc_253', 'pc_254', 'pc_255', 'pc_256', 'pc_257', 'pc_258', 'pc_259', 'pc_260', 'pc_261', 'pc_262', 'pc_263', 'pc_264', 'pc_265', 'pc_266', 'pc_267', 'pc_268', 'pc_269', 'pc_270', 'pc_271', 'pc_272', 'pc_273', 'pc_274', 'pc_275', 'pc_276', 'pc_277', 'pc_278', 'pc_279', 'pc_280', 'pc_281', 'pc_282', 'pc_283', 'pc_284', 'pc_285', 'pc_286', 'pc_287', 'pc_288', 'pc_289', 'pc_290', 'pc_291', 'pc_292', 'pc_293', 'pc_294', 'pc_295', 'pc_296', 'pc_297', 'pc_298', 'pc_299', 'pc_300', 'pc_301', 'pc_302', 'pc_303', 'pc_304', 'pc_305', 'pc_306', 'pc_307', 'pc_308', 'pc_309', 'pc_310', 'pc_311', 'pc_312', 'pc_313', 'pc_314', 'pc_315', 'pc_316', 'pc_317', 'pc_318', 'pc_319', 'pc_320', 'pc_321', 'pc_322', 'pc_323', 'pc_324', 'pc_325', 'pc_326', 'pc_327', 'pc_328', 'pc_329', 'pc_330', 'pc_331', 'pc_332', 'pc_333', 'pc_334', 'pc_335', 'pc_336', 'pc_337', 'pc_338', 'pc_339', 'pc_340', 'pc_341', 'pc_342', 'pc_343', 'pc_344', 'pc_345', 'pc_346', 'pc_347', 'pc_348', 'pc_349', 'pc_350', 'pc_351', 'pc_352', 'pc_353', 'pc_354', 'pc_355', 'pc_356', 'pc_357', 'pc_358', 'pc_359', 'pc_360', 'pc_361', 'pc_362', 'pc_363', 'pc_364', 'pc_365', 'pc_366', 'pc_367', 'pc_368', 'pc_369', 'pc_370', 'pc_371', 'pc_372', 'pc_373', 'pc_374', 'pc_375', 'pc_376', 'pc_377', 'pc_378', 'pc_379', 'pc_380', 'pc_381', 'pc_382', 'pc_383', 'pc_384', 'pc_385', 'pc_386', 'pc_387', 'pc_388', 'pc_389', 'pc_390', 'pc_391', 'pc_392', 'pc_393', 'pc_394', 'pc_395', 'pc_396', 'pc_397', 'pc_398', 'pc_399', 'pc_400', 'pc_401', 'pc_402', 'pc_403', 'pc_404', 'pc_405', 'pc_406', 'pc_407', 'pc_408', 'pc_409', 'pc_410', 'pc_411', 'pc_412', 'pc_413', 'pc_414', 'pc_415', 'pc_416', 'pc_417', 'pc_418', 'pc_419', 'pc_420', 'pc_421', 'pc_422', 'pc_423', 'pc_424', 'pc_425', 'pc_426', 'pc_427', 'pc_428', 'pc_429', 'pc_430', 'pc_431', 'pc_432', 'pc_433', 'pc_434', 'pc_435', 'pc_436', 'pc_437', 'pc_438', 'pc_439', 'pc_440', 'pc_441', 'pc_442', 'pc_443', 'pc_444', 'pc_445', 'pc_446', 'pc_447', 'pc_448', 'pc_449', 'pc_450', 'pc_451', 'pc_452', 'pc_453', 'pc_454', 'pc_455', 'pc_456', 'pc_457', 'pc_458', 'pc_459', 'pc_460', 'pc_461', 'pc_462', 'pc_463', 'pc_464', 'pc_465', 'pc_466', 'pc_467', 'pc_468', 'pc_469', 'pc_470', 'pc_471', 'pc_472', 'pc_473', 'pc_474', 'pc_475', 'pc_476', 'pc_477', 'pc_478', 'pc_479', 'pc_480', 'pc_481', 'pc_482', 'pc_483', 'pc_484', 'pc_485', 'pc_486', 'pc_487', 'pc_488', 'pc_489', 'pc_490', 'pc_491', 'pc_492', 'pc_493', 'pc_494', 'pc_495', 'pc_496', 'pc_497', 'pc_498', 'pc_499', 'pc_500', 'MRI_Track_Scan_Location', 'PreInt_Demos_Fam_Child_Race', 'Basic_Demos_Enroll_Year', 'PreInt_Demos_Fam_Child_Ethnicity', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Basic_Demos_Study_Site']\n\nMissing values in X_train: 11\nMissing values in X_test: 178\n\nADHD_Outcome distribution in training:\nADHD_Outcome\n1   0.69\n0   0.31\nName: proportion, dtype: float64\n\nSex_F distribution in training:\nSex_F\n0   0.66\n1   0.34\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"def preprocess_data(X_train, X_test, y_train):\n    # 1. Handle missing values first\n    X_train = X_train.fillna(X_train.mean())\n    X_test = X_test.fillna(X_test.mean())\n    \n    # 2. Keep only pc_ columns (which are unique) and one copy of the demographic columns\n    pc_cols = [col for col in X_train.columns if col.startswith('pc_')]\n    demo_cols = [\n        'EHQ_EHQ_Total', \n        'ColorVision_CV_Score',\n        'APQ_P_APQ_P_CP',\n        'APQ_P_APQ_P_ID',\n        'APQ_P_APQ_P_INV',\n        'APQ_P_APQ_P_OPD',\n        'APQ_P_APQ_P_PM',\n        'APQ_P_APQ_P_PP',\n        'SDQ_SDQ_Conduct_Problems',\n        'SDQ_SDQ_Difficulties_Total',\n        'SDQ_SDQ_Emotional_Problems',\n        'SDQ_SDQ_Externalizing',\n        'SDQ_SDQ_Generating_Impact',\n        'SDQ_SDQ_Hyperactivity',\n        'SDQ_SDQ_Internalizing',\n        'SDQ_SDQ_Peer_Problems',\n        'SDQ_SDQ_Prosocial',\n        'MRI_Track_Age_at_Scan'\n    ]\n    \n    # Keep demographic columns with _x suffix (first copy)\n    demo_cols_x = [col for col in X_train.columns if col.endswith('_x') and col.replace('_x', '') not in demo_cols]\n    \n    # Combine all columns we want to keep\n    keep_cols = pc_cols + demo_cols + demo_cols_x\n    \n    # Select columns and rename _x columns\n    X_train = X_train[keep_cols].copy()\n    X_test = X_test[keep_cols].copy()\n    \n    # Remove _x suffix\n    rename_dict = {col: col.replace('_x', '') for col in demo_cols_x}\n    X_train = X_train.rename(columns=rename_dict)\n    X_test = X_test.rename(columns=rename_dict)\n    \n    print(f\"Shape after preprocessing - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n    \n    return X_train, X_test\n\ndef train_models(X_train, X_test, y_train):\n    # Train separate models for ADHD and Sex prediction\n    models = {}\n    predictions = {}\n    \n    for target in ['ADHD_Outcome', 'Sex_F']:\n        # Initialize model\n        model = XGBClassifier(\n            n_estimators=500,\n            learning_rate=0.03,\n            max_depth=8,\n            colsample_bytree=0.8,\n            subsample=0.8,\n            gamma=1,\n            reg_lambda=10,\n            reg_alpha=1,\n            scale_pos_weight=1/y_train[target].mean(),  # Handle class imbalance\n            random_state=42\n        )\n        \n        # Train model\n        model.fit(\n            X_train, \n            y_train[target],\n            eval_metric='auc',\n            verbose=False\n        )\n        \n        # Store model\n        models[target] = model\n        \n        # Make predictions\n        predictions[target] = model.predict(X_test)\n    \n    return predictions\n\n# Preprocess the data\nX_train_prep, X_test_prep = preprocess_data(X_train, X_test, y_train)\n\n# Train models and get predictions\npredictions = train_models(X_train_prep, X_test_prep, y_train)\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    'participant_id': X_test.index,\n    'ADHD_Outcome': predictions['ADHD_Outcome'],\n    'Sex_F': predictions['Sex_F']\n})\n\n# Print class distributions in predictions\nprint(\"\\nPredicted distributions:\")\nprint(\"ADHD Distribution:\", pd.Series(predictions['ADHD_Outcome']).value_counts(normalize=True))\nprint(\"Sex Distribution:\", pd.Series(predictions['Sex_F']).value_counts(normalize=True))\n\n# Save predictions\nsubmission_df.to_csv('multi_output_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:13:47.941445Z","iopub.execute_input":"2025-02-08T22:13:47.941835Z","iopub.status.idle":"2025-02-08T22:14:39.749558Z","shell.execute_reply.started":"2025-02-08T22:13:47.941804Z","shell.execute_reply":"2025-02-08T22:14:39.748526Z"}},"outputs":[{"name":"stdout","text":"Shape after preprocessing - X_train: (1213, 527), X_test: (304, 527)\n\nPredicted distributions:\nADHD Distribution: 1   0.87\n0   0.13\nName: proportion, dtype: float64\nSex Distribution: 1   0.53\n0   0.47\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# Split training data into train and validation sets\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n    X_train_prep, \n    y_train, \n    test_size=0.2, \n    random_state=42,\n    stratify=y_train['ADHD_Outcome']\n)\n\n# Train and evaluate models\nfor target in ['ADHD_Outcome', 'Sex_F']:\n    print(f\"\\n{target} Classification Report:\")\n    \n    model = XGBClassifier(\n        n_estimators=500,\n        learning_rate=0.03,\n        max_depth=8,\n        colsample_bytree=0.8,\n        subsample=0.8,\n        gamma=1,\n        reg_lambda=10,\n        reg_alpha=1,\n        scale_pos_weight=1/y_train[target].mean(),\n        random_state=42\n    )\n    \n    # Train on split training data\n    model.fit(\n        X_train_split, \n        y_train_split[target],\n        eval_metric='auc',\n        verbose=False\n    )\n    \n    # Predict on validation set\n    val_pred = model.predict(X_val_split)\n    \n    # Print classification report\n    print(classification_report(y_val_split[target], val_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:15:29.143236Z","iopub.execute_input":"2025-02-08T22:15:29.143601Z","iopub.status.idle":"2025-02-08T22:16:11.961860Z","shell.execute_reply.started":"2025-02-08T22:15:29.143574Z","shell.execute_reply":"2025-02-08T22:16:11.960585Z"}},"outputs":[{"name":"stdout","text":"\nADHD_Outcome Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.52      0.62        77\n           1       0.81      0.93      0.86       166\n\n    accuracy                           0.80       243\n   macro avg       0.79      0.72      0.74       243\nweighted avg       0.79      0.80      0.79       243\n\n\nSex_F Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.70      0.82      0.76       158\n           1       0.51      0.34      0.41        85\n\n    accuracy                           0.65       243\n   macro avg       0.60      0.58      0.58       243\nweighted avg       0.63      0.65      0.63       243\n\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.calibration import CalibratedClassifierCV\n\ndef train_improved_model(X_train, X_val, y_train, y_val, target):\n    # Apply SMOTE to balance classes\n    smote = SMOTE(random_state=42)\n    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train[target])\n    \n    # Initialize base model\n    base_model = XGBClassifier(\n        n_estimators=1000,  # Increased from 500\n        learning_rate=0.01,  # Decreased from 0.03\n        max_depth=6,        # Decreased from 8\n        colsample_bytree=0.8,\n        subsample=0.8,\n        gamma=1,\n        reg_lambda=15,      # Increased regularization\n        reg_alpha=2,\n        random_state=42\n    )\n    \n    # Add probability calibration\n    model = CalibratedClassifierCV(\n        base_model,\n        cv=5,\n        method='sigmoid'\n    )\n    \n    # Train model\n    model.fit(X_train_balanced, y_train_balanced)\n    \n    # Get predictions\n    val_pred = model.predict(X_val)\n    val_proba = model.predict_proba(X_val)\n    \n    # Print classification report\n    print(f\"\\n{target} Classification Report:\")\n    print(classification_report(y_val[target], val_pred))\n    \n    return model, val_proba\n\n# Train improved models\nadhd_model, adhd_proba = train_improved_model(\n    X_train_split, X_val_split, y_train_split, y_val_split, 'ADHD_Outcome'\n)\n\nsex_model, sex_proba = train_improved_model(\n    X_train_split, X_val_split, y_train_split, y_val_split, 'Sex_F'\n)\n\n# Function to find optimal threshold\ndef find_optimal_threshold(y_true, y_proba):\n    thresholds = np.arange(0.3, 0.7, 0.01)\n    best_f1 = 0\n    best_threshold = 0.5\n    \n    for threshold in thresholds:\n        y_pred = (y_proba[:, 1] > threshold).astype(int)\n        f1 = f1_score(y_true, y_pred)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = threshold\n    \n    return best_threshold\n\n# Find optimal thresholds\nadhd_threshold = find_optimal_threshold(y_val_split['ADHD_Outcome'], adhd_proba)\nsex_threshold = find_optimal_threshold(y_val_split['Sex_F'], sex_proba)\n\nprint(f\"\\nOptimal thresholds - ADHD: {adhd_threshold:.3f}, Sex: {sex_threshold:.3f}\")\n\n# Make final predictions on test set\ntest_adhd_proba = adhd_model.predict_proba(X_test_prep)\ntest_sex_proba = sex_model.predict_proba(X_test_prep)\n\nsubmission_df = pd.DataFrame({\n    'participant_id': X_test.index,\n    'ADHD_Outcome': (test_adhd_proba[:, 1] > adhd_threshold).astype(int),\n    'Sex_F': (test_sex_proba[:, 1] > sex_threshold).astype(int)\n})\n\n# Print final distributions\nprint(\"\\nFinal predicted distributions:\")\nprint(\"ADHD Distribution:\", submission_df['ADHD_Outcome'].value_counts(normalize=True))\nprint(\"Sex Distribution:\", submission_df['Sex_F'].value_counts(normalize=True))\n\n# Save predictions\nsubmission_df.to_csv('improved_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:19:43.403108Z","iopub.execute_input":"2025-02-08T22:19:43.403536Z","iopub.status.idle":"2025-02-08T22:26:28.179711Z","shell.execute_reply.started":"2025-02-08T22:19:43.403504Z","shell.execute_reply":"2025-02-08T22:26:28.178327Z"}},"outputs":[{"name":"stdout","text":"\nADHD_Outcome Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      0.58      0.66        77\n           1       0.83      0.91      0.87       166\n\n    accuracy                           0.81       243\n   macro avg       0.79      0.75      0.76       243\nweighted avg       0.80      0.81      0.80       243\n\n\nSex_F Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.67      0.90      0.77       158\n           1       0.48      0.18      0.26        85\n\n    accuracy                           0.65       243\n   macro avg       0.58      0.54      0.51       243\nweighted avg       0.60      0.65      0.59       243\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-6993a6ab3a40>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Find optimal thresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0madhd_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_optimal_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madhd_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0msex_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_optimal_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sex_F'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msex_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-89-6993a6ab3a40>\u001b[0m in \u001b[0;36mfind_optimal_threshold\u001b[0;34m(y_true, y_proba)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_f1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mbest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"],"ename":"NameError","evalue":"name 'f1_score' is not defined","output_type":"error"}],"execution_count":89},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report\nimport numpy as np\n\n# Function to find optimal threshold\ndef find_optimal_threshold(y_true, y_proba):\n    thresholds = np.arange(0.3, 0.7, 0.01)\n    best_f1 = 0\n    best_threshold = 0.5\n    \n    for threshold in thresholds:\n        y_pred = (y_proba[:, 1] > threshold).astype(int)\n        f1 = f1_score(y_true, y_pred)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = threshold\n    \n    return best_threshold\n\n# Find optimal thresholds\nadhd_threshold = find_optimal_threshold(y_val_split['ADHD_Outcome'], adhd_proba)\nsex_threshold = find_optimal_threshold(y_val_split['Sex_F'], sex_proba)\n\nprint(f\"\\nOptimal thresholds - ADHD: {adhd_threshold:.3f}, Sex: {sex_threshold:.3f}\")\n\n# Make final predictions on test set\ntest_adhd_proba = adhd_model.predict_proba(X_test_prep)\ntest_sex_proba = sex_model.predict_proba(X_test_prep)\n\nsubmission_df = pd.DataFrame({\n    'participant_id': X_test.index,\n    'ADHD_Outcome': (test_adhd_proba[:, 1] > adhd_threshold).astype(int),\n    'Sex_F': (test_sex_proba[:, 1] > sex_threshold).astype(int)\n})\n\n# Print final distributions\nprint(\"\\nFinal predicted distributions:\")\nprint(\"ADHD Distribution:\", submission_df['ADHD_Outcome'].value_counts(normalize=True))\nprint(\"Sex Distribution:\", submission_df['Sex_F'].value_counts(normalize=True))\n\n# Save predictions\nsubmission_df.to_csv('improved_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:29:01.010867Z","iopub.execute_input":"2025-02-08T22:29:01.011344Z","iopub.status.idle":"2025-02-08T22:29:01.722512Z","shell.execute_reply.started":"2025-02-08T22:29:01.011309Z","shell.execute_reply":"2025-02-08T22:29:01.721425Z"}},"outputs":[{"name":"stdout","text":"\nOptimal thresholds - ADHD: 0.450, Sex: 0.300\n\nFinal predicted distributions:\nADHD Distribution: ADHD_Outcome\n1   0.81\n0   0.19\nName: proportion, dtype: float64\nSex Distribution: Sex_F\n0   0.74\n1   0.26\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\n\ndef train_sex_model_improved(X_train, X_val, y_train, y_val):\n    # First, use XGBoost to select important features\n    feature_selector = XGBClassifier(n_estimators=100, importance_type='gain')\n    feature_selector.fit(X_train, y_train['Sex_F'])\n    \n    # Select top features\n    selection = SelectFromModel(feature_selector, prefit=True, threshold='median')\n    X_train_selected = selection.transform(X_train)\n    X_val_selected = selection.transform(X_val)\n    \n    # Apply SMOTE with different parameters\n    smote = SMOTE(random_state=42, k_neighbors=5)\n    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_selected, y_train['Sex_F'])\n    \n    # Initialize LightGBM model\n    model = LGBMClassifier(\n        n_estimators=2000,\n        learning_rate=0.01,\n        num_leaves=31,\n        class_weight='balanced',\n        random_state=42,\n        n_jobs=-1,\n        verbose=-1  # Suppress output\n    )\n    \n    # Train model\n    model.fit(\n        X_train_balanced, \n        y_train_balanced,\n        eval_metric='auc'\n    )\n    \n    # Get predictions\n    val_pred = model.predict(X_val_selected)\n    val_proba = model.predict_proba(X_val_selected)\n    \n    print(\"\\nSex_F Classification Report (LightGBM with Feature Selection):\")\n    print(classification_report(y_val['Sex_F'], val_pred))\n    \n    return model, selection, val_proba\n\n# Train improved sex model\nsex_model_lgb, feature_selector, sex_proba_lgb = train_sex_model_improved(\n    X_train_split, X_val_split, y_train_split, y_val_split\n)\n\n# Find optimal threshold for sex predictions\nsex_threshold_lgb = find_optimal_threshold(y_val_split['Sex_F'], sex_proba_lgb)\nprint(f\"\\nOptimal threshold for Sex prediction: {sex_threshold_lgb:.3f}\")\n\n# Make final predictions\nX_test_selected = feature_selector.transform(X_test_prep)\ntest_sex_proba_lgb = sex_model_lgb.predict_proba(X_test_selected)\n\n# Create new submission with improved sex predictions\nsubmission_df = pd.DataFrame({\n    'participant_id': X_test.index,\n    'ADHD_Outcome': (test_adhd_proba[:, 1] > adhd_threshold).astype(int),\n    'Sex_F': (test_sex_proba_lgb[:, 1] > sex_threshold_lgb).astype(int)\n})\n\n# Print final distributions\nprint(\"\\nFinal predicted distributions:\")\nprint(\"ADHD Distribution:\", submission_df['ADHD_Outcome'].value_counts(normalize=True))\nprint(\"Sex Distribution:\", submission_df['Sex_F'].value_counts(normalize=True))\n\n# Print feature importance\nif hasattr(sex_model_lgb, 'feature_importances_'):\n    importances = pd.DataFrame({\n        'feature': feature_selector.get_feature_names_out(),\n        'importance': sex_model_lgb.feature_importances_\n    }).sort_values('importance', ascending=False)\n    print(\"\\nTop 10 features for Sex prediction:\")\n    print(importances.head(10))\n\n# Save predictions\nsubmission_df.to_csv('improved_predictions_with_lgb.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T22:30:06.133752Z","iopub.execute_input":"2025-02-08T22:30:06.134213Z","iopub.status.idle":"2025-02-08T22:30:38.013479Z","shell.execute_reply.started":"2025-02-08T22:30:06.134161Z","shell.execute_reply":"2025-02-08T22:30:38.011789Z"}},"outputs":[{"name":"stdout","text":"\nSex_F Classification Report (LightGBM with Feature Selection):\n              precision    recall  f1-score   support\n\n           0       0.66      0.83      0.74       158\n           1       0.41      0.22      0.29        85\n\n    accuracy                           0.62       243\n   macro avg       0.54      0.53      0.51       243\nweighted avg       0.58      0.62      0.58       243\n\n\nOptimal threshold for Sex prediction: 0.300\n\nFinal predicted distributions:\nADHD Distribution: ADHD_Outcome\n1   0.81\n0   0.19\nName: proportion, dtype: float64\nSex Distribution: Sex_F\n0   0.89\n1   0.11\nName: proportion, dtype: float64\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-45290c9b3b90>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msex_model_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature_importances_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     importances = pd.DataFrame({\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;34m'importance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msex_model_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     }).sort_values('importance', ascending=False)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mget_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0minput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_feature_names_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names_in\u001b[0;34m(estimator, input_features, generate_names)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     \u001b[0;31m# Generates feature names if `n_features_in_` is defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_features_in_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to generate feature names without n_features_in_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"x{i}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to generate feature names without n_features_in_"],"ename":"ValueError","evalue":"Unable to generate feature names without n_features_in_","output_type":"error"}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}